 (cd "$(git rev-parse --show-toplevel)" && git apply --3way <<'EOF' 
diff --git a/tests/routes/caption-generation.test.ts b/tests/routes/caption-generation.test.ts
index 5770fb737acb5e4b9a524eab4fa26ebd2b85b10b..224735f921a6781c0015c1bad32896408405e34c 100644
--- a/tests/routes/caption-generation.test.ts
+++ b/tests/routes/caption-generation.test.ts
@@ -193,27 +193,142 @@ describe('Caption Generation', () => {
               caption: 'Enhanced and engaging caption! ✨',
               hashtags: ['#enhanced', '#content'],
               safety_level: 'normal',
               mood: 'engaging',
               style: 'authentic',
               cta: 'What do you think?',
             },
           ]),
         },
       };
 
       const { textModel } = await import('../../server/lib/gemini.js');
       const genSpy = vi.spyOn(textModel, 'generateContent').mockResolvedValue(mockResponse as any);
 
       const result = await pipelineRewrite({
         platform: 'instagram',
         voice: 'engaging',
         existingCaption,
       });
 
       expect(result.final.caption).not.toBe(existingCaption);
       expect(result.final.caption).toContain('Enhanced');
 
       genSpy.mockRestore();
     });
+
+    it('retries rewrite with hints when the first pass is too short', async () => {
+      const existingCaption = 'Basic caption here';
+      const longAltText =
+        'A descriptive alt text that clearly explains the scene and exceeds the schema requirements for length.';
+
+      const makeVariants = (caption: string) =>
+        Array.from({ length: 5 }, () => ({
+          caption,
+          hashtags: ['#vibes', '#style', '#moments'],
+          safety_level: 'normal',
+          mood: 'engaging',
+          style: 'authentic',
+          cta: 'Tell me what you think',
+          alt: longAltText,
+          nsfw: false,
+        }));
+
+      const shortVariantsResponse = {
+        response: {
+          text: () => JSON.stringify(makeVariants(existingCaption)),
+        },
+      } satisfies { response: { text: () => string } };
+
+      const shortRankResponse = {
+        response: {
+          text: () =>
+            JSON.stringify({
+              winner_index: 0,
+              scores: [5, 4, 3, 2, 1],
+              reason: 'Short baseline rewrite',
+              final: {
+                caption: existingCaption,
+                hashtags: ['#vibes', '#style', '#moments'],
+                safety_level: 'normal',
+                mood: 'engaging',
+                style: 'authentic',
+                cta: 'Tell me what you think',
+                alt: longAltText,
+                nsfw: false,
+              },
+            }),
+        },
+      } satisfies { response: { text: () => string } };
+
+      const longerCaption =
+        'Basic caption here, now expanded with vivid detail that teases the story and invites you to join the conversation.';
+
+      const longVariantsResponse = {
+        response: {
+          text: () => JSON.stringify(makeVariants(longerCaption)),
+        },
+      } satisfies { response: { text: () => string } };
+
+      const longRankResponse = {
+        response: {
+          text: () =>
+            JSON.stringify({
+              winner_index: 0,
+              scores: [5, 4, 3, 2, 1],
+              reason: 'Longer rewrite with CTA',
+              final: {
+                caption: longerCaption,
+                hashtags: ['#vibes', '#style', '#moments'],
+                safety_level: 'normal',
+                mood: 'engaging',
+                style: 'authentic',
+                cta: 'Tell me what you think',
+                alt: longAltText,
+                nsfw: false,
+              },
+            }),
+        },
+      } satisfies { response: { text: () => string } };
+
+      const { textModel } = await import('../../server/lib/gemini.js');
+      const generateContentMock = vi.spyOn(textModel, 'generateContent');
+
+      const shortVariantsCast = shortVariantsResponse as unknown as Awaited<
+        ReturnType<(typeof textModel)['generateContent']>
+      >;
+      const shortRankCast = shortRankResponse as unknown as Awaited<
+        ReturnType<(typeof textModel)['generateContent']>
+      >;
+      const longVariantsCast = longVariantsResponse as unknown as Awaited<
+        ReturnType<(typeof textModel)['generateContent']>
+      >;
+      const longRankCast = longRankResponse as unknown as Awaited<
+        ReturnType<(typeof textModel)['generateContent']>
+      >;
+
+      generateContentMock
+        .mockResolvedValueOnce(shortVariantsCast)
+        .mockResolvedValueOnce(shortRankCast)
+        .mockResolvedValueOnce(longVariantsCast)
+        .mockResolvedValueOnce(longRankCast);
+
+      const result = await pipelineRewrite({
+        platform: 'instagram',
+        voice: 'engaging',
+        existingCaption,
+      });
+
+      expect(result.final.caption.length).toBeGreaterThan(existingCaption.length);
+      expect(result.final.caption).toBe(longerCaption);
+      expect(result.final.caption).not.toContain('Enhanced with engaging content and call-to-action that drives better engagement');
+
+      const promptCalls = [...generateContentMock.mock.calls];
+      expect(promptCalls).toHaveLength(4);
+      expect(promptCalls[2]?.[0]?.[0]?.text).toContain(
+        'Make it 20% longer with a natural hook and CTA; keep it human, no sparkle clichés.'
+      );
+
+      generateContentMock.mockRestore();
+    });
   });
-});
+});
 
EOF
)