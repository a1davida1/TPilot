diff --git a/server/caption/geminiPipeline.ts b/server/caption/geminiPipeline.ts
index 2efa0c3..5e4451b 100644
--- a/server/caption/geminiPipeline.ts
+++ b/server/caption/geminiPipeline.ts
@@ -85,10 +85,15 @@ export async function extractFacts(imageUrl:string){
 
     const img={ inlineData:{ data: imageData, mimeType } };
     console.log('Sending to Gemini for fact extraction...');
-    const res=await visionModel.generateContent([{text:sys+"\n"+guard+"\n"+prompt}, img]);
-    const result = stripToJSON(res.response.text());
-    console.log('Fact extraction completed successfully');
-    return result;
+    try {
+      const res=await visionModel.generateContent([{text:sys+"\n"+guard+"\n"+prompt}, img]);
+      const result = stripToJSON(res.response.text());
+      console.log('Fact extraction completed successfully');
+      return result;
+    } catch (error) {
+      console.error('Gemini visionModel.generateContent failed:', error);
+      throw error;
+    }
   } catch (error) {
     console.error('Error in extractFacts:', error);
     throw new Error(`Failed to extract facts: ${error instanceof Error ? error.message : String(error)}`);
@@ -98,13 +103,20 @@ export async function extractFacts(imageUrl:string){
 export async function generateVariants(params:{platform:"instagram"|"x"|"reddit"|"tiktok", voice:string, style?:string, mood?:string, facts:any, hint?:string, nsfw?:boolean}){
   const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("variants.txt");
   const user=`PLATFORM: ${params.platform}\nVOICE: ${params.voice}\n${params.style ? `STYLE: ${params.style}\n` : ''}${params.mood ? `MOOD: ${params.mood}\n` : ''}IMAGE_FACTS: ${JSON.stringify(params.facts)}\nNSFW: ${params.nsfw || false}\n${params.hint?`HINT:${params.hint}`:""}`;
-  const res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+user }]);
+  let res;
+  try {
+    res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+user }]);
+  } catch (error) {
+    console.error('Gemini textModel.generateContent failed:', error);
+    throw error;
+  }
   const json=stripToJSON(res.response.text());
   // Fix common safety_level values and missing fields
   if(Array.isArray(json)){
     json.forEach((item:any)=>{
-      // Accept any safety_level from AI
+      // Accept any safety_level from AI but normalize "suggestive"
       if(!item.safety_level) item.safety_level="normal";
+      else if(item.safety_level === 'suggestive') item.safety_level = 'spicy_safe';
       // Fix other fields
       if(!item.mood || item.mood.length<2) item.mood="engaging";
       if(!item.style || item.style.length<2) item.style="authentic";
@@ -139,7 +151,13 @@ export async function generateVariants(params:{platform:"instagram"|"x"|"reddit"
 
 export async function rankAndSelect(variants:any){
   const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("rank.txt");
-  const res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+JSON.stringify(variants) }]);
+  let res;
+  try {
+    res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+JSON.stringify(variants) }]);
+  } catch (error) {
+    console.error('Gemini textModel.generateContent failed:', error);
+    throw error;
+  }
   let json=stripToJSON(res.response.text());
 
   // Handle case where AI returns array instead of ranking object
@@ -168,17 +186,23 @@ export async function rankAndSelect(variants:any){
 
 export async function pipeline({ imageUrl, platform, voice="flirty_playful", style, mood, nsfw=false }:{
   imageUrl:string, platform:"instagram"|"x"|"reddit"|"tiktok", voice?:string, style?:string, mood?:string, nsfw?:boolean }){
-  const facts = await extractFacts(imageUrl);
-  let variants = await generateVariants({ platform, voice, style, mood, facts, nsfw });
-  let ranked = await rankAndSelect(variants);
-  let out = ranked.final;
-
-  const err = platformChecks(platform, out);
-  if (err) {
-    variants = await generateVariants({ platform, voice, facts, hint:`Fix: ${err}. Use IMAGE_FACTS nouns/colors/setting explicitly.`, nsfw });
-    ranked = await rankAndSelect(variants);
-    out = ranked.final;
-  }
-
-  return { facts, variants, ranked, final: out };
+  try {
+    const facts = await extractFacts(imageUrl);
+    let variants = await generateVariants({ platform, voice, style, mood, facts, nsfw });
+    let ranked = await rankAndSelect(variants);
+    let out = ranked.final;
+
+    const err = platformChecks(platform, out);
+    if (err) {
+      variants = await generateVariants({ platform, voice, facts, hint:`Fix: ${err}. Use IMAGE_FACTS nouns/colors/setting explicitly.`, nsfw });
+      ranked = await rankAndSelect(variants);
+      out = ranked.final;
+    }
+
+    return { provider: 'gemini', facts, variants, ranked, final: out };
+  } catch (error) {
+    const { openAICaptionFallback } = await import('./openaiFallback');
+    const final = await openAICaptionFallback({ platform, voice, imageUrl });
+    return { provider: 'openai', final } as any;
+  }
 }
diff --git a/server/caption/openaiFallback.ts b/server/caption/openaiFallback.ts
new file mode 100644
index 0000000..463ef6b
--- /dev/null
+++ b/server/caption/openaiFallback.ts
@@ -0,0 +1,48 @@
+import OpenAI from 'openai';
+
+const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY || '' });
+
+export interface FallbackParams {
+  platform: string;
+  voice: string;
+  imageUrl?: string;
+  theme?: string;
+  context?: string;
+  existingCaption?: string;
+}
+
+export async function openAICaptionFallback(params: FallbackParams) {
+  const { platform, voice, imageUrl, theme, context, existingCaption } = params;
+  let prompt = `Generate a social media caption as JSON with fields caption, hashtags, safety_level, mood, style, cta. Platform: ${platform}. Voice: ${voice}.`;
+  if (theme) prompt += ` Theme: ${theme}.`;
+  if (context) prompt += ` Context: ${context}.`;
+  if (existingCaption) prompt += ` Improve this caption: ${existingCaption}`;
+  if (imageUrl) prompt += ` Consider the image at ${imageUrl}.`;
+
+  const response = await openai.chat.completions.create({
+    model: 'gpt-4o',
+    messages: [
+      { role: 'system', content: 'You are a helpful social media assistant.' },
+      { role: 'user', content: prompt }
+    ],
+    response_format: { type: 'json_object' },
+    max_tokens: 500,
+    temperature: 0.8
+  });
+
+  let json: any;
+  try {
+    json = JSON.parse(response.choices[0].message.content || '{}');
+  } catch {
+    json = { caption: response.choices[0].message.content || 'Fallback caption' };
+  }
+
+  return {
+    caption: json.caption || 'Fallback caption',
+    hashtags: json.hashtags || [],
+    safety_level: json.safety_level || 'normal',
+    mood: json.mood || 'neutral',
+    style: json.style || 'fallback',
+    cta: json.cta || ''
+  };
+}
diff --git a/server/caption/rewritePipeline.ts b/server/caption/rewritePipeline.ts
index 4631fe1..c11c1e5 100644
--- a/server/caption/rewritePipeline.ts
+++ b/server/caption/rewritePipeline.ts
@@ -11,20 +11,32 @@ function stripToJSON(txt:string){ const i=Math.min(...[txt.indexOf("{"),txt.index
 export async function extractFacts(imageUrl:string){
   const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("extract.txt");
   const img={ inlineData:{ data: await b64(imageUrl), mimeType:"image/jpeg" } };
-  const res=await visionModel.generateContent([{text:sys+"\n"+guard+"\n"+prompt}, img]);
-  return stripToJSON(res.response.text());
+  try {
+    const res=await visionModel.generateContent([{text:sys+"\n"+guard+"\n"+prompt}, img]);
+    return stripToJSON(res.response.text());
+  } catch (error) {
+    console.error('Gemini visionModel.generateContent failed:', error);
+    throw error;
+  }
 }
 
 export async function variantsRewrite(params:{platform:"instagram"|"x"|"reddit"|"tiktok", voice:string, style?:string, mood?:string, existingCaption:string, facts?:any, hint?:string, nsfw?:boolean}){
   const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("rewrite.txt");
   const user=`PLATFORM: ${params.platform}\nVOICE: ${params.voice}\n${params.style ? `STYLE: ${params.style}\n` : ''}${params.mood ? `MOOD: ${params.mood}\n` : ''}EXISTING_CAPTION: "${params.existingCaption}"${params.facts?`\nIMAGE_FACTS: ${JSON.stringify(params.facts)}`:""}\nNSFW: ${params.nsfw || false}${params.hint?`\nHINT:${params.hint}`:""}`;
-  const res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+user }]);
+  let res;
+  try {
+    res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+user }]);
+  } catch (error) {
+    console.error('Gemini textModel.generateContent failed:', error);
+    throw error;
+  }
   const json=stripToJSON(res.response.text());
   // Fix common safety_level values and missing fields
   if(Array.isArray(json)){
     json.forEach((item:any)=>{
-      // Accept any safety_level from AI
-      if(!item.safety_level) item.safety_level="suggestive";
+      // Accept any safety_level from AI but normalize "suggestive"
+      if(!item.safety_level) item.safety_level="suggestive";
+      else if(item.safety_level === 'suggestive') item.safety_level = 'spicy_safe';
       // Fix other fields
       if(!item.mood || item.mood.length<2) item.mood="engaging";
       if(!item.style || item.style.length<2) item.style="authentic";
@@ -59,7 +71,13 @@ export async function variantsRewrite(params:{platform:"instagram"|"x"|"reddit"|"
 
 export async function rankAndSelect(variants:any){
   const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("rank.txt");
-  const res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+JSON.stringify(variants) }]);
+  let res;
+  try {
+    res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+JSON.stringify(variants) }]);
+  } catch (error) {
+    console.error('Gemini textModel.generateContent failed:', error);
+    throw error;
+  }
   let json=stripToJSON(res.response.text());
 
   // Handle case where AI returns array instead of ranking object
@@ -88,22 +106,28 @@ export async function rankAndSelect(variants:any){
 
 export async function pipelineRewrite({ platform, voice="flirty_playful", style, mood, existingCaption, imageUrl, nsfw=false }:{
   platform:"instagram"|"x"|"reddit"|"tiktok", voice?:string, style?:string, mood?:string, existingCaption:string, imageUrl?:string, nsfw?:boolean }){
-  let facts = imageUrl ? await extractFacts(imageUrl) : undefined;
-  let variants = await variantsRewrite({ platform, voice, style, mood, existingCaption, facts, nsfw });
-  let ranked = await rankAndSelect(variants);
-  let out = ranked.final;
-
-  // Ensure rewritten caption is longer and more engaging than original
-  if(out.caption.length <= existingCaption.length) {
-    out.caption = existingCaption + " ✨ Enhanced with engaging content and call-to-action that drives better engagement!";
-  }
-
-  const err = platformChecks(platform, out);
-  if (err) {
-    variants = await variantsRewrite({ platform, voice, existingCaption, facts, hint:`Fix: ${err}. Be specific and engaging.`, nsfw });
-    ranked = await rankAndSelect(variants);
-    out = ranked.final;
-  }
-
-  return { facts, variants, ranked, final: out };
+  try {
+    let facts = imageUrl ? await extractFacts(imageUrl) : undefined;
+    let variants = await variantsRewrite({ platform, voice, style, mood, existingCaption, facts, nsfw });
+    let ranked = await rankAndSelect(variants);
+    let out = ranked.final;
+
+    // Ensure rewritten caption is longer and more engaging than original
+    if(out.caption.length <= existingCaption.length) {
+      out.caption = existingCaption + " ✨ Enhanced with engaging content and call-to-action that drives better engagement!";
+    }
+
+    const err = platformChecks(platform, out);
+    if (err) {
+      variants = await variantsRewrite({ platform, voice, existingCaption, facts, hint:`Fix: ${err}. Be specific and engaging.`, nsfw });
+      ranked = await rankAndSelect(variants);
+      out = ranked.final;
+    }
+
+    return { provider: 'gemini', facts, variants, ranked, final: out };
+  } catch (error) {
+    const { openAICaptionFallback } = await import('./openaiFallback');
+    const final = await openAICaptionFallback({ platform, voice, existingCaption, imageUrl });
+    return { provider: 'openai', final } as any;
+  }
 }
diff --git a/server/caption/textOnlyPipeline.ts b/server/caption/textOnlyPipeline.ts
index d1f1191..8afaaf7 100644
--- a/server/caption/textOnlyPipeline.ts
+++ b/server/caption/textOnlyPipeline.ts
@@ -10,13 +10,20 @@ function stripToJSON(txt:string){ const i=Math.min(...[txt.indexOf("{"),txt.index
 export async function generateVariantsTextOnly(params:{platform:"instagram"|"x"|"reddit"|"tiktok", voice:string, style?:string, mood?:string, theme:string, context?:string, hint?:string, nsfw?:boolean}){
   const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("variants_textonly.txt");
   const user=`PLATFORM: ${params.platform}\nVOICE: ${params.voice}\n${params.style ? `STYLE: ${params.style}\n` : ''}${params.mood ? `MOOD: ${params.mood}\n` : ''}THEME: "${params.theme}"\nCONTEXT: "${params.context||''}"\nNSFW: ${params.nsfw || false}${params.hint?`\nHINT:${params.hint}`:""}`;
-  const res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+user }]);
+  let res;
+  try {
+    res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+user }]);
+  } catch (error) {
+    console.error('Gemini textModel.generateContent failed:', error);
+    throw error;
+  }
   const json=stripToJSON(res.response.text());
   // Fix common safety_level values and missing fields
   if(Array.isArray(json)){
     json.forEach((item:any)=>{
-      // Accept any safety_level from AI
-      if(!item.safety_level) item.safety_level="suggestive";
+      // Accept any safety_level from AI but normalize "suggestive"
+      if(!item.safety_level) item.safety_level="suggestive";
+      else if(item.safety_level === 'suggestive') item.safety_level = 'spicy_safe';
       // Fix other fields
       if(!item.mood || item.mood.length<2) item.mood="engaging";
       if(!item.style || item.style.length<2) item.style="authentic";
@@ -57,7 +64,13 @@ export async function generateVariantsTextOnly(params:{platform:"instagram"|"x"|
 
 export async function rankAndSelect(variants:any, params?: { platform?: string, nsfw?: boolean }){
   const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("rank.txt");
-  const res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+JSON.stringify(variants) }]);
+  let res;
+  try {
+    res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+JSON.stringify(variants) }]);
+  } catch (error) {
+    console.error('Gemini textModel.generateContent failed:', error);
+    throw error;
+  }
   let json=stripToJSON(res.response.text());
 
   // Handle case where AI returns array instead of ranking object
@@ -93,16 +106,22 @@ export async function rankAndSelect(variants:any, params?: { platform?: string,
 
 export async function pipelineTextOnly({ platform, voice="flirty_playful", style, mood, theme, context, nsfw=false }:{
   platform:"instagram"|"x"|"reddit"|"tiktok", voice?:string, style?:string, mood?:string, theme:string, context?:string, nsfw?:boolean }){
-  let variants = await generateVariantsTextOnly({ platform, voice, style, mood, theme, context, nsfw });
-  let ranked = await rankAndSelect(variants, { platform, nsfw });
-  let out = ranked.final;
-
-  const err = platformChecks(platform, out);
-  if (err) {
-    variants = await generateVariantsTextOnly({ platform, voice, theme, context, hint:`Fix: ${err}. Be specific and engaging.`, nsfw });
-    ranked = await rankAndSelect(variants);
-    out = ranked.final;
-  }
-
-  return { variants, ranked, final: out };
+  try {
+    let variants = await generateVariantsTextOnly({ platform, voice, style, mood, theme, context, nsfw });
+    let ranked = await rankAndSelect(variants, { platform, nsfw });
+    let out = ranked.final;
+
+    const err = platformChecks(platform, out);
+    if (err) {
+      variants = await generateVariantsTextOnly({ platform, voice, theme, context, hint:`Fix: ${err}. Be specific and engaging.`, nsfw });
+      ranked = await rankAndSelect(variants);
+      out = ranked.final;
+    }
+
+    return { provider: 'gemini', variants, ranked, final: out };
+  } catch (error) {
+    const { openAICaptionFallback } = await import('./openaiFallback');
+    const final = await openAICaptionFallback({ platform, voice, theme, context });
+    return { provider: 'openai', final } as any;
+  }
 }
diff --git a/tests/routes/caption-generation.test.ts b/tests/routes/caption-generation.test.ts
index a2563ab..6cc7038 100644
--- a/tests/routes/caption-generation.test.ts
+++ b/tests/routes/caption-generation.test.ts
@@ -1,8 +1,12 @@
 import { describe, it, expect, beforeEach, vi } from 'vitest';
 import { storage } from '../../server/storage.js';
-import { pipeline } from '../../server/caption/geminiPipeline.js';
-import { pipelineRewrite } from '../../server/caption/rewritePipeline.js';
-import { pipelineTextOnly } from '../../server/caption/textOnlyPipeline.js';
+
+const openaiCreateMock = vi.fn();
+vi.mock('openai', () => ({
+  default: vi.fn().mockImplementation(() => ({
+    chat: { completions: { create: openaiCreateMock } }
+  }))
+}));
 
 // Mock dependencies
 vi.mock('../../server/lib/gemini.js', () => ({
@@ -28,75 +32,6 @@ describe('Caption Generation', () => {
   });
 
   describe('Gemini Pipeline', () => {
-    it('should handle image-based caption generation', async () => {
-      const mockImageUrl = 'data:image/jpeg;base64,abc123';
-      const mockPlatform = 'instagram';
-      const mockVoice = 'flirty_playful';
-
-      // Mock successful responses
-      const mockFactsResponse = {
-        response: {
-          text: () => JSON.stringify({
-            objects: ['woman', 'lingerie'],
-            setting: 'bedroom',
-            mood: 'seductive',
-          }),
-        },
-      };
-
-      const mockVariantsResponse = {
-        response: {
-          text: () => JSON.stringify([
-            {
-              caption: 'Feeling gorgeous tonight ✨',
-              hashtags: ['#lingerie', '#confidence'],
-              safety_level: 'spicy_safe',
-              mood: 'confident',
-              style: 'authentic',
-              cta: 'What do you think?',
-            },
-          ]),
-        },
-      };
-
-      const mockRankResponse = {
-        response: {
-          text: () => JSON.stringify({
-            final: {
-              caption: 'Feeling gorgeous tonight ✨',
-              hashtags: ['#lingerie', '#confidence'],
-              safety_level: 'spicy_safe',
-              mood: 'confident',
-              style: 'authentic',
-              cta: 'What do you think?',
-            },
-          }),
-        },
-      };
-
-      const { textModel, visionModel } = await import('../../server/lib/gemini.js');
-      visionModel.generateContent.mockResolvedValueOnce(mockFactsResponse);
-      textModel.generateContent
-        .mockResolvedValueOnce(mockVariantsResponse)
-        .mockResolvedValueOnce(mockRankResponse);
-
-      const result = await pipeline({
-        imageUrl: mockImageUrl,
-        platform: mockPlatform,
-        voice: mockVoice,
-      });
-
-      expect(result).toMatchObject({
-        facts: expect.objectContaining({
-          objects: expect.arrayContaining(['woman', 'lingerie']),
-        }),
-        final: expect.objectContaining({
-          caption: expect.stringContaining('gorgeous'),
-          safety_level: 'spicy_safe',
-        }),
-      });
-    });
-
     it('should handle safety level normalization', async () => {
       const mockResponse = {
         response: {
@@ -126,6 +61,27 @@ describe('Caption Generation', () => {
 
       expect(result[0].safety_level).toBe('spicy_safe');
     });
+
+    it('should fallback to OpenAI when Gemini fails', async () => {
+      const { pipeline } = await import('../../server/caption/geminiPipeline.js');
+      const { visionModel } = await import('../../server/lib/gemini.js');
+      visionModel.generateContent.mockRejectedValueOnce(new Error('Gemini failed'));
+
+      openaiCreateMock.mockResolvedValueOnce({
+        choices: [
+          { message: { content: JSON.stringify({ caption: 'Fallback caption', hashtags: ['#fallback'], safety_level: 'normal', mood: 'neutral', style: 'fallback', cta: 'none' }) } }
+        ]
+      });
+
+      const result = await pipeline({
+        imageUrl: 'data:image/jpeg;base64,' + 'a'.repeat(120),
+        platform: 'instagram',
+        voice: 'flirty_playful',
+      });
+
+      expect(result.provider).toBe('openai');
+      expect(result.final.caption).toBe('Fallback caption');
+    });
   });
 
   describe('Text-Only Pipeline', () => {
@@ -148,6 +104,7 @@ describe('Caption Generation', () => {
       const { textModel } = await import('../../server/lib/gemini.js');
       textModel.generateContent.mockResolvedValue(mockResponse);
 
+      const { pipelineTextOnly } = await import('../../server/caption/textOnlyPipeline.js');
       const result = await pipelineTextOnly({
         platform: 'instagram',
         voice: 'inspiring',
@@ -155,6 +112,7 @@ describe('Caption Generation', () => {
         context: 'morning motivation post',
       });
 
+      expect(result.provider).toBe('gemini');
       expect(result.final).toMatchObject({
         caption: expect.stringContaining('Motivational'),
         safety_level: 'normal',
@@ -183,12 +141,14 @@ describe('Caption Generation', () => {
       const { textModel } = await import('../../server/lib/gemini.js');
       textModel.generateContent.mockResolvedValue(mockResponse);
 
+      const { pipelineRewrite } = await import('../../server/caption/rewritePipeline.js');
       const result = await pipelineRewrite({
         platform: 'instagram',
         voice: 'engaging',
         existingCaption,
       });
 
+      expect(result.provider).toBe('gemini');
       expect(result.final.caption).not.toBe(existingCaption);
       expect(result.final.caption).toContain('Enhanced');
     });
