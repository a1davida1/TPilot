diff --git a/server/lib/worker-scaler.ts b/server/lib/worker-scaler.ts
index cda1083731da19e1da285f6ec328d719ecfd1b67..2f6022e3faa59c6aa8461e9a9c244a6b29b485c3 100644
--- a/server/lib/worker-scaler.ts
+++ b/server/lib/worker-scaler.ts
@@ -1,27 +1,28 @@
 import { queueMonitor } from "./queue-monitor.js";
 import { QUEUE_NAMES } from "./queue/index.js";
+import { logger } from "../middleware/security.js";
 
 export interface ScalingConfig {
   minConcurrency: number;
   maxConcurrency: number;
   scaleUpThreshold: number; // pending jobs threshold
   scaleDownThreshold: number; // time in ms with low activity
   cooldownPeriod: number; // time in ms between scaling actions
 }
 
 export interface WorkerScalingState {
   currentConcurrency: number;
   targetConcurrency: number;
   lastScalingAction?: Date;
   pendingJobs: number;
   isScaling: boolean;
 }
 
 export class WorkerScaler {
   private static instance: WorkerScaler;
   private scaling = false;
   private intervalId?: NodeJS.Timeout;
   private scalingStates: Map<string, WorkerScalingState> = new Map();
   
   private defaultConfig: ScalingConfig = {
     minConcurrency: 1,
diff --git a/server/lib/worker-scaler.ts b/server/lib/worker-scaler.ts
index cda1083731da19e1da285f6ec328d719ecfd1b67..2f6022e3faa59c6aa8461e9a9c244a6b29b485c3 100644
--- a/server/lib/worker-scaler.ts
+++ b/server/lib/worker-scaler.ts
@@ -42,87 +43,87 @@ export class WorkerScaler {
     },
     [QUEUE_NAMES.AI_PROMO]: {
       maxConcurrency: 2, // AI generation is expensive
       scaleUpThreshold: 5,
     },
     [QUEUE_NAMES.DUNNING]: {
       maxConcurrency: 2, // Payment processing should be conservative
       scaleUpThreshold: 8,
     },
     [QUEUE_NAMES.BATCH_POST]: {
       maxConcurrency: 1, // Always single concurrency for batch posts
       scaleUpThreshold: 999, // Never scale up
     },
   };
 
   public static getInstance(): WorkerScaler {
     if (!WorkerScaler.instance) {
       WorkerScaler.instance = new WorkerScaler();
     }
     return WorkerScaler.instance;
   }
 
   async startScaling(intervalMs: number = 60000) { // Check every minute
     if (this.scaling) return;
 
-    console.log('ðŸ“ˆ Starting worker auto-scaling...');
+    logger.info('ðŸ“ˆ Starting worker auto-scaling...');
     this.scaling = true;
 
     // Initialize scaling states
     for (const queueName of Object.values(QUEUE_NAMES)) {
       this.scalingStates.set(queueName, {
         currentConcurrency: this.getQueueConfig(queueName).minConcurrency,
         targetConcurrency: this.getQueueConfig(queueName).minConcurrency,
         pendingJobs: 0,
         isScaling: false,
       });
     }
 
     // Set up periodic scaling checks
     this.intervalId = setInterval(async () => {
       try {
         await this.performScalingCheck();
       } catch (error) {
-        console.error('Worker scaling error:', error);
+        logger.error('Worker scaling error', { error });
       }
     }, intervalMs);
 
-    console.log(`âœ… Worker auto-scaling started (interval: ${intervalMs}ms)`);
+    logger.info(`âœ… Worker auto-scaling started (interval: ${intervalMs}ms)`);
   }
 
   stopScaling() {
     if (!this.scaling) return;
 
-    console.log('ðŸ›‘ Stopping worker auto-scaling...');
+    logger.info('ðŸ›‘ Stopping worker auto-scaling...');
     this.scaling = false;
 
     if (this.intervalId) {
       clearInterval(this.intervalId);
       this.intervalId = undefined;
     }
 
-    console.log('âœ… Worker auto-scaling stopped');
+    logger.info('âœ… Worker auto-scaling stopped');
   }
 
   private async performScalingCheck() {
     const queueMetrics = queueMonitor.getQueueMetrics();
     const now = new Date();
 
     for (const [queueName, metrics] of Object.entries(queueMetrics)) {
       const config = this.getQueueConfig(queueName);
       const state = this.scalingStates.get(queueName);
       
       if (!state || state.isScaling) continue;
 
       // Check if we're in cooldown period
       if (state.lastScalingAction) {
         const timeSinceLastScaling = now.getTime() - state.lastScalingAction.getTime();
         if (timeSinceLastScaling < config.cooldownPeriod) {
           continue; // Still in cooldown
         }
       }
 
       const shouldScaleUp = this.shouldScaleUp(metrics, config, state);
       const shouldScaleDown = this.shouldScaleDown(metrics, config, state);
 
       if (shouldScaleUp) {
         await this.scaleUp(queueName, config, state);
diff --git a/server/lib/worker-scaler.ts b/server/lib/worker-scaler.ts
index cda1083731da19e1da285f6ec328d719ecfd1b67..2f6022e3faa59c6aa8461e9a9c244a6b29b485c3 100644
--- a/server/lib/worker-scaler.ts
+++ b/server/lib/worker-scaler.ts
@@ -135,110 +136,110 @@ export class WorkerScaler {
     }
   }
 
   private shouldScaleUp(metrics: unknown, config: ScalingConfig, state: WorkerScalingState): boolean {
     return (
       state.currentConcurrency < config.maxConcurrency &&
       metrics.pending >= config.scaleUpThreshold &&
       metrics.healthStatus !== 'critical' // Don't scale up if there are errors
     );
   }
 
   private shouldScaleDown(metrics: unknown, config: ScalingConfig, state: WorkerScalingState): boolean {
     return (
       state.currentConcurrency > config.minConcurrency &&
       metrics.pending < config.scaleUpThreshold / 2 && // Less than half the scale-up threshold
       metrics.active === 0 // No active jobs
     );
   }
 
   private async scaleUp(queueName: string, config: ScalingConfig, state: WorkerScalingState) {
     const newConcurrency = Math.min(
       state.currentConcurrency + 1,
       config.maxConcurrency
     );
 
-    console.log(`ðŸ“ˆ Scaling UP ${queueName}: ${state.currentConcurrency} â†’ ${newConcurrency}`);
+    logger.info(`ðŸ“ˆ Scaling UP ${queueName}: ${state.currentConcurrency} â†’ ${newConcurrency}`);
 
     await this.updateWorkerConcurrency(queueName, newConcurrency);
 
     state.currentConcurrency = newConcurrency;
     state.targetConcurrency = newConcurrency;
     state.lastScalingAction = new Date();
     state.isScaling = false;
   }
 
   private async scaleDown(queueName: string, config: ScalingConfig, state: WorkerScalingState) {
     const newConcurrency = Math.max(
       state.currentConcurrency - 1,
       config.minConcurrency
     );
 
-    console.log(`ðŸ“‰ Scaling DOWN ${queueName}: ${state.currentConcurrency} â†’ ${newConcurrency}`);
+    logger.info(`ðŸ“‰ Scaling DOWN ${queueName}: ${state.currentConcurrency} â†’ ${newConcurrency}`);
 
     await this.updateWorkerConcurrency(queueName, newConcurrency);
 
     state.currentConcurrency = newConcurrency;
     state.targetConcurrency = newConcurrency;
     state.lastScalingAction = new Date();
     state.isScaling = false;
   }
 
   private async updateWorkerConcurrency(queueName: string, newConcurrency: number) {
     try {
       // In a full implementation, this would dynamically adjust worker concurrency
       // For now, log the scaling action
-      console.log(`ðŸ”§ Worker concurrency for ${queueName} set to ${newConcurrency}`);
+      logger.info(`ðŸ”§ Worker concurrency for ${queueName} set to ${newConcurrency}`);
       
       // This would typically:
       // 1. Update the worker's concurrency setting
       // 2. Spawn/terminate worker processes
       // 3. Adjust resource allocation
       
     } catch (error) {
-      console.error(`Failed to update worker concurrency for ${queueName}:`, error);
+      logger.error(`Failed to update worker concurrency for ${queueName}`, { error });
     }
   }
 
   private getQueueConfig(queueName: string): ScalingConfig {
     const customConfig = this.queueConfigs[queueName] || {};
     return { ...this.defaultConfig, ...customConfig };
   }
 
   // Public API
   getScalingStates(): Record<string, WorkerScalingState> {
     const result: Record<string, WorkerScalingState> = {};
     for (const [queueName, state] of this.scalingStates.entries()) {
       result[queueName] = { ...state };
     }
     return result;
   }
 
   async manualScale(queueName: string, targetConcurrency: number): Promise<boolean> {
     const config = this.getQueueConfig(queueName);
     const state = this.scalingStates.get(queueName);
 
     if (!state) return false;
 
     if (targetConcurrency < config.minConcurrency || targetConcurrency > config.maxConcurrency) {
       throw new Error(`Concurrency must be between ${config.minConcurrency} and ${config.maxConcurrency}`);
     }
 
-    console.log(`ðŸŽ¯ Manual scaling ${queueName}: ${state.currentConcurrency} â†’ ${targetConcurrency}`);
+    logger.info(`ðŸŽ¯ Manual scaling ${queueName}: ${state.currentConcurrency} â†’ ${targetConcurrency}`);
 
     await this.updateWorkerConcurrency(queueName, targetConcurrency);
 
     state.currentConcurrency = targetConcurrency;
     state.targetConcurrency = targetConcurrency;
     state.lastScalingAction = new Date();
 
     return true;
   }
 
   updateConfig(queueName: string, config: Partial<ScalingConfig>) {
     this.queueConfigs[queueName] = { ...this.queueConfigs[queueName], ...config };
-    console.log(`ðŸ”§ Updated scaling config for ${queueName}:`, config);
+    logger.info(`ðŸ”§ Updated scaling config for ${queueName}`, { config });
   }
 }
 
 // Export singleton instance
-export const workerScaler = WorkerScaler.getInstance();
+export const workerScaler = WorkerScaler.getInstance();
