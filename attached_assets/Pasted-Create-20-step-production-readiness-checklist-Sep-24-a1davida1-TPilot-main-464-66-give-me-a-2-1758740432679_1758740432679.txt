Create 20-step production readiness checklist
Sep 24 · a1davida1/TPilot · main ·
+464-66
give me a 20 step production readiness checklist with clickable tasks please
Production Readiness Checklist

Provision production environment secrets — Mirror the exhaustive .env.example into your secrets manager (or cloud parameter store) so every required key—from JWT/session secrets and database URLs to AI providers, storage, billing, email, and fraud controls—is available before deployment.

Gate deployments on environment schema checks — Keep validateEnvironment() in the boot path and surface its zod validation failures early in CI/CD so registerRoutes never reaches production with missing secrets or malformed URLs.

Lock down CORS allowlists — Populate ALLOWED_ORIGINS with your real domains so configureCors only permits expected origins while still honoring localhost and Replit shortcuts in non-production modes.

Align proxy trust and secure cookies — Confirm your ingress IP ranges so the custom app.set('trust proxy') logic works correctly, and verify TLS termination because the session cookie is marked secure/HTTP-only with a one-week lifetime in production.

Back sessions with durable storage — Provide either REDIS_URL or DATABASE_URL in production so the session middleware can instantiate Redis or Postgres-backed stores instead of falling back to in-memory sessions.

Apply CSRF protection to sensitive flows — Review the curated list of state-changing endpoints guarded by the CSRF middleware to ensure every browser-based mutation route has coverage and emits meaningful diagnostics on token failures.

Tune rate limiting and API-key enforcement — Calibrate the auth/general/upload/generation limiters and the API-key validator so /api traffic stays within quotas and machine clients understand the allowed formats and retry semantics.

Harden input sanitization and payload ceilings — Confirm the sanitize middleware’s XSS scrubbing, key renaming, and 10 KB truncation thresholds meet your threat model, and extend them if new surfaces are added.

Finalize HTTP hardening middleware — Review Helmet’s CSP directives, HPP allowances, gzip compression, and fallback rate limiter to make sure permitted domains (Stripe, Google, etc.) and development exceptions align with your production posture.

Operationalize error & 404 handling — Ensure Sentry DSNs are wired, cleanup hooks are respected, and response messages remain sanitized while the not-found handler logs IPs, referers, and suggested remediations for support triage.

Ship structured logs to centralized sinks — Leverage the Winston logger’s rotating file transports (combined/error/debug/security/metrics) and console output by forwarding the generated files or streaming stdout/stderr into your observability stack.

Correlate HTTP traffic with request IDs — Propagate the generated X-Request-ID header downstream and ingest the per-request logs emitted by applyRequestLogging so debugging traces can be stitched together across services.

Provision background queue infrastructure & monitoring — Stand up the queue backends needed by startQueue, verify worker scaling and 30 s monitoring intervals, and decide whether to enable or defer queue startup via the CreateAppOptions flags.

Automate database migrations with Drizzle — Feed drizzle.config.ts the production DATABASE_URL and make npm run db:generate / npm run db:migrate part of your release workflow so schema drift cannot reach production.

Codify reproducible production builds — Run build-production.sh in CI to clean dist, compile the server, fix path aliases/imports, copy client artifacts, and gzip assets, yielding a deployable bundle every time.

Standardize production entrypoints — Decide whether operators should invoke npm start, production-start.js, or production-server.js; all of them ensure builds exist, set memory limits, and load the TypeScript server, so document the canonical choice for your process manager.

Guarantee client asset delivery — Confirm the build script’s client/index.html checks and gzip copying work in your pipeline, and validate that configureStaticAssets serves the SPA fallback from the resolved client path in production.

Verify bootstrap resilience on dynamic ports — Align infrastructure expectations with the server bootstrap that retries EADDRINUSE up to three times, logs fallbacks, and exits on persistent binding failures.

Enforce test quality gates — Integrate npm run lint, npm test, npm run test:coverage, and npm run test:e2e into CI so every build proves lint cleanliness, unit coverage, and Playwright regressions before shipping.

Expose health/readiness for orchestration — Wire /api/health into your load balancer probes today and expand it with dependency checks (queues, DB, third parties) as production needs mature.
i dont see start buttons on any of that 
also lets do a few things that mean we can handle multiople users under load please?
Production Readiness Checklist (Load-Hardened)

Provision production secrets & quotas — Mirror every key required by the Zod schema into your secrets manager before deployment.
<details><summary>▶️ Start</summary>

    Export the schema from server/middleware/security.ts and compile a definitive list of required secrets (JWT, session, database, optional Redis/Sentry, etc.).

    Populate these keys in your production secret store (AWS Secrets Manager, Doppler, etc.), including per-provider API quotas so downstream rate limits align with business expectations.

    Enable versioning and audit logging on the secret store to trace future changes.

</details>

Gate CI/CD on environment validation — Block promotions if validateEnvironment() would throw at runtime.
<details><summary>▶️ Start</summary>

    Add a lightweight pipeline job that runs node --loader ts-node/esm -e "import('./server/middleware/security.ts').then(m => m.validateEnvironment())" (or equivalent via tsx) against your production secret scope.

Fail the deployment stage when validation errors surface so registerRoutes never boots with missing config.

    Surface the failing key names in build notifications to shorten incident MTTR.

</details>

Lock down CORS allowlists — Set ALLOWED_ORIGINS for real domains so only sanctioned clients reach Express.
<details><summary>▶️ Start</summary>

    Enumerate production origins (primary domain, marketing microsites, admin tools) and inject them into ALLOWED_ORIGINS as a comma-separated list.

Confirm staging/test entries are removed prior to go-live; rely on the built-in development fallbacks for local testing.

    Add a smoke test that requests a protected endpoint from an unauthorized origin to verify the middleware rejects it.

</details>

Verify ingress trust & secure cookies — Align load balancer IP ranges with app.set('trust proxy') and confirm TLS termination for secure cookies.
<details><summary>▶️ Start</summary>

    Compare your reverse proxy CIDR blocks to the whitelist defined when registerRoutes overrides trust proxy; expand it if you terminate TLS outside those private ranges.

Validate that your ingress terminates HTTPS so the session cookie’s secure flag stays effective in production.

Capture packet traces or use X-Forwarded-For headers in staging to ensure Express resolves the true client IP for rate limiting.
</details>

Back sessions with durable storage — Provision Redis or Postgres session stores and verify failover behavior.
<details><summary>▶️ Start</summary>

    Stand up a managed Redis (preferred for throughput) or Postgres instance and feed its URI into REDIS_URL/DATABASE_URL before enabling production traffic.

Load test simultaneous logins to confirm the store handles rolling refresh, resave: false, and rolling: true semantics without churn.

Configure dashboards/alerts for store connectivity so the boot-time guardrail (throw new Error) doesn’t surprise you mid-deploy.
</details>

Provision queue infrastructure & scaling hooks — Decide on Redis BullMQ vs Postgres queues and ensure monitoring/scaling processes run from day one.
<details><summary>▶️ Start</summary>

    Supply a production-ready REDIS_URL (or explicitly set USE_PG_QUEUE) so getQueueBackend() stabilizes on a single backend at boot.

Validate that startQueue() successfully initializes queues, workers, monitoring, and auto-scaling during app startup; surface failures in deployment logs.

Document operational runbooks for pausing/resuming queues and gracefully closing them with closeQueue() during maintenance windows.
</details>

Calibrate rate limiting for multi-tenant load — Tune the limiter thresholds and shard them by plan so legitimate bursts aren’t throttled.
<details><summary>▶️ Start</summary>

    Analyze expected RPS per tenant tier, then adjust max and windowMs for authLimiter, generalLimiter, uploadLimiter, and generationLimiter to reflect reality.

Introduce tier-aware overrides (e.g., based on session metadata) before invoking generalLimiter so premium plans sustain heavier bursts under load.

    Instrument limiter hit ratios and feed them into dashboards to detect hot spots that need higher ceilings.

</details>

Enforce API key policy for integrations — Harden the API-key middleware so partner traffic authenticates separately from browser sessions.
<details><summary>▶️ Start</summary>

    Populate a hashed API-key registry (database or secrets manager) and extend validateApiKey to reject unknown keys instead of only format mismatches.

Expand publicEndpoints intentionally; ensure new mutation routes require keys even for non-session clients.

Emit structured security logs for invalid keys (including req.userIP) and alert on spikes that may indicate abuse.
</details>

Harden sanitization & payload ceilings — Confirm anti-XSS scrubbing and 10 KB truncation cover new request shapes.
<details><summary>▶️ Start</summary>

    Review new API payloads and update sanitizeObject to include additional keywords/patterns that surfaced in recent pentests.

Add regression tests that submit malicious payloads to guarantee mongo-sanitize hooks still fire and log offending keys.

    Document acceptable payload limits for clients so they handle truncation gracefully.

</details>

Apply Helmet/HPP/compression baselines — Keep the CSP allowlist and HTTP hardening middleware aligned with your third-party dependencies.
<details><summary>▶️ Start</summary>

    Audit every external script/style host (Stripe, Google, analytics) and refresh the CSP arrays accordingly before launch.

Validate new media/CDN endpoints are added to imgSrc, mediaSrc, or connectSrc to avoid runtime CSP violations.

Confirm compression and HPP don’t clash with upstream proxies (disable double-compression if your ingress already gzips responses).
</details>

Operationalize log shipping — Forward Winston’s rotated files and console stream into your centralized logging stack.
<details><summary>▶️ Start</summary>

    Create filebeat/Fluent Bit collectors that tail logs/combined-current.log, error-current.log, security-current.log, and metrics-current.log generated by the rotating transports.

Wire structured parsing rules that preserve requestId and log level for distributed tracing.

Add retention policies consistent with your compliance requirements (e.g., 30-day security logs, 7-day metrics).
</details>

Propagate request IDs end-to-end — Ensure downstream services and logs align on the UUID assigned per request.
<details><summary>▶️ Start</summary>

    Capture the X-Request-ID header in frontend/API clients and echo it in outbound calls for cross-service correlation.

Confirm the response logger keeps redacting and truncating payloads so sensitive data doesn’t leak when you ingest logs centrally.

    Update alert templates to include request IDs, enabling rapid drill-down across systems.

</details>

Validate static asset pipeline & SPA fallback — Guarantee gzip’d client bundles are built and served before traffic shifts.
<details><summary>▶️ Start</summary>

    Run build-production.sh in CI to pre-warm dist/client and avoid the runtime 404 handler that triggers when index.html is missing.

Configure CDN caching and MIME overrides in line with the setHeaders logic (JS as application/javascript, CSS as text/css).

Smoke test SPA routes behind your CDN to ensure the fallback app.get('*') serves index.html for non-API paths.
</details>

Document the production entrypoint — Standardize how operators launch the server so builds and memory flags stay consistent.
<details><summary>▶️ Start</summary>

    Decide whether to invoke production-server.js directly (which enforces builds and sets NODE_OPTIONS) or wrap it in your process manager (PM2/Systemd).

If you need multi-core support, wrap this entry in a cluster/PM2 ecosystem file because the script currently spawns a single Node process.

    Record restart procedures, environment expectations, and log locations in your runbook.

</details>

Expand health/readiness coverage — Extend /api/health to verify queues, database connectivity, and third-party dependencies.
<details><summary>▶️ Start</summary>

    Add async checks for Postgres/Redis (e.g., pool.query('SELECT 1')) and queue status (via checkQueueHealth()) before responding status: 'ok'.

    Differentiate readiness vs. liveness responses so orchestrators stop routing traffic during dependency outages.

    Integrate the expanded endpoint with load balancer probes and set alert thresholds for non-200 responses.

</details>

Guarantee CSRF & error observability — Keep sensitive endpoints behind CSRF tokens and route operational errors to Sentry with context.
<details><summary>▶️ Start</summary>

    Audit all state-changing routes to ensure they reside in the CSRF-protected block and provide descriptive messages on failure.

Verify Sentry DSN availability so non-operational errors captured in errorHandler surface with endpoint tags for incident triage.

Add synthetic tests that submit invalid tokens to confirm logging captures IP, user agent, and session state for forensics.
</details>

Stabilize AI content generation under load — Monitor the circuit breakers and persistence path to ensure throughput scales with user demand.
<details><summary>▶️ Start</summary>

    Instrument breaker trip counts and latencies from generateContentBreaker/unifiedBreaker to detect upstream AI provider degradation early.

Confirm storage.createContentGeneration writes asynchronously won’t become a bottleneck at high RPS; consider batching or queueing heavy writes under peak load.

    Pre-warm cache layers or result reuse strategies for repeat prompts to save API spend and protect rate limits.

</details>

Operationalize queue monitoring & auto-scaling — Wire the monitoring feed into observability and replace placeholder concurrency updates with real worker orchestration.
<details><summary>▶️ Start</summary>

    Export queue metrics (pending, failureRate, throughput) into Prometheus/Grafana by exposing them via HTTP or pushing to your metrics bus.

Replace the TODO logging in updateWorkerConcurrency with hooks that resize worker pools (spawn processes, adjust BullMQ concurrency) so scaling actions materially increase throughput.

Tweak per-queue configs (max concurrency, thresholds) based on observed workload, especially for AI and metrics queues that will see heavy multi-user traffic.
</details>

Tune database pool capacity & failover — Configure Postgres/Neon pooling parameters for concurrent users and codify shutdown procedures.
<details><summary>▶️ Start</summary>

    Adjust Neon/Postgres pool sizes and timeouts via environment variables (e.g., PGPOOLSIZE) so the shared pool can satisfy peak concurrent sessions without thrashing.

Implement retry/backoff around transient connection failures and document how to call closeDatabaseConnections() during deployments.

    Monitor pool saturation metrics (wait counts, connection age) to catch leaks early.

</details>

Enforce build/test quality gates — Require clean builds, lint, and tests before any production deploy.
<details><summary>▶️ Start</summary>

    Add CI jobs for npm run build, npm run lint, npm test, npm run test:coverage, and npm run test:e2e using the scripts already defined in package.json.

        Fail the pipeline when coverage or lint regress, and publish Vitest/Playwright artifacts for debugging.

        Schedule nightly runs of the end-to-end suite under load (e.g., k6/Playwright concurrency) to validate multi-user scenarios remain green.
    </details>

which of these can you help with?

Below is a detailed, code-oriented breakdown of the 20 production-readiness checklist items, highlighting exactly where and how I can assist inside this repository. You can copy‑paste these notes into another agent (or Replit) to execute the work step by step.

    Provision production environment secrets
    • Review server/middleware/security.ts to confirm the Zod schema covers every required secret.
    • Update .env.example (and any docs/ guidance) to mirror the schema.
    • Script a validation utility or CI check to ensure real secrets match the schema.
    ✅ I can audit the schema, expand .env.example, and add TypeScript-based validators or scripts to enforce compliance.

    Gate deployments on environment schema checks
    • Embed a CI step (e.g., in GitHub Actions or the project’s scripts/) that calls validateEnvironment() from server/middleware/security.ts.
    • Ensure the pipeline fails fast if validation throws.
    ✅ I can add the Node/ts-node command and documentation or config needed to wire this into CI, plus update the repo’s DEPLOYMENT.md.

    Lock down CORS allowlists
    • Modify server/configureCors.ts (or the relevant Express setup) to require ALLOWED_ORIGINS.
    • Adjust config so production enforces a strict list while development retains sensible defaults.
    ✅ I can implement the stricter logic and provide configuration examples.

    Align proxy trust and secure cookies
    • Inspect server/app.ts or server/createApp.ts for app.set('trust proxy').
    • Parameterize the trusted proxy ranges via env vars or config constants.
    • Confirm session cookie options (secure, sameSite, etc.) in the session middleware.
    ✅ I can enhance the configuration and expose tunables for ingress topologies.

    Back sessions with durable storage
    • Verify session setup in server/middleware/session.ts (or equivalent) and confirm it toggles between Redis/Postgres drivers based on env variables.
    • Implement fallback/error handling so missing REDIS_URL or DATABASE_URL fails loudly in production.
    ✅ I can refactor the session middleware and add initialization tests.

    Apply CSRF protection to sensitive flows
    • Examine server/middleware/csrf.ts and the route-registration pipeline.
    • Ensure every state-changing route lives behind the CSRF guard or provide utilities to opt in/out safely.
    ✅ I can audit route files under server/routes/, extend CSRF coverage, and document integration patterns.

    Tune rate limiting and API-key enforcement
    • Update limiters in server/middleware/rateLimiters.ts (or similar) with tier-specific overrides.
    • Expand server/middleware/apiKey.ts to validate real keys (e.g., hashed in DB or config).
    ✅ I can modify these middlewares, add helper utilities, and write regression tests.

    Harden input sanitization and payload ceilings
    • Inspect sanitization logic (server/middleware/sanitize.ts) for XSS protection and payload truncation.
    • Extend it to cover new API payloads or adjust thresholds.
    ✅ I can extend sanitization utilities and add targeted tests.

    Finalize HTTP hardening middleware
    • Review Helmet/HPP/compression setup (likely in server/middleware/securityHeaders.ts).
    • Update Content Security Policy arrays for current third-party domains.
    ✅ I can adjust the configuration objects, add comments, and ensure TypeScript types remain strict.

    Operationalize error & 404 handling
    • Confirm server/middleware/errorHandler.ts sends sanitized responses and logs via Winston.
    • Ensure 404 handler logs request context without leaking secrets.
    ✅ I can refactor handlers, improve logging metadata, and update tests.

    Ship structured logs to centralized sinks
    • Inspect server/utils/logger.ts (or shared/logger.ts).
    • Add transport hooks (e.g., rotate files, forward to stdout, or expose structured metadata).
    ✅ I can configure Winston transports, annotate log formats, and document integration steps.

    Correlate HTTP traffic with request IDs
    • Check middleware that assigns X-Request-ID (likely applyRequestLogging).
    • Ensure the ID is inserted into context, logger metadata, and downstream service calls.
    ✅ I can enhance the middleware and propagate IDs through request/response cycles.

    Provision background queue infrastructure & monitoring
    • Explore server/queues/ for BullMQ/Postgres queue setup (startQueue, closeQueue, etc.).
    • Wire instrumentation or environment toggles so queues can be enabled/disabled per env.
    ✅ I can implement missing queue initialization logic, add monitoring hooks, and expose health endpoints.

    Automate database migrations with Drizzle
    • Verify drizzle.config.ts and scripts/ around npm run db:generate/db:migrate.
    • Provide CLI wrappers or CI steps to run migrations automatically.
    ✅ I can script the commands, ensure TypeScript typings for schema changes, and document the process.

    Codify reproducible production builds
    • Inspect build-production.sh, production-start.js, and production-server.js.
    • Ensure the script cleans dist, builds server/client, copies assets, and gzips outputs.
    ✅ I can harden the script, add error handling, and align the Node entrypoints.

    Standardize production entrypoints
    • Decide on the canonical start command (npm start, production-start.js, or production-server.js).
    • Update documentation (DEPLOYMENT.md, README.md) and maybe add a scripts/start-production.sh.
    ✅ I can rationalize the entrypoints, refactor duplication, and document the official run command.

    Guarantee client asset delivery
    • Confirm client/index.html and built assets end up in dist/client.
    • Verify Express static serving fallback logic (configureStaticAssets).
    ✅ I can adjust build paths, integrate gzip copies, and add sanity checks/tests.

    Verify bootstrap resilience on dynamic ports
    • Review server/index.ts or whichever file binds HTTP ports.
    • Ensure the retry logic around EADDRINUSE and add configurable max retries/backoff.
    ✅ I can inspect and reinforce the port-binding logic with configuration knobs.

    Enforce test quality gates
    • Align package.json scripts: npm run lint, npm test, npm run test:coverage, npm run test:e2e.
    • Add CI pipeline configuration or documentation emphasizing these gates.
    ✅ I can validate scripts, fix failing tests/lint rules, and author CI config or docs.

    Expose health/readiness for orchestration
    • Expand /api/health route (likely server/routes/health.ts) to check DB, queues, third-party services.
    • Distinguish liveness vs readiness responses.
    ✅ I can add the checks, refactor route handlers, and write integration tests.

Summary: I can directly implement or refactor the codebase for every checklist item that involves TypeScript, Express middleware, queue/database scripts, build tooling, or documentation updates inside this repo. For external infrastructure (e.g., configuring AWS, provisioning Redis instances, or setting cloud secrets), I can only provide instructions and scripts; the actual cloud changes must be done outside this container.
start doing these or teaching me how one at a time

Summary

    Reorganized .env.example into production-focused sections, capturing core runtime, security secrets, infrastructure backends, third-party services, and QA/testing keys.

Authored docs/runbooks/secret-provisioning-checklist.md with a 14-step, checkbox-driven guide for provisioning and validating every environment secret category ahead of production load.

Added scripts/audit-env.ts and exposed an npm run env:audit script to automatically compare code-used keys against .env.example, flag duplicates, and keep documentation in sync.

Testing

    ✅ npm run env:audit

✅ npm run lint (exits with existing warnings across the repo)

⚠️ npm test (fails across many pre-existing suites that require unavailable external services/assets; run interrupted after repeated failures)


.env.example
+90-66
# Environment
# Environment & Networking
NODE_ENV=development
PORT=5000
APP_BASE_URL=http://localhost:5000
FRONTEND_URL=http://localhost:3000
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5000
CRON_TZ=America/Chicago
DEFAULT_SYNC_SUBREDDITS=nsfw,lingerie,thighhighs

# Deployment Metadata (auto-populated in CI/CD but documented for completeness)
GIT_COMMIT_SHA=
NODE_OPTIONS=--max-old-space-size=4096
REPLIT_DEPLOYMENT=0
REPLIT_DOMAINS=your-domain.com,www.your-domain.com
REPL_ID=
CI=false

# Security Secrets (REQUIRED)
JWT_SECRET=your_jwt_secret_32_characters_minimum
SESSION_SECRET=your_session_secret_32_characters_minimum
TURNSTILE_SITE_KEY=your_turnstile_site_key
TURNSTILE_SECRET_KEY=your_turnstile_secret_key

# Database
# Database Connectivity
DATABASE_URL=postgresql://user:password@localhost:5432/thottopilot
NEON_DATABASE_URL=
TEST_DATABASE_URL=postgresql://user:password@localhost:5432/thottopilot_test

# Reddit API (Optional for development)
REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_client_secret  
REDDIT_REDIRECT_URI=http://localhost:5000/auth/reddit/callback

# AI APIs (Gemini primary, OpenAI fallback)
GOOGLE_GENAI_API_KEY=your_google_genai_api_key
GEMINI_API_KEY=your_gemini_api_key
OPENAI_API_KEY=your_openai_api_key
# Cache & Queue Backends
REDIS_URL=redis://localhost:6379
USE_PG_QUEUE=true

# AWS S3 (Optional for development)
# Object Storage (S3-compatible)
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-1
S3_BUCKET_MEDIA=your-media-bucket
S3_PUBLIC_CDN_DOMAIN=https://your-cdn.example.com
PRIVATE_OBJECT_DIR=

# Redis (Optional - improves queue performance)
REDIS_URL=redis://localhost:6379

# App Configuration
APP_BASE_URL=http://localhost:5000
CRON_TZ=America/Chicago

# Billing - CCBill (Optional for development)
CCBILL_CLIENT_ACCOUNT=your_ccbill_client_account
CCBILL_SUBACCOUNT=your_ccbill_subaccount
CCBILL_FLEXFORM_ID=your_ccbill_flexform_id
CCBILL_SALT=your_ccbill_salt

# Media Configuration
# Application Feature Flags & Limits
ENABLE_VITE_DEV=false
PLAN_STORAGE_BYTES_FREE=2147483648
PLAN_STORAGE_BYTES_STARTER=10737418240
PLAN_STORAGE_BYTES_PRO=53687091200
MEDIA_SIGNED_TTL_SECONDS=900
MEDIA_MAX_BYTES_FREE=524288000
MEDIA_MAX_BYTES_PRO=10737418240
WATERMARK_ENABLED=true
WATERMARK_TEXT=ThottoPilot
WATERMARK_OPACITY=0.18
MEDIA_MAX_BYTES_FREE=524288000
MEDIA_MAX_BYTES_PRO=10737418240

# Queue Configuration
USE_PG_QUEUE=true

# Rate Limiting
MAX_POSTS_PER_SUBREDDIT_24H=1

# Daily Generation Limits by Tier
DAILY_GENERATIONS_FREE=5
DAILY_GENERATIONS_STARTER=50
DAILY_GENERATIONS_PRO=-1

# Admin & Operational Accounts
ADMIN_EMAIL=admin@yourdomain.com
ADMIN_PASSWORD=changeme
ADMIN_PASSWORD_HASH=
ADMIN_USERNAME=admin
ADMIN_EMAIL_WHITELIST=admin@example.com,admin2@example.com

# Email Service (choose one provider)
FROM_EMAIL=noreply@yourdomain.com
RESEND_API_KEY=your_resend_api_key
SENDGRID_API_KEY=your_sendgrid_api_key

# Billing - Stripe
STRIPE_SECRET_KEY=sk_test_your_stripe_secret_key
STRIPE_PUBLISHABLE_KEY=pk_test_your_stripe_publishable_key
STRIPE_API_VERSION=2023-10-16
STRIPE_WEBHOOK_SECRET=whsec_your_webhook_secret
STRIPE_PRICE_STARTER=
STRIPE_PRICE_PRO_29=
STRIPE_PRICE_PRO_39=
STRIPE_PRICE_PRO_49=
VITE_STRIPE_PUBLIC_KEY=pk_test_your_stripe_public_key

# Billing - CCBill (Optional)
CCBILL_CLIENT_ACCOUNT=your_ccbill_client_account
CCBILL_SUBACCOUNT=your_ccbill_subaccount
CCBILL_FLEXFORM_ID=your_ccbill_flexform_id
CCBILL_SALT=your_ccbill_salt
CCBILL_ACCOUNT_NUMBER=

# Additional Payment Providers (Optional)
SEGPAY_MERCHANT_ID=your_segpay_merchant_id
SEGPAY_API_KEY=your_segpay_api_key
EPOCH_MERCHANT_ID=your_epoch_merchant_id
EPOCH_API_KEY=your_epoch_api_key
PAXUM_API_KEY=your_paxum_api_key
COINBASE_COMMERCE_KEY=your_coinbase_commerce_key

# Email Service (Choose one)
FROM_EMAIL=noreply@yourdomain.com
RESEND_API_KEY=your_resend_api_key
SENDGRID_API_KEY=your_sendgrid_api_key

# Anti-Bot Protection (Turnstile)
TURNSTILE_SITE_KEY=your_turnstile_site_key
TURNSTILE_SECRET_KEY=your_turnstile_secret_key
# AI & Content Generation Providers
GOOGLE_GENAI_API_KEY=your_google_genai_api_key
GEMINI_API_KEY=your_gemini_api_key
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
HF_API_KEY=your_hugging_face_api_key
ML_SAFETY_URL=https://ml.thottopilot.com

# Analytics
# Analytics & Monitoring
ANALYTICS_WRITE_KEY=your_analytics_write_key

# UTM Configuration
UTM_COOKIE_TTL_DAYS=30

# Admin Configuration
ADMIN_EMAIL_WHITELIST=admin@example.com,admin2@example.com

# Error Tracking (Optional)
SENTRY_DSN=your_sentry_dsn
SENTRY_SAMPLE_RATE=0.2

# Logging Enhancements
MAXMIND_DB_PATH=/var/thottopilot/GeoLite2-City.mmdb

# Social Authentication (Optional)
# Google OAuth - Get credentials from: https://console.developers.google.com/
# Google OAuth - https://console.developers.google.com/
GOOGLE_CLIENT_ID=your_google_client_id
GOOGLE_CLIENT_SECRET=your_google_client_secret

# Facebook OAuth - Get credentials from: https://developers.facebook.com/
# Facebook OAuth - https://developers.facebook.com/
FACEBOOK_APP_ID=your_facebook_app_id
FACEBOOK_APP_SECRET=your_facebook_app_secret

# Reddit OAuth - Get credentials from: https://www.reddit.com/prefs/apps
# Reddit API & OAuth
REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_client_secret
REDDIT_REDIRECT_URI=https://your-domain.com/api/reddit/callback

# Replit-specific configuration for production
REPLIT_DOMAINS=your-domain.com,www.your-domain.com
REDDIT_REDIRECT_URI=http://localhost:5000/auth/reddit/callback
REDDIT_USERNAME=
REDDIT_PASSWORD=
REDDIT_USER_AGENT=ThottoPilotBot/1.0 by your_reddit_username
REDDIT_REFRESH_TOKEN=

# Stripe Payment Processing (Optional)
STRIPE_SECRET_KEY=sk_test_your_stripe_secret_key
STRIPE_PUBLISHABLE_KEY=pk_test_your_stripe_publishable_key
STRIPE_WEBHOOK_SECRET=whsec_your_webhook_secret
# UTM & Marketing Attribution
UTM_COOKIE_TTL_DAYS=30

# Production Environment
# Testing & QA Harnesses
E2E_BASE_URL=https://staging.yourdomain.com
E2E_BILLING_PLAN=starter
E2E_ADMIN_EMAIL=admin@staging.yourdomain.com
E2E_ADMIN_PASSWORD=changeme
TEST_URL=http://localhost:5000
# Client Development Shortcuts
VITE_ADMIN_EMAIL=admin@yourdomain.com
VITE_ADMIN_PASSWORD=changeme
# Set NODE_ENV=production in live deployments
# NODE_ENV=production
# NODE_ENV=production
docs/runbooks/secret-provisioning-checklist.md
New
+168-0
# Secret Provisioning Checklist

This runbook converts the production secrets task into a set of actionable, auditable steps. Work through each section in order and check items off once the corresponding credentials are present in your secrets manager (AWS Secrets Manager, Doppler, 1Password, etc.).

## 1. Generate the definitive key list

- [ ] Run the automated audit to ensure `.env.example` matches every environment variable referenced in the codebase:

  ```bash
  npm run env:audit
  ```

  The command fails if a key is missing from `.env.example` or duplicated. Address any failures before proceeding so development, staging, and production remain aligned.

## 2. Core runtime & networking

- [ ] Provision the following variables with production values:

  | Key | Required in Production? | Notes |
  | --- | --- | --- |
  | `NODE_ENV` | ✅ | Set to `production` for live deployments.
  | `PORT` | ✅ | External load balancer/backend service port.
  | `APP_BASE_URL` | ✅ | Public base URL for API callbacks.
  | `FRONTEND_URL` | ✅ | Primary marketing/app domain used in emails and redirects.
  | `ALLOWED_ORIGINS` | ✅ | Comma-separated list of trusted web origins.
  | `CRON_TZ` | ⚙️ | Timezone used by scheduled jobs.
  | `DEFAULT_SYNC_SUBREDDITS` | ⚙️ | Seed list for Reddit sync tooling.
  | `GIT_COMMIT_SHA` | ⚙️ | Optional release identifier surfaced in Sentry logs.
  | `NODE_OPTIONS` | ⚙️ | Memory flags passed to the Node runtime.
  | `REPLIT_DEPLOYMENT`, `REPL_ID`, `REPLIT_DOMAINS`, `CI` | ⚙️ | Managed automatically in Replit/CI—documented so the audit remains green.

## 3. Security secrets & session protection

- [ ] Store high-entropy values (≥32 characters) for:

  | Key | Purpose |
  | --- | --- |
  | `JWT_SECRET` | Signs API tokens.
  | `SESSION_SECRET` | Secures Express session cookies.
  | `TURNSTILE_SITE_KEY`, `TURNSTILE_SECRET_KEY` | Cloudflare Turnstile anti-bot verification.

## 4. Database & cache backends

- [ ] Configure database and queue connectivity:

  | Key | Required in Production? | Notes |
  | --- | --- | --- |
  | `DATABASE_URL` | ✅ | Primary Postgres/Neon connection string.
  | `NEON_DATABASE_URL` | ⚙️ | Optional fallback for Neon serverless deployments.
  | `TEST_DATABASE_URL` | 🧪 | Only needed in CI/test pipelines.
  | `REDIS_URL` | ✅ (if using Redis session/queue backends) | Use managed Redis for multi-user load.
  | `USE_PG_QUEUE` | ⚙️ | Toggle Postgres-backed queues if Redis unavailable.

## 5. Object storage & media controls

- [ ] Provide S3/Object Storage credentials plus media constraints:

  | Key | Required in Production? | Notes |
  | --- | --- | --- |
  | `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_REGION` | ✅ (if using S3-compatible storage) | Required for media uploads.
  | `S3_BUCKET_MEDIA`, `S3_PUBLIC_CDN_DOMAIN` | ✅ | Buckets/domains serving generated media.
  | `PRIVATE_OBJECT_DIR` | ✅ (Replit Object Storage) | Path/name for private asset storage buckets.
  | `PLAN_STORAGE_BYTES_*`, `MEDIA_*`, `WATERMARK_*`, `MAX_POSTS_PER_SUBREDDIT_24H`, `DAILY_GENERATIONS_*` | ⚙️ | Feature limits tuned per plan/tier.
  | `ENABLE_VITE_DEV` | ⚙️ | Leave `false` in production.

## 6. Administrative access

- [ ] Align admin credentials across environments:

  | Key | Required in Production? | Notes |
  | --- | --- | --- |
  | `ADMIN_EMAIL`, `ADMIN_USERNAME` | ✅ | Primary administrative account.
  | `ADMIN_PASSWORD_HASH` | ✅ | Bcrypt hash of the admin password stored server-side.
  | `ADMIN_PASSWORD` | 🧰 | Only used by the `scripts/create-admin.ts` helper—do not store plaintext in shared secret stores after bootstrap.
  | `ADMIN_EMAIL_WHITELIST` | ⚙️ | Additional addresses allowed to elevate.

## 7. Email delivery

- [ ] Choose and configure one provider:

  | Key | Required in Production? | Notes |
  | --- | --- | --- |
  | `FROM_EMAIL` | ✅ | Default sender address for transactional mail.
  | `RESEND_API_KEY` or `SENDGRID_API_KEY` | ✅ | Provision at least one provider key.

## 8. Payments & billing

- [ ] Stripe configuration:

  | Key | Required in Production? | Notes |
  | --- | --- | --- |
  | `STRIPE_SECRET_KEY`, `STRIPE_PUBLISHABLE_KEY` | ✅ | Live mode keys for API & frontend.
  | `STRIPE_API_VERSION` | ✅ | Keep aligned with tested API version (`2023-10-16`).
  | `STRIPE_WEBHOOK_SECRET` | ✅ | Secures webhook ingestion.
  | `STRIPE_PRICE_STARTER`, `STRIPE_PRICE_PRO_29`, `STRIPE_PRICE_PRO_39`, `STRIPE_PRICE_PRO_49` | ⚙️ | Set to the price IDs created in Stripe Dashboard.
  | `VITE_STRIPE_PUBLIC_KEY` | ✅ | Surfaced in the checkout UI.

- [ ] Alternative processors (optional but document-ready):

  | Key | Purpose |
  | --- | --- |
  | `CCBILL_CLIENT_ACCOUNT`, `CCBILL_SUBACCOUNT`, `CCBILL_FLEXFORM_ID`, `CCBILL_SALT`, `CCBILL_ACCOUNT_NUMBER` | Enable CCBill fallbacks and dunning flows.
  | `SEGPAY_MERCHANT_ID`, `SEGPAY_API_KEY` | SegPay integration.
  | `EPOCH_MERCHANT_ID`, `EPOCH_API_KEY` | Epoch integration.
  | `PAXUM_API_KEY` | Paxum integration.
  | `COINBASE_COMMERCE_KEY` | Coinbase Commerce crypto payments.

## 9. AI & content generation providers

- [ ] Supply API keys and model endpoints to keep throughput stable under load:

  | Key | Notes |
  | --- | --- |
  | `GOOGLE_GENAI_API_KEY`, `GEMINI_API_KEY` | Primary generative models.
  | `OPENAI_API_KEY`, `ANTHROPIC_API_KEY` | Fallback vendors for multi-provider routing.
  | `HF_API_KEY` | Hugging Face NSFW fallback.
  | `ML_SAFETY_URL` | Internal safety service endpoint.

## 10. Analytics, monitoring, and logging

- [ ] Wire observability secrets:

  | Key | Notes |
  | --- | --- |
  | `ANALYTICS_WRITE_KEY` | Client analytics pipeline.
  | `SENTRY_DSN`, `SENTRY_SAMPLE_RATE` | Error monitoring for server workloads.
  | `MAXMIND_DB_PATH` | Path to the GeoIP database for analytics enrichment.

## 11. Social login & third-party auth

- [ ] Confirm OAuth credentials are present:

  | Provider | Keys |
  | --- | --- |
  | Google | `GOOGLE_CLIENT_ID`, `GOOGLE_CLIENT_SECRET`
  | Facebook | `FACEBOOK_APP_ID`, `FACEBOOK_APP_SECRET`
  | Reddit | `REDDIT_CLIENT_ID`, `REDDIT_CLIENT_SECRET`, `REDDIT_REDIRECT_URI`, `REDDIT_USERNAME`, `REDDIT_PASSWORD`, `REDDIT_USER_AGENT`, `REDDIT_REFRESH_TOKEN`

## 12. Marketing & attribution

- [ ] Review auxiliary configuration:

  | Key | Notes |
  | --- | --- |
  | `UTM_COOKIE_TTL_DAYS` | Attribution cookie lifetime.

## 13. Testing & QA harnesses

- [ ] Ensure automated suites have credentials:

  | Key | Notes |
  | --- | --- |
  | `E2E_BASE_URL`, `E2E_BILLING_PLAN`, `E2E_ADMIN_EMAIL`, `E2E_ADMIN_PASSWORD` | Consumed by the Playwright smoke tests.
  | `TEST_DATABASE_URL` | Provided earlier in section 4 for test runners.

- [ ] Populate convenience keys used only in development clients (store in local `.env`, not production secrets):

  | Key | Notes |
  | --- | --- |
  | `VITE_ADMIN_EMAIL`, `VITE_ADMIN_PASSWORD` | Enables “quick admin login” in local builds.

## 14. Final validation

- [ ] Re-run `npm run env:audit` to confirm no new gaps were introduced while provisioning secrets.
- [ ] Run `npm run lint` and `npm test` locally or in CI with the fully populated secret set to catch misconfigurations early.
- [ ] Update deployment runbooks (`DEPLOYMENT.md`, process manager configs) with locations of the secret store and rotation procedures.

Once every item above is checked, your production environment has parity with the repository configuration. This foundation enables higher concurrency—sessions stay sticky, queues have durable storage, and AI/payment providers possess the required credentials to scale beyond single-user loads.
package.json
+1-0
{
  "name": "rest-express",
  "version": "1.0.0",
  "type": "module",
  "license": "MIT",
  "scripts": {
    "dev": "NODE_ENV=development tsx server/index.ts",
    "build": "bash build-production.sh",
    "prestart": "npm run build",
    "build:client": "vite build",
    "build:server": "tsc -p tsconfig.server.json",
    "start": "NODE_ENV=production node dist/server/index.js",
    "db:generate": "drizzle-kit generate",
    "db:migrate": "drizzle-kit migrate",
    "db:studio": "drizzle-kit studio",
    "typecheck": "tsc -p tsconfig.json --noEmit",
    "fix-imports": "bash fix-all-imports.sh",
    "lint": "eslint .",
    "test": "vitest run",
    "env:audit": "tsx scripts/audit-env.ts",
    "backfill:post-rate-limits": "tsx scripts/backfill-post-rate-limits.ts",
    "test:coverage": "vitest run --coverage",
    "test:e2e": "tsx vendor/playwright-test/runner.ts"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.37.0",
    "@aws-sdk/client-s3": "^3.864.0",
    "@aws-sdk/s3-request-presigner": "^3.864.0",
    "@eslint/js": "^9.35.0",
    "@google-cloud/storage": "^7.17.0",
    "@google/genai": "^1.12.0",
    "@google/generative-ai": "^0.24.1",
    "@hookform/resolvers": "^3.10.0",
    "@jridgewell/trace-mapping": "^0.3.25",
    "@maxmind/geoip2-node": "^6.1.0",
    "@neondatabase/serverless": "^0.10.4",
    "@playwright/test": "file:vendor/playwright-test",
    "@radix-ui/react-accordion": "^1.2.4",
    "@radix-ui/react-alert-dialog": "^1.1.7",
    "@radix-ui/react-aspect-ratio": "^1.1.3",
    "@radix-ui/react-avatar": "^1.1.4",
    "@radix-ui/react-checkbox": "^1.1.5",
    "@radix-ui/react-collapsible": "^1.1.4",
    "@radix-ui/react-context-menu": "^2.2.7",
    "@radix-ui/react-dialog": "^1.1.7",
scripts/audit-env.ts
New
+205-0
import { readdir, readFile } from 'node:fs/promises';
import path from 'node:path';
import { fileURLToPath } from 'node:url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const repoRoot = path.resolve(__dirname, "..");
const includeExtensions = new Set([
  ".ts",
  ".tsx",
  ".js",
  ".jsx",
  ".mjs",
  ".cjs",
]);
const ignoredDirectories = new Set([
  ".git",
  "node_modules",
  "dist",
  "build",
  "coverage",
  "logs",
  "attached_assets",
]);
const maxFileSizeBytes = 1_500_000;

const processEnvPattern = /process\.env\.([A-Z][A-Z0-9_]*)/g;
const importMetaPattern = /import\.meta\.env\.([A-Z][A-Z0-9_]*)/g;
const bracketEnvPattern = /process\.env\[['"]([A-Z][A-Z0-9_]*)['"]\]/g;
const viteBuiltins = new Set(["MODE", "DEV", "PROD", "SSR", "BASE_URL", "BASE", "LEGACY"]);

async function walk(directory: string, accumulator: Set<string>, importMetaKeys: Set<string>): Promise<void> {
  const entries = await readdir(directory, { withFileTypes: true });

  for (const entry of entries) {
    if (ignoredDirectories.has(entry.name)) {
      continue;
    }

    const entryPath = path.join(directory, entry.name);

    if (entry.isDirectory()) {
      await walk(entryPath, accumulator, importMetaKeys);
      continue;
    }

    const extension = path.extname(entry.name);
    if (!includeExtensions.has(extension)) {
      continue;
    }

    const fileBuffer = await readFile(entryPath);
    if (fileBuffer.length > maxFileSizeBytes) {
      continue;
    }

    const content = fileBuffer.toString("utf8");

    let processMatch: RegExpExecArray | null;
    while ((processMatch = processEnvPattern.exec(content)) !== null) {
      const [, key] = processMatch;
      if (typeof key === "string") {
        accumulator.add(key);
      }
    }

    let bracketMatch: RegExpExecArray | null;
    while ((bracketMatch = bracketEnvPattern.exec(content)) !== null) {
      const [, key] = bracketMatch;
      if (typeof key === "string") {
        accumulator.add(key);
      }
    }

    let importMatch: RegExpExecArray | null;
    while ((importMatch = importMetaPattern.exec(content)) !== null) {
      const [, key] = importMatch;
      if (typeof key === "string" && !viteBuiltins.has(key)) {
        importMetaKeys.add(key);
      }
    }
  }
}

async function collectDocumentedKeys(examplePath: string): Promise<{ keys: Set<string>; duplicates: string[] }>
{
  const content = await readFile(examplePath, "utf8");
  const keys = new Set<string>();
  const duplicates: string[] = [];

  for (const line of content.split(/\r?\n/u)) {
    if (!line || line.startsWith("#")) {
      continue;
    }

    const [rawKey] = line.split("=", 1);
    if (!rawKey) {
      continue;
    }

    const key = rawKey.trim();
    if (!key) {
      continue;
    }

    if (keys.has(key)) {
      duplicates.push(key);
    }

    keys.add(key);
  }

  return { keys, duplicates };
}

async function collectSchemaKeys(schemaPath: string): Promise<Set<string>> {
  let content: string;
  try {
    content = await readFile(schemaPath, "utf8");
  } catch {
    return new Set<string>();
  }

  const match = content.match(/z\.object\(\s*\{([\s\S]*?)\}\s*\)/u);
  if (!match) {
    return new Set<string>();
  }

  const schemaBody = match[1];
  const keys = new Set<string>();

  for (const rawLine of schemaBody.split(/\r?\n/u)) {
    const line = rawLine.trim();
    if (!line || line.startsWith("//")) {
      continue;
    }

    const keyMatch = line.match(/^([A-Z][A-Z0-9_]*)\s*:/u);
    if (keyMatch) {
      keys.add(keyMatch[1]);
    }
  }

  return keys;
}

function formatList(values: Iterable<string>): string {
  const items = Array.from(values).sort();
  return items.length > 0 ? `\n  - ${items.join("\n  - ")}` : " (none)";
}

async function main(): Promise<void> {
  const usedKeys = new Set<string>();
  const importMetaKeys = new Set<string>();
  await walk(repoRoot, usedKeys, importMetaKeys);

  const schemaKeys = await collectSchemaKeys(path.join(repoRoot, "server/lib/config.ts"));
  const allUsedKeys = new Set<string>([...usedKeys, ...importMetaKeys, ...schemaKeys]);
  const envExamplePath = path.join(repoRoot, ".env.example");
  const { keys: documentedKeys, duplicates } = await collectDocumentedKeys(envExamplePath);

  const missingDocumentation = [...allUsedKeys].filter(key => !documentedKeys.has(key)).sort();
  const unusedAllowlist = new Set<string>([
    "STRIPE_PUBLISHABLE_KEY",
    "E2E_ADMIN_EMAIL",
    "E2E_ADMIN_PASSWORD",
  ]);
  const unusedDocumentation = [...documentedKeys]
    .filter(key => !allUsedKeys.has(key) && !unusedAllowlist.has(key))
    .sort();

  let sharedCount = 0;
  for (const key of allUsedKeys) {
    if (documentedKeys.has(key)) {
      sharedCount += 1;
    }
  }

  console.log("Environment Key Audit Summary");
  console.log(`• Code references: ${allUsedKeys.size}`);
  console.log(`• Documented in .env.example: ${documentedKeys.size}`);
  console.log(`• Shared keys: ${sharedCount}`);

  if (duplicates.length > 0) {
    console.error("Duplicate keys found in .env.example:" + formatList(duplicates));
  }

  if (missingDocumentation.length > 0) {
    console.error("Missing from .env.example:" + formatList(missingDocumentation));
  }

  if (unusedDocumentation.length > 0) {
    console.warn("Documented but not referenced in code:" + formatList(unusedDocumentation));
  }

  if (duplicates.length > 0 || missingDocumentation.length > 0) {
    process.exitCode = 1;
  }
}

main().catch(error => {
  console.error("Failed to audit environment keys.");
  console.error(error);
  process.exitCode = 1;
});
