create-env.js
+9
-6

const fs = require('fs');
import fs from 'fs';
import process from 'node:process';

// List the secrets you need for testing
const secrets = [
  'DATABASE_URL',
  'APP_BASE_URL',
  'JWT_SECRET',
  'SESSION_SECRET',
  'REDDIT_CLIENT_ID',
  'REDDIT_CLIENT_SECRET',
  'REDDIT_USERNAME',
  'REDDIT_PASSWORD',
  'REDDIT_USER_AGENT',
  'GEMINI_API_KEY',
  'OPENAI_API_KEY',
  'STRIPE_SECRET_KEY',
  'COINBASE_API_KEY',
  'PAXUM_MERCHANT_EMAIL',
  'FROM_EMAIL'
];

// Build .env content
let envContent = '';
secrets.forEach(key => {
  if (process.env[key]) {
    envContent += `${key}=${process.env[key]}\n`;
for (const key of secrets) {
  const value = process.env[key];
  if (value) {
    envContent += `${key}=${value}\n`;
  } else {
    console.warn(`Warning: ${key} is not set in Replit Secrets`);
  }
});
}

// Write to .env file
fs.writeFileSync('.env', envContent);
console.log('.env file created with', envContent.split('\n').filter(l => l).length, 'variables');
const variableCount = envContent.split('\n').filter((line) => line).length;
console.log('.env file created with', variableCount, 'variables');
fix-type-errors.cjs
+1
-1

#!/usr/bin/env node

/* eslint-env node */
const fs = require('fs');
const path = require('path');

// Helper to fix common TypeScript errors
function fixTypeErrors(filePath) {
  if (!fs.existsSync(filePath)) return;
  
  let content = fs.readFileSync(filePath, 'utf8');
  
  // Fix error.message patterns
  content = content.replace(/(\s)error\.message/g, '$1(error as Error).message');
  content = content.replace(/(\s)error\.stack/g, '$1(error as Error).stack');
  
  // Fix implicit any in map functions
  content = content.replace(/\.map\(\(([^,)]+),\s*([^)]+)\)/g, '.map(($1: any, $2: number)');
  
  // Fix implicit any in function parameters
  content = content.replace(/function\s+(\w+)\(([^:)]+)\)/g, 'function $1($2: any)');
  
  fs.writeFileSync(filePath, content);
}

// Process all TypeScript files
const files = process.argv.slice(2);
files.forEach(fixTypeErrors);

console.log('‚úÖ Type errors fixed in', files.length, 'files');
server/lib/media.ts
+138
-27

import { S3Client, PutObjectCommand, GetObjectCommand, DeleteObjectCommand } from "@aws-sdk/client-s3";
import { getSignedUrl } from "@aws-sdk/s3-request-presigner";
import sharp from "sharp";
import crypto from "crypto";
import Redis from "ioredis";
import { env, config } from "./config.js";
import { db } from "../db.js";
import { mediaAssets, mediaUsages } from "@shared/schema";
import { eq, sum, and } from "drizzle-orm";
import fs from "fs/promises";
import path from "path";

// Check if S3 is configured
const isS3Configured = !!(env.AWS_ACCESS_KEY_ID && env.AWS_SECRET_ACCESS_KEY && env.S3_BUCKET_MEDIA);

// S3 client configuration (only if configured)
const s3Client = isS3Configured ? new S3Client({
  region: env.AWS_REGION || 'us-east-1',
  credentials: {
    accessKeyId: env.AWS_ACCESS_KEY_ID!,
    secretAccessKey: env.AWS_SECRET_ACCESS_KEY!,
  },
}) : null;

// Ensure uploads directory exists
const uploadsDir = path.join(process.cwd(), 'uploads');
fs.mkdir(uploadsDir, { recursive: true }).catch(() => {});

type MediaAssetRow = typeof mediaAssets.$inferSelect;

interface DownloadTokenPayload {
  assetId: number;
  userId: number;
  key: string;
}

interface MemoryDownloadTokenPayload extends DownloadTokenPayload {
  expiresAt: number;
}

const DOWNLOAD_TOKEN_PREFIX = 'media:download:';
const downloadRedisClient = env.REDIS_URL ? new Redis(env.REDIS_URL) : null;
const memoryDownloadTokens = new Map<string, MemoryDownloadTokenPayload>();

export interface MediaUploadOptions {
  visibility?: 'private' | 'preview-watermarked';
  applyWatermark?: boolean;
  userId: number;
  filename: string;
}

export interface MediaAssetWithUrl {
  id: number;
  key: string;
  filename: string;
  bytes: number;
  mime: string;
  visibility: string;
  signedUrl?: string;
  downloadUrl?: string;
  downloadToken?: string;
  createdAt: Date;
}

export class MediaManager {
  

  private static getDownloadTokenKey(token: string): string {
    return `${DOWNLOAD_TOKEN_PREFIX}${token}`;
  }

  private static sanitizeLocalKey(key: string): string {
    return key.replace(/\//g, '_');
  }

  private static getDownloadTokenTTL(): number {
    return Math.max(1, config.signedUrlTTL || 900);
  }

  static usesLocalStorage(): boolean {
    return !isS3Configured;
  }

  static getLocalAssetPath(key: string): string {
    return path.join(uploadsDir, this.sanitizeLocalKey(key));
  }

  static async validateDownloadToken(token: string): Promise<DownloadTokenPayload | null> {
    if (!token) {
      return null;
    }

    if (downloadRedisClient) {
      try {
        const raw = await downloadRedisClient.get(this.getDownloadTokenKey(token));
        if (raw) {
          return JSON.parse(raw) as DownloadTokenPayload;
        }
      } catch (error) {
        console.error('Failed to read download token from Redis:', error);
      }
    }

    const memoryEntry = memoryDownloadTokens.get(token);
    if (!memoryEntry) {
      return null;
    }

    if (memoryEntry.expiresAt <= Date.now()) {
      memoryDownloadTokens.delete(token);
      return null;
    }

    return {
      assetId: memoryEntry.assetId,
      userId: memoryEntry.userId,
      key: memoryEntry.key,
    };
  }

  private static async persistDownloadToken(token: string, payload: DownloadTokenPayload): Promise<void> {
    const ttlSeconds = this.getDownloadTokenTTL();

    if (downloadRedisClient) {
      try {
        await downloadRedisClient.setex(this.getDownloadTokenKey(token), ttlSeconds, JSON.stringify(payload));
        return;
      } catch (error) {
        console.error('Failed to store download token in Redis:', error);
      }
    }

    const expiresAt = Date.now() + ttlSeconds * 1000;
    memoryDownloadTokens.set(token, { ...payload, expiresAt });
    const timeout = setTimeout(() => {
      const entry = memoryDownloadTokens.get(token);
      if (entry && entry.expiresAt <= Date.now()) {
        memoryDownloadTokens.delete(token);
      }
    }, ttlSeconds * 1000);

    if (typeof timeout.unref === 'function') {
      timeout.unref();
    }
  }

  private static async generateLocalDownloadToken(asset: MediaAssetRow): Promise<string> {
    const token = crypto.randomUUID();
    await this.persistDownloadToken(token, {
      assetId: asset.id,
      userId: asset.userId,
      key: asset.key,
    });
    return token;
  }

  private static async buildAssetResponse(asset: MediaAssetRow): Promise<MediaAssetWithUrl> {
    const response: MediaAssetWithUrl = { ...asset };

    if (isS3Configured && s3Client) {
      const signedUrl = await this.getSignedUrl(asset.key);
      response.signedUrl = signedUrl;
      response.downloadUrl = env.S3_PUBLIC_CDN_DOMAIN
        ? `${env.S3_PUBLIC_CDN_DOMAIN}/${asset.key}`
        : undefined;
    } else {
      const token = await this.generateLocalDownloadToken(asset);
      const downloadPath = `/uploads/${token}`;
      response.signedUrl = downloadPath;
      response.downloadUrl = downloadPath;
      response.downloadToken = token;
    }

    return response;
  }

  static async uploadFile(
    buffer: Buffer,
    options: MediaUploadOptions
  ): Promise<MediaAssetWithUrl> {
    const { userId, filename, visibility = 'private', applyWatermark = false } = options;
    
    // Check user quota
    await this.checkUserQuota(userId, buffer.length);
    
    // Process image if needed
    let finalBuffer = buffer;
    let finalMime = this.getMimeType(filename);
    
    if (this.isImage(filename)) {
      finalBuffer = await this.processImage(buffer, {
        applyWatermark: applyWatermark && config.watermark.enabled,
        quality: visibility === 'preview-watermarked' ? 70 : 90,
      });
      finalMime = 'image/jpeg'; // Always convert to JPEG for consistency
    }
    
    // Generate unique key
    const sha256 = crypto.createHash('sha256').update(finalBuffer).digest('hex');
    const extension = this.getFileExtension(filename);
    const key = `${userId}/${Date.now()}-${sha256.substring(0, 12)}.${extension}`;
    
    // Check if file already exists
    const existing = await this.findExistingAsset(sha256, userId);
    if (existing) {
      return existing;
    }
    
    // Upload to S3 or local filesystem
    if (isS3Configured && s3Client) {
      await s3Client.send(new PutObjectCommand({
        Bucket: env.S3_BUCKET_MEDIA!,
        Key: key,
        Body: finalBuffer,
        ContentType: finalMime,
        Metadata: {
          'user-id': userId.toString(),
          'original-filename': filename,
          'visibility': visibility,
        },
      }));
    } else {
      // Fallback to local filesystem
      const localPath = path.join(uploadsDir, key.replace(/\//g, '_'));
      const localPath = this.getLocalAssetPath(key);
      await fs.writeFile(localPath, finalBuffer);
    }
    
    // Save to database
    const [asset] = await db.insert(mediaAssets).values({
      userId,
      key,
      filename,
      bytes: finalBuffer.length,
      mime: finalMime,
      sha256,
      visibility,
    }).returning();
    
    return {
      ...asset,
      signedUrl: isS3Configured ? await this.getSignedUrl(key) : `/uploads/${key.replace(/\//g, '_')}`,
    };
    return this.buildAssetResponse(asset);
  }
  

  static async getAsset(id: number, userId?: number): Promise<MediaAssetWithUrl | null> {
    const whereCondition = userId 
      ? and(eq(mediaAssets.id, id), eq(mediaAssets.userId, userId))
      : eq(mediaAssets.id, id);
    
    const [asset] = await db
      .select()
      .from(mediaAssets)
      .where(whereCondition)
      .limit(1);
    if (!asset) return null;
    
    return {
      ...asset,
      signedUrl: isS3Configured ? await this.getSignedUrl(asset.key) : `/uploads/${asset.key.replace(/\//g, '_')}`,
      downloadUrl: env.S3_PUBLIC_CDN_DOMAIN 
        ? `${env.S3_PUBLIC_CDN_DOMAIN}/${asset.key}`
        : undefined,
    };
    return this.buildAssetResponse(asset);
  }
  

  static async getUserAssets(userId: number, limit: number = 50): Promise<MediaAssetWithUrl[]> {
    const assets = await db
      .select()
      .from(mediaAssets)
      .where(eq(mediaAssets.userId, userId))
      .orderBy(mediaAssets.createdAt)
      .limit(limit);
    
    return Promise.all(assets.map(async (asset) => ({
      ...asset,
      signedUrl: isS3Configured ? await this.getSignedUrl(asset.key) : `/uploads/${asset.key.replace(/\//g, '_')}`,
    })));
    return Promise.all(assets.map(async (asset) => this.buildAssetResponse(asset)));
  }
  
  static async deleteAsset(id: number, userId: number): Promise<boolean> {
    const [asset] = await db
      .select()
      .from(mediaAssets)
      .where(and(eq(mediaAssets.id, id), eq(mediaAssets.userId, userId)))
      .limit(1);
      
    if (!asset) return false;
    
    try {
      // Delete from S3 or local filesystem
      if (isS3Configured && s3Client) {
        await s3Client.send(new DeleteObjectCommand({
          Bucket: env.S3_BUCKET_MEDIA!,
          Key: asset.key,
        }));
      } else {
        // Delete from local filesystem
        const localPath = path.join(uploadsDir, asset.key.replace(/\//g, '_'));
        const localPath = this.getLocalAssetPath(asset.key);
        await fs.unlink(localPath).catch(() => {});
      }
      
      // Delete from database
      await db.delete(mediaAssets).where(eq(mediaAssets.id, id));
      
      return true;
    } catch (error) {
      console.error('Failed to delete asset:', error);
      return false;
    }
  }
  
  static async getUserStorageUsage(userId: number): Promise<{ used: number; quota: number }> {
    const result = await db
      .select({ totalBytes: sum(mediaAssets.bytes) })
      .from(mediaAssets)
      .where(eq(mediaAssets.userId, userId));
    
    const used = parseInt(result[0]?.totalBytes || '0');
    
    // Get user tier to determine quota (would need user lookup)
    const quota = config.mediaQuotas.free; // Default to free tier
    
    return { used, quota };
@@ -216,75 +331,71 @@ export class MediaManager {
    
    if (options.applyWatermark) {
      // Add watermark to bottom-right corner
      const watermarkSvg = Buffer.from(`
        <svg width="300" height="60" xmlns="http://www.w3.org/2000/svg">
          <rect width="300" height="60" fill="black" opacity="0.3" rx="8"/>
          <text x="20" y="35" font-family="Arial, sans-serif" font-size="18" 
                fill="white" opacity="${config.watermark.opacity}">
            üõ°Ô∏è ${config.watermark.text}
          </text>
        </svg>
      `);
      
      image = image.composite([{
        input: watermarkSvg,
        gravity: 'southeast',
        blend: 'over'
      }]);
    }
    
    return image.toBuffer();
  }
  
  private static async getSignedUrl(key: string): Promise<string> {
    if (!isS3Configured || !s3Client) {
      // Return local URL if S3 not configured
      return `/uploads/${key.replace(/\//g, '_')}`;
      throw new Error('Signed URLs are not available without S3 configuration');
    }
    
    const command = new GetObjectCommand({
      Bucket: env.S3_BUCKET_MEDIA!,
      Key: key,
    });
    
    return getSignedUrl(s3Client, command, { expiresIn: config.signedUrlTTL });
  }
  
  private static async findExistingAsset(sha256: string, userId: number): Promise<MediaAssetWithUrl | null> {
    const [existing] = await db
      .select()
      .from(mediaAssets)
      .where(and(eq(mediaAssets.sha256, sha256), eq(mediaAssets.userId, userId)))
      .limit(1);
      
    if (!existing) return null;
    
    return {
      ...existing,
      signedUrl: isS3Configured ? await this.getSignedUrl(existing.key) : `/uploads/${existing.key.replace(/\//g, '_')}`,
    };

    return this.buildAssetResponse(existing);
  }
  
  private static isImage(filename: string): boolean {
    const ext = this.getFileExtension(filename).toLowerCase();
    return ['jpg', 'jpeg', 'png', 'gif', 'webp'].includes(ext);
  }
  
  private static getFileExtension(filename: string): string {
    return filename.split('.').pop() || 'bin';
  }
  
  private static getMimeType(filename: string): string {
    const ext = this.getFileExtension(filename).toLowerCase();
    const mimeTypes: Record<string, string> = {
      jpg: 'image/jpeg',
      jpeg: 'image/jpeg',
      png: 'image/png',
      gif: 'image/gif',
      webp: 'image/webp',
      mp4: 'video/mp4',
      mov: 'video/quicktime',
      avi: 'video/x-msvideo',
    };
    
    return mimeTypes[ext] || 'application/octet-stream';
server/routes.ts
+3
-2

@@ -58,50 +58,51 @@ declare module 'express-session' {
  interface SessionData extends RedditSessionData {}
}

// Service imports
import { generateContent } from "./services/content-generator.js";
import { generateAIContent, analyzeImageForContent } from "./services/ai-generator.js";
import { generateWithMultiProvider, getProviderStatus } from "./services/multi-ai-provider.js";
import { generateUnifiedAIContent, analyzeImage } from "./services/unified-ai-service.js";
import { generateImageCaption, imageToBase64, validateImageFormat } from "./image-caption-generator.js";
import { ObjectStorageService, ObjectNotFoundError } from "./objectStorage.js";
import { getRandomTemplates, addWatermark, getTemplateByMood } from "./content-templates.js";
import { generateAdvancedContent, type ContentParameters } from "./advanced-content-generator.js";
// Reddit communities now handled in reddit-routes.ts
import { getAvailablePerks, getPerksByCategory, generateReferralCode, getSignupInstructions } from "./pro-perks.js";

// API route modules
import { registerApiRoutes } from "./api-routes.js";
import { registerPolicyRoutes } from "./policy-routes.js";
import { registerRedditRoutes } from "./reddit-routes.js";
import { registerAnalyticsRoutes } from "./analytics-routes.js";
import { createLead, confirmLead } from "./api/leads.js";
import { getLeads } from "./api/admin-leads.js";
import { captionRouter } from "./routes/caption.js";
import { contentGenerationLimiter } from "./middleware/tiered-rate-limit.js";
import { registerSocialMediaRoutes } from "./social-media-routes.js";
import { secureUploadsRouter } from "./routes/secure-uploads.js";

// Schema imports
import { insertContentGenerationSchema, insertUserImageSchema } from "@shared/schema";

// Core dependencies
import multer from 'multer';
import fs from 'fs/promises';
import crypto from 'crypto';
import jwt from 'jsonwebtoken';
import bcrypt from 'bcrypt';
import csrf from 'csurf';

// Get secure environment variables (no fallbacks)
const rawSessionSecret = process.env.SESSION_SECRET;
if (!rawSessionSecret) {
  throw new Error('SESSION_SECRET missing');
}
const SESSION_SECRET: string = rawSessionSecret;
const IS_PRODUCTION = process.env.NODE_ENV === 'production';
const DATABASE_URL = process.env.DATABASE_URL;
const REDIS_URL = process.env.REDIS_URL;
const STRIPE_SECRET_KEY = process.env.STRIPE_SECRET_KEY;

// Initialize Stripe if configured
const stripe = STRIPE_SECRET_KEY ? new Stripe(STRIPE_SECRET_KEY, {
@@ -292,52 +293,52 @@ export async function registerRoutes(app: Express, apiPrefix: string = '/api'):
  
  // Configure social authentication
  configureSocialAuth();

  // ==========================================
  // ROUTE REGISTRATION
  // ==========================================
  
  // Authentication routes - handled by setupAuth() in server/auth.ts
  // app.use('/api/auth', authRoutes); // Removed - duplicate auth system
  
  // Upload routes
  app.use('/api/upload', uploadRoutes);
  
  // Media routes
  app.use('/api/media', mediaRoutes);
  
  // Social auth routes
  app.get('/api/auth/google', socialAuthRoutes.googleAuth);
  app.get('/api/auth/google/callback', socialAuthRoutes.googleCallback);
  app.get('/api/auth/facebook', socialAuthRoutes.facebookAuth);
  app.get('/api/auth/facebook/callback', socialAuthRoutes.facebookCallback);
  app.get('/api/auth/reddit', socialAuthRoutes.redditAuth);
  app.get('/api/auth/reddit/callback', socialAuthRoutes.redditCallback);

  // Serve uploaded files securely
  app.use('/uploads', express.static(path.join(process.cwd(), 'uploads')));
  // Serve uploaded files securely with auth + ownership checks
  app.use('/uploads', secureUploadsRouter);

  // ==========================================
  // STRIPE PAYMENT ENDPOINTS
  // ==========================================
  
  // Create subscription payment intent
  app.post("/api/create-subscription", authenticateToken, async (req: AuthRequest, res) => {
    try {
      if (!stripe) {
        return res.status(503).json({ 
          message: "Payment system is not configured. Please try again later." 
        });
      }

      if (!req.user?.id) {
        return res.status(401).json({ message: "Authentication required" });
      }

      const { plan, amount } = req.body;
      
      // Validate plan and amount
      if (!plan || !amount) {
        return res.status(400).json({ message: "Plan and amount are required" });
      }

server/routes/secure-uploads.ts
New
+75
-0

import express from 'express';
import fs from 'fs';
import type { Response } from 'express';
import { authenticateToken, type AuthRequest } from '../middleware/auth.js';
import { MediaManager } from '../lib/media.js';
import { logger } from '../middleware/security.js';

const router = express.Router();

async function streamFile(response: Response, filePath: string, mimeType: string, filename: string): Promise<void> {
  const stat = await fs.promises.stat(filePath);

  response.setHeader('Content-Type', mimeType);
  response.setHeader('Content-Length', stat.size);
  const safeFileName = filename.replace(/"/g, '');
  response.setHeader('Content-Disposition', `inline; filename="${safeFileName}"`);
  response.setHeader('Cache-Control', 'private, max-age=0, no-cache');

  const stream = fs.createReadStream(filePath);
  stream.on('error', (error) => {
    logger.error('Error streaming protected asset', { error });
    if (!response.headersSent) {
      response.status(500).json({ message: 'Failed to stream asset' });
    } else {
      response.end();
    }
  });

  stream.pipe(response);
}

router.get('/:token', authenticateToken, async (req: AuthRequest, res) => {
  try {
    const { token } = req.params;

    if (!token) {
      return res.status(400).json({ message: 'Download token is required' });
    }

    if (!req.user?.id) {
      return res.status(401).json({ message: 'Authentication required' });
    }

    if (!MediaManager.usesLocalStorage()) {
      return res.status(400).json({ message: 'Local storage downloads are disabled' });
    }

    const payload = await MediaManager.validateDownloadToken(token);
    if (!payload) {
      return res.status(403).json({ message: 'Invalid or expired download token' });
    }

    if (payload.userId !== req.user.id) {
      return res.status(403).json({ message: 'Download token does not belong to this user' });
    }

    const asset = await MediaManager.getAsset(payload.assetId, req.user.id);
    if (!asset) {
      return res.status(404).json({ message: 'Asset not found' });
    }

    const filePath = MediaManager.getLocalAssetPath(asset.key);
    const exists = await fs.promises.stat(filePath).catch(() => null);
    if (!exists) {
      return res.status(404).json({ message: 'File not found' });
    }

    await streamFile(res, filePath, asset.mime, asset.filename);
  } catch (error) {
    logger.error('Failed to serve secure upload', error);
    res.status(500).json({ message: 'Failed to download asset' });
  }
});

export const secureUploadsRouter = router;
tests/integration/secure-download.test.ts
New
+131
-0

import request from 'supertest';
import express from 'express';
import cookieParser from 'cookie-parser';
import sharp from 'sharp';
import fs from 'fs/promises';
import crypto from 'crypto';
import { beforeAll, afterAll, describe, expect, test, vi } from 'vitest';

const TEST_USER_ID = 4242;

vi.mock('../../server/middleware/auth.js', () => {
  const authenticateToken = (req: express.Request, res: express.Response, next: express.NextFunction) => {
    const authHeader = req.headers['authorization'];
    if (authHeader === 'Bearer valid-token') {
      (req as express.Request & { user?: { id: number } }).user = { id: TEST_USER_ID };
      return next();
    }

    return res.status(401).json({ message: 'Access token required' });
  };

  return {
    authenticateToken,
  };
});

import { secureUploadsRouter } from '../../server/routes/secure-uploads';
import { MediaManager, type MediaAssetWithUrl } from '../../server/lib/media';

type TestAsset = MediaAssetWithUrl & {
  userId: number;
  sha256: string;
  lastUsedAt: Date;
};

describe('Secure media download flow', () => {
  const app = express();
  let storedAsset: TestAsset | null = null;
  let downloadToken = '';
  let signedPath = '';
  let assetFilePath = '';

  beforeAll(async () => {
    app.use(cookieParser());
    app.use('/uploads', secureUploadsRouter);

    const imageBuffer = await sharp({
      create: {
        width: 24,
        height: 24,
        channels: 3,
        background: { r: 120, g: 45, b: 200 },
      },
    }).jpeg().toBuffer();

    const key = `${TEST_USER_ID}/${Date.now()}-${crypto.randomBytes(6).toString('hex')}.jpg`;
    storedAsset = {
      id: 1,
      userId: TEST_USER_ID,
      key,
      filename: 'secure-download.jpg',
      bytes: imageBuffer.length,
      mime: 'image/jpeg',
      visibility: 'private',
      createdAt: new Date(),
      sha256: crypto.randomBytes(32).toString('hex'),
      lastUsedAt: new Date(),
    };

    const tokenGenerator = (MediaManager as unknown as {
      generateLocalDownloadToken: (asset: TestAsset) => Promise<string>;
    }).generateLocalDownloadToken;

    downloadToken = await Reflect.apply(tokenGenerator, MediaManager, [storedAsset]);
    signedPath = `/uploads/${downloadToken}`;

    vi.spyOn(MediaManager, 'getAsset').mockImplementation(async (id: number, userId?: number) => {
      if (!storedAsset) return null;
      if (id !== storedAsset.id || userId !== storedAsset.userId) {
        return null;
      }

      return {
        ...storedAsset,
        downloadToken,
        signedUrl: signedPath,
        downloadUrl: signedPath,
      };
    });

    assetFilePath = MediaManager.getLocalAssetPath(storedAsset.key);
    await fs.writeFile(assetFilePath, imageBuffer);
  });

  afterAll(async () => {
    vi.restoreAllMocks();
    if (assetFilePath) {
      await fs.unlink(assetFilePath).catch(() => {});
    }
  });

  test('blocks guessed filenames and enforces download tokens', async () => {
    if (!storedAsset) {
      throw new Error('Test asset not initialized');
    }

    const guessedPath = `/uploads/${storedAsset.key.replace(/\//g, '_')}`;

    const response = await request(app)
      .get(guessedPath)
      .set('Authorization', 'Bearer valid-token');

    expect(response.status).toBe(403);
  });

  test('rejects download attempts without authentication', async () => {
    const response = await request(app).get(signedPath);
    expect(response.status).toBe(401);
  });

  test('streams media when valid token and auth provided', async () => {
    const response = await request(app)
      .get(signedPath)
      .set('Authorization', 'Bearer valid-token');

    expect(response.status).toBe(200);
    expect(response.headers['content-type']).toContain('image/jpeg');
    expect(Buffer.isBuffer(response.body)).toBe(true);
    expect(response.body.length).toBeGreaterThan(0);
  });
});
tests/setup.ts
+3
-0

import dotenv from 'dotenv';

// Load .env file for tests
dotenv.config();

// Set default test environment variables if not present
process.env.APP_BASE_URL = process.env.APP_BASE_URL || 'https://thottopilot.com';
process.env.DATABASE_URL = process.env.DATABASE_URL || process.env.NEON_DATABASE_URL;
process.env.JWT_SECRET = process.env.JWT_SECRET || 'test-secret-key';
process.env.SESSION_SECRET = process.env.SESSION_SECRET || 'test-session-secret-please-change';
process.env.ADMIN_EMAIL = process.env.ADMIN_EMAIL || 'admin@example.com';
process.env.ADMIN_PASSWORD = process.env.ADMIN_PASSWORD || 'super-secure-password';
process.env.NODE_ENV = 'test';
tests/vitest-setup.ts
+3
-0

import dotenv from 'dotenv';
import { beforeEach } from 'vitest';

// Load .env.test file specifically for vitest tests
dotenv.config({ path: '.env.test' });

// Set default test environment variables if not present
process.env.APP_BASE_URL = process.env.APP_BASE_URL || 'https://thottopilot.com';
process.env.DATABASE_URL = process.env.DATABASE_URL || process.env.NEON_DATABASE_URL;
process.env.JWT_SECRET = process.env.JWT_SECRET || 'test-secret-key';
process.env.SESSION_SECRET = process.env.SESSION_SECRET || 'test-session-secret-please-change';
process.env.ADMIN_EMAIL = process.env.ADMIN_EMAIL || 'admin@example.com';
process.env.ADMIN_PASSWORD = process.env.ADMIN_PASSWORD || 'super-secure-password';
process.env.NODE_ENV = 'test';

// Clean up between tests
beforeEach(() => {
  // Reset any global state here if needed
});