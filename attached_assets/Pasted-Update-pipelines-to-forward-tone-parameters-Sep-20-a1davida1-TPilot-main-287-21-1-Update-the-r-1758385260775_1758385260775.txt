Update pipelines to forward tone parameters
Sep 20 · a1davida1/TPilot · main
+287-21
1. Update the retry calls in `geminiPipeline.pipeline`, `rewritePipeline.pipelineRewrite`, and `textOnlyPipeline.pipelineTextOnly` so they forward every tone parameter they received originally (`style`, `mood`, and any future additions).
2. Add regression tests around the pipelines that trigger a platform validation failure, verify a second Gemini call occurs, and ensure the mocked payload still includes the supplied `style`/`mood`.
3. Document this contract in the pipeline docstrings so future changes keep the persona intact.

Summary

    Added a shared toneOptions helper and threaded its tone metadata through the Gemini, rewrite, and text-only pipelines so retries reuse the caller’s persona while documenting the contract in each pipeline docstring.

Introduced regression tests that trigger platform validation retries across all caption pipelines and assert the mocked Gemini prompts still contain the supplied style and mood cues.

Testing

    ✅ npm run lint (warnings only)

❌ npm test *(fails: suite depends on external services/env such as Neon DB and Gemini credentials not available in this environment)*

✅ npx vitest run tests/unit/caption/pipeline-tone-retry.test.ts


server/caption/geminiPipeline.ts
+20-10
import fs from "node:fs/promises";
import path from "node:path";
import { z } from "zod";
import { visionModel, textModel } from "../lib/gemini";
import { CaptionArray, CaptionItem, RankResult, platformChecks } from "./schema";
import { normalizeSafetyLevel } from "./normalizeSafetyLevel";
import { extractToneOptions, ToneOptions } from "./toneOptions";

// Custom error class for image validation failures
export class InvalidImageError extends Error {
  constructor(message: string) {
    super(message);
    this.name = 'InvalidImageError';
  }
}

// CaptionResult interface for type safety
interface CaptionResult {
  provider: string;
  final: z.infer<typeof CaptionItem>;
  facts?: Record<string, unknown>;
  variants?: z.infer<typeof CaptionArray>;
  ranked?: z.infer<typeof RankResult>;
}

async function load(p: string): Promise<string> {
  return fs.readFile(path.join(process.cwd(), "prompts", p), "utf8");
}
async function b64(url: string): Promise<{ base64: string; mimeType: string }> {
  try {
    const r = await fetch(url);
    if (!r.ok) throw new InvalidImageError(`fetch failed: ${r.status} ${r.statusText}`);
@@ -177,59 +178,59 @@ export async function extractFacts(imageUrl: string): Promise<Record<string, unk
      
      // For GIFs that fail Gemini processing, provide better fallback facts
      if (mimeType === 'image/gif') {
        console.log('GIF processing failed in Gemini, using enhanced fallback facts');
        return {
          objects: ['animated', 'gif', 'motion'],
          colors: ['colorful', 'dynamic'],
          vibe: 'animated',
          setting: 'digital',
          wardrobe: ['various'],
          angles: ['dynamic'],
          mood: 'playful',
          style: 'animated'
        };
      }
      
      throw error;
    }
  } catch (error) {
    console.error('Error in extractFacts:', error);
    if (error instanceof InvalidImageError) throw error;
    throw new Error(`Failed to extract facts: ${error instanceof Error ? error.message : String(error)}`);
  }
}

export async function generateVariants(params: {
type GeminiVariantParams = {
  platform: "instagram" | "x" | "reddit" | "tiktok";
  voice: string;
  style?: string;
  mood?: string;
  facts: Record<string, unknown>;
  hint?: string;
  nsfw?: boolean;
}): Promise<z.infer<typeof CaptionArray>> {
} & ToneOptions;

export async function generateVariants(params: GeminiVariantParams): Promise<z.infer<typeof CaptionArray>> {
  const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("variants.txt");
  const user=`PLATFORM: ${params.platform}\nVOICE: ${params.voice}\n${params.style ? `STYLE: ${params.style}\n` : ''}${params.mood ? `MOOD: ${params.mood}\n` : ''}IMAGE_FACTS: ${JSON.stringify(params.facts)}\nNSFW: ${params.nsfw || false}\n${params.hint?`HINT:${params.hint}`:""}`;
  let res;
  try {
    res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+user }]);
  } catch (error) {
    console.error('Gemini textModel.generateContent failed:', error);
    throw error;
  }
  const json = stripToJSON(res.response.text()) as unknown[];
  // Fix common safety_level values and missing fields
  if(Array.isArray(json)){
    json.forEach((item) => {
      const variant = item as Record<string, unknown>;
      variant.safety_level = normalizeSafetyLevel(
        typeof variant.safety_level === 'string' ? variant.safety_level : 'normal'
      );
      // Fix other fields
      if(typeof variant.mood !== 'string' || variant.mood.length < 2) variant.mood = "engaging";
      if(typeof variant.style !== 'string' || variant.style.length < 2) variant.style = "authentic";
      if(typeof variant.cta !== 'string' || variant.cta.length < 2) variant.cta = "Check it out";
      if(typeof variant.alt !== 'string' || variant.alt.length < 20) variant.alt = "Engaging social media content";
      if(!Array.isArray(variant.hashtags)) variant.hashtags = ["#content", "#creative", "#amazing"];
      if(typeof variant.caption !== 'string' || variant.caption.length < 1) variant.caption = "Check out this amazing content!";
    });
@@ -276,53 +277,62 @@ export async function rankAndSelect(variants: z.infer<typeof CaptionArray>): Pro
    const winner = json[0] || variants[0];
    json = {
      winner_index: 0,
      scores: [5, 4, 3, 2, 1],
      reason: "Selected based on engagement potential",
      final: winner
    };
  }
  
  // Accept any safety_level in final result
  if((json as Record<string, unknown>).final){
    const final = (json as { final: Record<string, unknown> }).final;
    final.safety_level = normalizeSafetyLevel(
      typeof final.safety_level === 'string' ? final.safety_level : 'normal'
    );
    if(typeof final.mood !== 'string' || final.mood.length<2) final.mood="engaging";
    if(typeof final.style !== 'string' || final.style.length<2) final.style="authentic";
    if(typeof final.cta !== 'string' || final.cta.length<2) final.cta="Check it out";
    if(typeof final.alt !== 'string' || final.alt.length<20) final.alt="Engaging social media content";
    if(!Array.isArray(final.hashtags)) final.hashtags=["#content", "#creative", "#amazing"];
    if(typeof final.caption !== 'string' || final.caption.length<1) final.caption="Check out this amazing content!";
  }
  return RankResult.parse(json);
}

export async function pipeline({ imageUrl, platform, voice = "flirty_playful", style, mood, nsfw = false }: {
type GeminiPipelineArgs = {
  imageUrl: string;
  platform: "instagram" | "x" | "reddit" | "tiktok";
  voice?: string;
  style?: string;
  mood?: string;
  nsfw?: boolean;
}): Promise<CaptionResult> {
} & ToneOptions;

/**
 * Primary image captioning pipeline backed by Gemini vision + text models.
 *
 * @remarks
 * Persona controls such as `style`, `mood`, and future tone keys must persist through
 * retries. When platform validation fails we re-run Gemini with the exact same tone
 * payload so the caller's requested persona stays intact.
 */
export async function pipeline({ imageUrl, platform, voice = "flirty_playful", nsfw = false, ...toneRest }: GeminiPipelineArgs): Promise<CaptionResult> {
  try {
    const tone = extractToneOptions(toneRest);
    const facts = await extractFacts(imageUrl);
    let variants = await generateVariants({ platform, voice, style, mood, facts, nsfw });
    let variants = await generateVariants({ platform, voice, facts, nsfw, ...tone });
    let ranked = await rankAndSelect(variants);
    let out = ranked.final;

    const err = platformChecks(platform, out);
    if (err) {
      variants = await generateVariants({ platform, voice, facts, hint:`Fix: ${err}. Use IMAGE_FACTS nouns/colors/setting explicitly.`, nsfw });
      variants = await generateVariants({ platform, voice, facts, nsfw, ...tone, hint:`Fix: ${err}. Use IMAGE_FACTS nouns/colors/setting explicitly.` });
      ranked = await rankAndSelect(variants);
      out = ranked.final;
    }

    return { provider: 'gemini', facts, variants, ranked, final: out };
  } catch (error) {
    const { openAICaptionFallback } = await import('./openaiFallback');
    const final = await openAICaptionFallback({ platform, voice, imageUrl });
    return { provider: 'openai', final } as CaptionResult;
  }
}
server/caption/rewritePipeline.ts
+31-6
import fs from "node:fs/promises";
import path from "node:path";
import { textModel, visionModel } from "../lib/gemini";
import { CaptionArray, RankResult, platformChecks } from "./schema";
import { normalizeSafetyLevel } from "./normalizeSafetyLevel";
import { extractToneOptions, ToneOptions } from "./toneOptions";

// CaptionResult interface for type safety
interface CaptionResult {
  provider: string;
  final: unknown;
  facts?: unknown;
  variants?: unknown;
  ranked?: unknown;
}

async function load(p:string){ return fs.readFile(path.join(process.cwd(),"prompts",p),"utf8"); }
async function b64(url:string){ const r=await fetch(url); if(!r.ok) throw new Error("fetch failed"); const b=Buffer.from(await r.arrayBuffer()); return b.toString("base64"); }
function stripToJSON(txt:string){ const i=Math.min(...[txt.indexOf("{"),txt.indexOf("[")].filter(x=>x>=0));
  const j=Math.max(txt.lastIndexOf("}"),txt.lastIndexOf("]")); return JSON.parse((i>=0&&j>=0)?txt.slice(i,j+1):txt); }

export async function extractFacts(imageUrl:string){
  const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("extract.txt");
  const img={ inlineData:{ data: await b64(imageUrl), mimeType:"image/jpeg" } };
  try {
    const res=await visionModel.generateContent([{text:sys+"\n"+guard+"\n"+prompt}, img]);
    return stripToJSON(res.response.text());
  } catch (error) {
    console.error('Gemini visionModel.generateContent failed:', error);
    throw error;
  }
}

export async function variantsRewrite(params:{platform:"instagram"|"x"|"reddit"|"tiktok", voice:string, style?:string, mood?:string, existingCaption:string, facts?:Record<string, unknown>, hint?:string, nsfw?:boolean}){
type RewriteVariantsParams = {
  platform:"instagram"|"x"|"reddit"|"tiktok";
  voice:string;
  existingCaption:string;
  facts?:Record<string, unknown>;
  hint?:string;
  nsfw?:boolean;
} & ToneOptions;

export async function variantsRewrite(params:RewriteVariantsParams){
  const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("rewrite.txt");
  const user=`PLATFORM: ${params.platform}\nVOICE: ${params.voice}\n${params.style ? `STYLE: ${params.style}\n` : ''}${params.mood ? `MOOD: ${params.mood}\n` : ''}EXISTING_CAPTION: "${params.existingCaption}"${params.facts?`\nIMAGE_FACTS: ${JSON.stringify(params.facts)}`:""}\nNSFW: ${params.nsfw || false}${params.hint?`\nHINT:${params.hint}`:""}`;
  let res;
  try {
    res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+user }]);
  } catch (error) {
    console.error('Gemini textModel.generateContent failed:', error);
    throw error;
  }
  const json=stripToJSON(res.response.text()) as unknown;
  // Fix common safety_level values and missing fields
  if(Array.isArray(json)){
    json.forEach((item) => {
      const variant = item as Record<string, unknown>;
      variant.safety_level = normalizeSafetyLevel(
        typeof variant.safety_level === 'string' ? variant.safety_level : 'normal'
      );
      // Fix other fields
      if(typeof variant.mood !== 'string' || variant.mood.length<2) variant.mood="engaging";
      if(typeof variant.style !== 'string' || variant.style.length<2) variant.style="authentic";
      if(typeof variant.cta !== 'string' || variant.cta.length<2) variant.cta="Check it out";
      if(typeof variant.alt !== 'string' || variant.alt.length<20) variant.alt="Engaging social media content";
      if(!Array.isArray(variant.hashtags)) variant.hashtags=["#content", "#creative", "#amazing"];
      if(typeof variant.caption !== 'string' || variant.caption.length<1) variant.caption="Check out this amazing content, you'll love it and want more!";
    });
@@ -98,52 +108,67 @@ export async function rankAndSelect(variants: unknown[]){
  if(Array.isArray(json)) {
    const winner = json[0] || variants[0];
    json = {
      winner_index: 0,
      scores: [5, 4, 3, 2, 1],
      reason: "Selected based on engagement potential",
      final: winner
    };
  }
  
  if((json as Record<string, unknown>).final){
    const final = (json as { final: Record<string, unknown> }).final;
    final.safety_level = normalizeSafetyLevel(
      typeof final.safety_level === 'string' ? final.safety_level : 'normal'
    );
    if(typeof final.mood !== 'string' || final.mood.length<2) final.mood="engaging";
    if(typeof final.style !== 'string' || final.style.length<2) final.style="authentic";
    if(typeof final.cta !== 'string' || final.cta.length<2) final.cta="Check it out";
    if(typeof final.alt !== 'string' || final.alt.length<20) final.alt="Engaging social media content";
    if(!Array.isArray(final.hashtags)) final.hashtags=["#content", "#creative", "#amazing"];
    if(typeof final.caption !== 'string' || final.caption.length<1) final.caption="Check out this amazing content!";
  }
  return RankResult.parse(json);
}

export async function pipelineRewrite({ platform, voice="flirty_playful", style, mood, existingCaption, imageUrl, nsfw=false }:{
  platform:"instagram"|"x"|"reddit"|"tiktok", voice?:string, style?:string, mood?:string, existingCaption:string, imageUrl?:string, nsfw?:boolean }){
type RewritePipelineArgs = {
  platform:"instagram"|"x"|"reddit"|"tiktok";
  voice?:string;
  existingCaption:string;
  imageUrl?:string;
  nsfw?:boolean;
} & ToneOptions;

/**
 * Rewriting pipeline that upgrades an existing caption while keeping persona tone.
 *
 * @remarks
 * Platform validation retries must keep the exact tone metadata (`style`, `mood`, etc.)
 * supplied by the caller so the rewritten caption never loses its persona.
 */
export async function pipelineRewrite({ platform, voice="flirty_playful", existingCaption, imageUrl, nsfw=false, ...toneRest }:RewritePipelineArgs){
  try {
    const tone = extractToneOptions(toneRest);
    const facts = imageUrl ? await extractFacts(imageUrl) : undefined;
    let variants = await variantsRewrite({ platform, voice, style, mood, existingCaption, facts, nsfw });
    let variants = await variantsRewrite({ platform, voice, existingCaption, facts, nsfw, ...tone });
    let ranked = await rankAndSelect(variants);
    let out = ranked.final;
    

    // Ensure rewritten caption is longer and more engaging than original
    if(out.caption.length <= existingCaption.length) {
      out.caption = existingCaption + " ✨ Enhanced with engaging content and call-to-action that drives better engagement!";
    }

    const err = platformChecks(platform, out);
    if (err) {
      variants = await variantsRewrite({ platform, voice, existingCaption, facts, hint:`Fix: ${err}. Be specific and engaging.`, nsfw });
      variants = await variantsRewrite({ platform, voice, existingCaption, facts, nsfw, ...tone, hint:`Fix: ${err}. Be specific and engaging.` });
      ranked = await rankAndSelect(variants);
      out = ranked.final;
    }

    return { provider: 'gemini', facts, variants, ranked, final: out };
  } catch (error) {
    const { openAICaptionFallback } = await import('./openaiFallback');
    const final = await openAICaptionFallback({ platform, voice, existingCaption, imageUrl });
    return { provider: 'openai', final } as CaptionResult;
  }
}
server/caption/textOnlyPipeline.ts
+30-5
import fs from "node:fs/promises";
import path from "node:path";
import { textModel } from "../lib/gemini";
import { CaptionArray, RankResult, platformChecks } from "./schema";
import { normalizeSafetyLevel } from "./normalizeSafetyLevel";
import { extractToneOptions, ToneOptions } from "./toneOptions";

async function load(p:string){ return fs.readFile(path.join(process.cwd(),"prompts",p),"utf8"); }
function stripToJSON(txt:string){ const i=Math.min(...[txt.indexOf("{"),txt.indexOf("[")].filter(x=>x>=0));
  const j=Math.max(txt.lastIndexOf("}"),txt.lastIndexOf("]")); return JSON.parse((i>=0&&j>=0)?txt.slice(i,j+1):txt); }

export async function generateVariantsTextOnly(params:{platform:"instagram"|"x"|"reddit"|"tiktok", voice:string, style?:string, mood?:string, theme:string, context?:string, hint?:string, nsfw?:boolean}){
type TextOnlyVariantParams = {
  platform:"instagram"|"x"|"reddit"|"tiktok";
  voice:string;
  theme:string;
  context?:string;
  hint?:string;
  nsfw?:boolean;
} & ToneOptions;

export async function generateVariantsTextOnly(params:TextOnlyVariantParams){
  const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("variants_textonly.txt");
  const user=`PLATFORM: ${params.platform}\nVOICE: ${params.voice}\n${params.style ? `STYLE: ${params.style}\n` : ''}${params.mood ? `MOOD: ${params.mood}\n` : ''}THEME: "${params.theme}"\nCONTEXT: "${params.context||''}"\nNSFW: ${params.nsfw || false}${params.hint?`\nHINT:${params.hint}`:""}`;
  const res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+user }]);
  const raw=stripToJSON(res.response.text());
  const json=Array.isArray(raw)?raw:[raw];
  // Fix common safety_level values and missing fields
  if(Array.isArray(json)){
    json.forEach((item) => {
      const variant = item as Record<string, unknown>;
      variant.safety_level = normalizeSafetyLevel(
        typeof variant.safety_level === 'string' ? variant.safety_level : 'normal'
      );
      // Fix other fields
      if(typeof variant.mood !== 'string' || variant.mood.length<2) variant.mood="engaging";
      if(typeof variant.style !== 'string' || variant.style.length<2) variant.style="authentic";
      if(typeof variant.cta !== 'string' || variant.cta.length<2) variant.cta="Check it out";
      if(typeof variant.alt !== 'string' || variant.alt.length<20) variant.alt="Engaging social media content";
      if(!Array.isArray(variant.hashtags) || variant.hashtags.length < 3) {
        if(params.platform === 'instagram') {
          variant.hashtags=["#content", "#creative", "#amazing", "#lifestyle"];
        } else {
          variant.hashtags=["#content", "#creative", "#amazing"];
        }
      }
      if(typeof variant.caption !== 'string' || variant.caption.length<1) variant.caption="Check out this amazing content!";
@@ -78,40 +88,55 @@ export async function rankAndSelect(variants: unknown[], params?: { platform?: s
    };
  }
  
  // Fix safety_level in final result
  if((json as Record<string, unknown>).final){
    const final = (json as { final: Record<string, unknown> }).final;
    final.safety_level = normalizeSafetyLevel(
      typeof final.safety_level === 'string' ? final.safety_level : 'normal'
    );
    if(typeof final.mood !== 'string' || final.mood.length<2) final.mood="engaging";
    if(typeof final.style !== 'string' || final.style.length<2) final.style="authentic";
    if(typeof final.cta !== 'string' || final.cta.length<2) final.cta="Check it out";
    if(typeof final.alt !== 'string' || final.alt.length<20) final.alt="Engaging social media content";
    if(!Array.isArray(final.hashtags) || final.hashtags.length < 3) {
      if(params?.platform === 'instagram') {
        final.hashtags=["#content", "#creative", "#amazing", "#lifestyle"];
      } else {
        final.hashtags=["#content", "#creative", "#amazing"];
      }
    }
    if(typeof final.caption !== 'string' || final.caption.length<1) final.caption="Check out this amazing content!";
  }
  return RankResult.parse(json);
}

export async function pipelineTextOnly({ platform, voice="flirty_playful", style, mood, theme, context, nsfw=false }:{
  platform:"instagram"|"x"|"reddit"|"tiktok", voice?:string, style?:string, mood?:string, theme:string, context?:string, nsfw?:boolean }){
  let variants = await generateVariantsTextOnly({ platform, voice, style, mood, theme, context, nsfw });
type TextOnlyPipelineArgs = {
  platform:"instagram"|"x"|"reddit"|"tiktok";
  voice?:string;
  theme:string;
  context?:string;
  nsfw?:boolean;
} & ToneOptions;

/**
 * Text-only caption pipeline for brainstorming without an image upload.
 *
 * @remarks
 * Persona settings (`style`, `mood`, etc.) are forwarded to every Gemini retry so the
 * voice remains consistent even when a platform validation retry is required.
 */
export async function pipelineTextOnly({ platform, voice="flirty_playful", theme, context, nsfw=false, ...toneRest }:TextOnlyPipelineArgs){
  const tone = extractToneOptions(toneRest);
  let variants = await generateVariantsTextOnly({ platform, voice, theme, context, nsfw, ...tone });
  let ranked = await rankAndSelect(variants, { platform, nsfw });
  let out = ranked.final;

  const err = platformChecks(platform, out);
  if (err) {
    variants = await generateVariantsTextOnly({ platform, voice, theme, context, hint:`Fix: ${err}. Be specific and engaging.`, nsfw });
    variants = await generateVariantsTextOnly({ platform, voice, theme, context, nsfw, ...tone, hint:`Fix: ${err}. Be specific and engaging.` });
    ranked = await rankAndSelect(variants);
    out = ranked.final;
  }

  return { variants, ranked, final: out };
}
server/caption/toneOptions.ts
New
+16-0
export type ToneOptions = {
  style?: string;
  mood?: string;
} & Partial<Record<string, string>>;

export function extractToneOptions(input: Record<string, unknown>): ToneOptions {
  const tone: Record<string, string> = {};

  for (const [key, value] of Object.entries(input)) {
    if (typeof value === 'string') {
      tone[key] = value;
    }
  }

  return tone as ToneOptions;
}
tests/unit/caption/pipeline-tone-retry.test.ts
New
+190-0
import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';

interface MockGeminiResponse {
  response: { text: () => string };
}

interface MockVariant {
  caption: string;
  alt: string;
  hashtags: string[];
  cta: string;
  mood: string;
  style: string;
  safety_level: string;
  nsfw: boolean;
}

const createTextModelMock = () => ({
  generateContent: vi.fn<
    [Array<{ text: string }>],
    Promise<MockGeminiResponse>
  >()
});

const createMockResponse = (payload: string): MockGeminiResponse => ({
  response: { text: () => payload }
});

const createVariantSet = (caption: string, hashtags: string[]) => {
  const base: MockVariant = {
    caption,
    alt: 'Detailed alt text describing the content for regression testing.',
    hashtags,
    cta: 'Check it out',
    mood: 'Upbeat',
    style: 'Bold Persona',
    safety_level: 'normal',
    nsfw: false
  };

  const variants = Array.from({ length: 5 }, (_, index) => ({
    ...base,
    caption: `${caption} v${index}`
  }));

  return {
    variants,
    payload: JSON.stringify(variants)
  };
};

const createRankingPayload = (variant: MockVariant) => JSON.stringify({
  winner_index: 0,
  scores: [5, 4, 3, 2, 1],
  reason: 'Persona retention regression test',
  final: variant
});

const extractVariantPrompts = (calls: Array<[Array<{ text: string }>]>) => calls
  .map(call => call[0]?.[0]?.text ?? '')
  .filter(text => text.includes('PLATFORM:'));

describe('Gemini pipelines keep persona tone on retry', () => {
  beforeEach(() => {
    vi.resetModules();
  });

  afterEach(() => {
    vi.clearAllMocks();
    vi.restoreAllMocks();
  });

  it('forwards tone fields on image pipeline retry', async () => {
    const textModel = createTextModelMock();
    const visionModel = { generateContent: vi.fn() };

    vi.doMock('../../../server/lib/gemini.js', () => ({ textModel, visionModel }));

    const fetchMock = vi.spyOn(global, 'fetch');
    fetchMock.mockResolvedValue({
      ok: true,
      headers: new Headers({ 'content-type': 'image/jpeg' }),
      arrayBuffer: async () => Buffer.alloc(256, 1)
    } as unknown as Response);

    visionModel.generateContent.mockResolvedValue({
      response: { text: () => JSON.stringify({ objects: ['subject'], setting: 'studio', mood: 'focused' }) }
    });

    const geminiModule = await import('../../../server/caption/geminiPipeline.js');

    const failing = createVariantSet('First attempt caption exceeding X rules', ['#one', '#two', '#three', '#four']);
    const passing = createVariantSet('Second attempt caption obeys X rules', ['#one', '#two']);

    textModel.generateContent
      .mockResolvedValueOnce(createMockResponse(failing.payload))
      .mockResolvedValueOnce(createMockResponse(createRankingPayload(failing.variants[0])))
      .mockResolvedValueOnce(createMockResponse(passing.payload))
      .mockResolvedValueOnce(createMockResponse(createRankingPayload(passing.variants[0])));

    await geminiModule.pipeline({
      imageUrl: 'https://example.com/image.png',
      platform: 'x',
      voice: 'Persona Voice',
      style: 'Bold Persona',
      mood: 'Upbeat',
      nsfw: false
    });

    const variantPrompts = extractVariantPrompts(textModel.generateContent.mock.calls);

    expect(variantPrompts).toHaveLength(2);
    const retryPrompt = variantPrompts[1];
    expect(retryPrompt).toContain('Fix:');
    expect(retryPrompt).toContain('STYLE: Bold Persona');
    expect(retryPrompt).toContain('MOOD: Upbeat');

    fetchMock.mockRestore();
  });

  it('forwards tone fields on rewrite pipeline retry', async () => {
    const textModel = createTextModelMock();
    const visionModel = { generateContent: vi.fn() };

    vi.doMock('../../../server/lib/gemini.js', () => ({ textModel, visionModel }));

    const rewriteModule = await import('../../../server/caption/rewritePipeline.js');

    const failing = createVariantSet('Rewrite attempt fails platform rules', ['#one', '#two', '#three', '#four']);
    const passing = createVariantSet('Rewrite attempt passes platform rules', ['#one', '#two']);

    textModel.generateContent
      .mockResolvedValueOnce(createMockResponse(failing.payload))
      .mockResolvedValueOnce(createMockResponse(createRankingPayload(failing.variants[0])))
      .mockResolvedValueOnce(createMockResponse(passing.payload))
      .mockResolvedValueOnce(createMockResponse(createRankingPayload(passing.variants[0])));

    await rewriteModule.pipelineRewrite({
      platform: 'x',
      voice: 'Persona Voice',
      style: 'Bold Persona',
      mood: 'Upbeat',
      existingCaption: 'Original',
      nsfw: false
    });

    const variantPrompts = extractVariantPrompts(textModel.generateContent.mock.calls);

    expect(variantPrompts).toHaveLength(2);
    const retryPrompt = variantPrompts[1];
    expect(retryPrompt).toContain('Fix:');
    expect(retryPrompt).toContain('STYLE: Bold Persona');
    expect(retryPrompt).toContain('MOOD: Upbeat');
  });

  it('forwards tone fields on text-only pipeline retry', async () => {
    const textModel = createTextModelMock();

    vi.doMock('../../../server/lib/gemini.js', () => ({ textModel }));

    const textOnlyModule = await import('../../../server/caption/textOnlyPipeline.js');

    const failing = createVariantSet('Text-only attempt fails platform rules', ['#one', '#two', '#three', '#four']);
    const passing = createVariantSet('Text-only attempt passes platform rules', ['#one', '#two']);

    textModel.generateContent
      .mockResolvedValueOnce(createMockResponse(failing.payload))
      .mockResolvedValueOnce(createMockResponse(createRankingPayload(failing.variants[0])))
      .mockResolvedValueOnce(createMockResponse(passing.payload))
      .mockResolvedValueOnce(createMockResponse(createRankingPayload(passing.variants[0])));

    await textOnlyModule.pipelineTextOnly({
      platform: 'x',
      voice: 'Persona Voice',
      theme: 'Testing theme',
      context: 'Testing context',
      style: 'Bold Persona',
      mood: 'Upbeat',
      nsfw: false
    });

    const variantPrompts = extractVariantPrompts(textModel.generateContent.mock.calls);

    expect(variantPrompts).toHaveLength(2);
    const retryPrompt = variantPrompts[1];
    expect(retryPrompt).toContain('Fix:');
    expect(retryPrompt).toContain('STYLE: Bold Persona');
    expect(retryPrompt).toContain('MOOD: Upbeat');
  });
});
