Add shared helper for serializePromptField
Sep 20 · a1davida1/TPilot · main
+277-30
1. Add a shared helper in `server/caption` (e.g., `serializePromptField(value: string)`), which returns a safely escaped representation (`JSON.stringify` + strip surrounding quotes for block fields; replace control characters with spaces).
2. Use the helper everywhere a prompt template currently embeds user-provided `existingCaption`, `theme`, `context`, or `hint`—namely in `geminiPipeline.generateVariants`, `rewritePipeline.variantsRewrite`, `textOnlyPipeline.generateVariantsTextOnly`, and all branches of `openaiFallback` message construction.
3. Extend the unit tests in `tests/routes/caption-generation.test.ts` with captions containing quotes/newlines to confirm the sanitized prompts still yield valid JSON and high-quality outputs (mock Gemini/OpenAI to echo the request they saw and assert the escaped form).

Summary

    Added a shared serializePromptField helper that strips control characters and returns JSON-safe fragments, then used it when building Gemini, rewrite, and text-only prompt strings so hints and captions with quotes/newlines stay valid.

Sanitized every OpenAI fallback branch by reusing the helper before embedding existingCaption, preventing malformed payloads in both vision and text-only flows.

Expanded caption-generation route tests to capture the prompts sent to Gemini and OpenAI, asserting the escaped forms for hints, themes, contexts, and existing captions that include quotes/newlines.

Testing

    ✅ npm run lint

⚠️ npm test (fails because many legacy integration/unit suites rely on external services and missing env/mocks outside this change)


server/caption/geminiPipeline.ts
+3-1
import fs from "node:fs/promises";
import path from "node:path";
import { z } from "zod";
import { visionModel, textModel } from "../lib/gemini";
import { CaptionArray, CaptionItem, RankResult, platformChecks } from "./schema";
import { normalizeSafetyLevel } from "./normalizeSafetyLevel";
import { serializePromptField } from "./promptUtils";

// Custom error class for image validation failures
export class InvalidImageError extends Error {
  constructor(message: string) {
    super(message);
    this.name = 'InvalidImageError';
  }
}

// CaptionResult interface for type safety
interface CaptionResult {
  provider: string;
  final: z.infer<typeof CaptionItem>;
  facts?: Record<string, unknown>;
  variants?: z.infer<typeof CaptionArray>;
  ranked?: z.infer<typeof RankResult>;
}

async function load(p: string): Promise<string> {
  return fs.readFile(path.join(process.cwd(), "prompts", p), "utf8");
}
async function b64(url: string): Promise<{ base64: string; mimeType: string }> {
  try {
    const r = await fetch(url);
    if (!r.ok) throw new InvalidImageError(`fetch failed: ${r.status} ${r.statusText}`);
@@ -187,51 +188,52 @@ export async function extractFacts(imageUrl: string): Promise<Record<string, unk
          angles: ['dynamic'],
          mood: 'playful',
          style: 'animated'
        };
      }
      
      throw error;
    }
  } catch (error) {
    console.error('Error in extractFacts:', error);
    if (error instanceof InvalidImageError) throw error;
    throw new Error(`Failed to extract facts: ${error instanceof Error ? error.message : String(error)}`);
  }
}

export async function generateVariants(params: {
  platform: "instagram" | "x" | "reddit" | "tiktok";
  voice: string;
  style?: string;
  mood?: string;
  facts: Record<string, unknown>;
  hint?: string;
  nsfw?: boolean;
}): Promise<z.infer<typeof CaptionArray>> {
  const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("variants.txt");
  const user=`PLATFORM: ${params.platform}\nVOICE: ${params.voice}\n${params.style ? `STYLE: ${params.style}\n` : ''}${params.mood ? `MOOD: ${params.mood}\n` : ''}IMAGE_FACTS: ${JSON.stringify(params.facts)}\nNSFW: ${params.nsfw || false}\n${params.hint?`HINT:${params.hint}`:""}`;
  const hint = params.hint ? `HINT:${serializePromptField(params.hint, { block: true })}` : "";
  const user=`PLATFORM: ${params.platform}\nVOICE: ${params.voice}\n${params.style ? `STYLE: ${params.style}\n` : ''}${params.mood ? `MOOD: ${params.mood}\n` : ''}IMAGE_FACTS: ${JSON.stringify(params.facts)}\nNSFW: ${params.nsfw || false}\n${hint}`;
  let res;
  try {
    res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+user }]);
  } catch (error) {
    console.error('Gemini textModel.generateContent failed:', error);
    throw error;
  }
  const json = stripToJSON(res.response.text()) as unknown[];
  // Fix common safety_level values and missing fields
  if(Array.isArray(json)){
    json.forEach((item) => {
      const variant = item as Record<string, unknown>;
      variant.safety_level = normalizeSafetyLevel(
        typeof variant.safety_level === 'string' ? variant.safety_level : 'normal'
      );
      // Fix other fields
      if(typeof variant.mood !== 'string' || variant.mood.length < 2) variant.mood = "engaging";
      if(typeof variant.style !== 'string' || variant.style.length < 2) variant.style = "authentic";
      if(typeof variant.cta !== 'string' || variant.cta.length < 2) variant.cta = "Check it out";
      if(typeof variant.alt !== 'string' || variant.alt.length < 20) variant.alt = "Engaging social media content";
      if(!Array.isArray(variant.hashtags)) variant.hashtags = ["#content", "#creative", "#amazing"];
      if(typeof variant.caption !== 'string' || variant.caption.length < 1) variant.caption = "Check out this amazing content!";
    });

    // Ensure exactly 5 variants by padding with variations if needed
server/caption/openaiFallback.ts
+8-6
import OpenAI from 'openai';
import * as z from 'zod';
import { serializePromptField } from './promptUtils';

// Assuming CaptionItem is defined elsewhere and imported
// For the purpose of this example, let's define a placeholder if it's not provided
const CaptionItem = z.object({
  caption: z.string(),
  hashtags: z.array(z.string()),
  safety_level: z.string(),
  mood: z.string(),
  style: z.string(),
  cta: z.string(),
  alt: z.string(),
  nsfw: z.boolean()
});

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY || '' });

export interface FallbackParams {
  platform: string;
  voice: string;
  imageUrl?: string;
  theme?: string;
  context?: string;
  existingCaption?: string;
}

export async function openAICaptionFallback({
  platform,
  voice = "flirty_playful",
  imageUrl,
  existingCaption
}: {
  platform: "instagram" | "x" | "reddit" | "tiktok";
  voice?: string;
  imageUrl?: string;
  existingCaption?: string;
}): Promise<z.infer<typeof CaptionItem>> {
  let messages: any[] = [];
  const sanitizedExistingCaption = existingCaption ? serializePromptField(existingCaption) : undefined;

  if (imageUrl && openai) {
    try {
      console.log('OpenAI fallback: Analyzing image for accurate captions');

      if (imageUrl.startsWith('data:')) {
        // For data URLs, we can send directly to OpenAI vision
        messages = [
          {
            role: "system",
            content: `You are an expert social media caption writer. Analyze the image carefully and create engaging ${voice} content for ${platform} that directly relates to what you see.

Return ONLY a JSON object with this structure:
{
  "caption": "engaging caption text that describes what's actually in the image",
  "hashtags": ["#relevant", "#to", "#image"],
  "safety_level": "safe_for_work",
  "mood": "${voice.includes('flirty') ? 'flirty' : 'confident'}",
  "style": "authentic",
  "cta": "relevant call to action",
  "alt": "detailed description of what's actually in the image",
  "nsfw": false
}`
          },
          {
            role: "user",
            content: [
              {
                type: "text",
                text: existingCaption
                  ? `Analyze this image and rewrite this caption to better match what you see: "${existingCaption}"`
                text: sanitizedExistingCaption
                  ? `Analyze this image and rewrite this caption to better match what you see: ${sanitizedExistingCaption}`
                  : `Analyze this image and create a caption that describes what you actually see`
              },
              {
                type: "image_url",
                image_url: { url: imageUrl }
              }
            ]
          }
        ];
      } else {
        // For regular URLs, describe the image request
        messages = [
          {
            role: "system",
            content: `Create engaging ${voice} content for ${platform} based on the image.`
          },
          {
            role: "user",
            content: `Create a caption for an image at: ${imageUrl.substring(0, 100)}...`
          }
        ];
      }
    } catch (error) {
      console.warn('Image analysis failed, using text-only fallback:', error);
      messages = [
        {
          role: "system",
          content: `You are an expert social media caption writer. Create engaging ${voice} content for ${platform}.`
        },
        {
          role: "user",
          content: existingCaption
            ? `Rewrite this caption: "${existingCaption}"`
          content: sanitizedExistingCaption
            ? `Rewrite this caption: ${sanitizedExistingCaption}`
            : `Create engaging ${voice} content for ${platform}`
        }
      ];
    }
  } else {
    messages = [
      {
        role: "system",
        content: `You are an expert social media caption writer. Create engaging ${voice} content for ${platform}.`
      },
      {
        role: "user",
        content: existingCaption
          ? `Rewrite this caption: "${existingCaption}"`
        content: sanitizedExistingCaption
          ? `Rewrite this caption: ${sanitizedExistingCaption}`
          : `Create engaging ${voice} content for ${platform}`
      }
    ];
  }

  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages,
      response_format: { type: "json_object" },
      max_tokens: 500
    });

    let json: unknown;
    try {
      json = JSON.parse(response.choices[0].message.content || '{}');
    } catch (e) {
      console.error("Error parsing JSON response from OpenAI:", e);
      console.error("OpenAI response content:", response.choices[0].message.content);
      // Fallback to a simpler structure if JSON parsing fails
      json = { caption: response.choices[0].message.content || 'Fallback caption' };
    }

    const jsonData: any = json;
    return {
server/caption/promptUtils.ts
New
+12-0
export function serializePromptField(value: string, options?: { block?: boolean }): string {
  let sanitized = "";
  for (let index = 0; index < value.length; index += 1) {
    const code = value.charCodeAt(index);
    sanitized += code < 32 || code === 127 ? " " : value[index];
  }
  const quoted = JSON.stringify(sanitized);
  if (options?.block && quoted.length >= 2) {
    return quoted.slice(1, -1);
  }
  return quoted;
}
server/caption/rewritePipeline.ts
+3-1
import fs from "node:fs/promises";
import path from "node:path";
import { textModel, visionModel } from "../lib/gemini";
import { CaptionArray, RankResult, platformChecks } from "./schema";
import { normalizeSafetyLevel } from "./normalizeSafetyLevel";
import { serializePromptField } from "./promptUtils";

// CaptionResult interface for type safety
interface CaptionResult {
  provider: string;
  final: unknown;
  facts?: unknown;
  variants?: unknown;
  ranked?: unknown;
}

async function load(p:string){ return fs.readFile(path.join(process.cwd(),"prompts",p),"utf8"); }
async function b64(url:string){ const r=await fetch(url); if(!r.ok) throw new Error("fetch failed"); const b=Buffer.from(await r.arrayBuffer()); return b.toString("base64"); }
function stripToJSON(txt:string){ const i=Math.min(...[txt.indexOf("{"),txt.indexOf("[")].filter(x=>x>=0));
  const j=Math.max(txt.lastIndexOf("}"),txt.lastIndexOf("]")); return JSON.parse((i>=0&&j>=0)?txt.slice(i,j+1):txt); }

export async function extractFacts(imageUrl:string){
  const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("extract.txt");
  const img={ inlineData:{ data: await b64(imageUrl), mimeType:"image/jpeg" } };
  try {
    const res=await visionModel.generateContent([{text:sys+"\n"+guard+"\n"+prompt}, img]);
    return stripToJSON(res.response.text());
  } catch (error) {
    console.error('Gemini visionModel.generateContent failed:', error);
    throw error;
  }
}

export async function variantsRewrite(params:{platform:"instagram"|"x"|"reddit"|"tiktok", voice:string, style?:string, mood?:string, existingCaption:string, facts?:Record<string, unknown>, hint?:string, nsfw?:boolean}){
  const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("rewrite.txt");
  const user=`PLATFORM: ${params.platform}\nVOICE: ${params.voice}\n${params.style ? `STYLE: ${params.style}\n` : ''}${params.mood ? `MOOD: ${params.mood}\n` : ''}EXISTING_CAPTION: "${params.existingCaption}"${params.facts?`\nIMAGE_FACTS: ${JSON.stringify(params.facts)}`:""}\nNSFW: ${params.nsfw || false}${params.hint?`\nHINT:${params.hint}`:""}`;
  const hint = params.hint ? `\nHINT:${serializePromptField(params.hint, { block: true })}` : "";
  const user=`PLATFORM: ${params.platform}\nVOICE: ${params.voice}\n${params.style ? `STYLE: ${params.style}\n` : ''}${params.mood ? `MOOD: ${params.mood}\n` : ''}EXISTING_CAPTION: ${serializePromptField(params.existingCaption)}${params.facts?`\nIMAGE_FACTS: ${JSON.stringify(params.facts)}`:""}\nNSFW: ${params.nsfw || false}${hint}`;
  let res;
  try {
    res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+user }]);
  } catch (error) {
    console.error('Gemini textModel.generateContent failed:', error);
    throw error;
  }
  const json=stripToJSON(res.response.text()) as unknown;
  // Fix common safety_level values and missing fields
  if(Array.isArray(json)){
    json.forEach((item) => {
      const variant = item as Record<string, unknown>;
      variant.safety_level = normalizeSafetyLevel(
        typeof variant.safety_level === 'string' ? variant.safety_level : 'normal'
      );
      // Fix other fields
      if(typeof variant.mood !== 'string' || variant.mood.length<2) variant.mood="engaging";
      if(typeof variant.style !== 'string' || variant.style.length<2) variant.style="authentic";
      if(typeof variant.cta !== 'string' || variant.cta.length<2) variant.cta="Check it out";
      if(typeof variant.alt !== 'string' || variant.alt.length<20) variant.alt="Engaging social media content";
      if(!Array.isArray(variant.hashtags)) variant.hashtags=["#content", "#creative", "#amazing"];
      if(typeof variant.caption !== 'string' || variant.caption.length<1) variant.caption="Check out this amazing content, you'll love it and want more!";
    });

    // Ensure exactly 5 variants by padding with variations if needed
server/caption/textOnlyPipeline.ts
+3-1
import fs from "node:fs/promises";
import path from "node:path";
import { textModel } from "../lib/gemini";
import { CaptionArray, RankResult, platformChecks } from "./schema";
import { normalizeSafetyLevel } from "./normalizeSafetyLevel";
import { serializePromptField } from "./promptUtils";

async function load(p:string){ return fs.readFile(path.join(process.cwd(),"prompts",p),"utf8"); }
function stripToJSON(txt:string){ const i=Math.min(...[txt.indexOf("{"),txt.indexOf("[")].filter(x=>x>=0));
  const j=Math.max(txt.lastIndexOf("}"),txt.lastIndexOf("]")); return JSON.parse((i>=0&&j>=0)?txt.slice(i,j+1):txt); }

export async function generateVariantsTextOnly(params:{platform:"instagram"|"x"|"reddit"|"tiktok", voice:string, style?:string, mood?:string, theme:string, context?:string, hint?:string, nsfw?:boolean}){
  const sys=await load("system.txt"), guard=await load("guard.txt"), prompt=await load("variants_textonly.txt");
  const user=`PLATFORM: ${params.platform}\nVOICE: ${params.voice}\n${params.style ? `STYLE: ${params.style}\n` : ''}${params.mood ? `MOOD: ${params.mood}\n` : ''}THEME: "${params.theme}"\nCONTEXT: "${params.context||''}"\nNSFW: ${params.nsfw || false}${params.hint?`\nHINT:${params.hint}`:""}`;
  const hint = params.hint ? `\nHINT:${serializePromptField(params.hint, { block: true })}` : "";
  const user=`PLATFORM: ${params.platform}\nVOICE: ${params.voice}\n${params.style ? `STYLE: ${params.style}\n` : ''}${params.mood ? `MOOD: ${params.mood}\n` : ''}THEME: ${serializePromptField(params.theme)}\nCONTEXT: ${serializePromptField(params.context ?? '')}\nNSFW: ${params.nsfw || false}${hint}`;
  const res=await textModel.generateContent([{ text: sys+"\n"+guard+"\n"+prompt+"\n"+user }]);
  const raw=stripToJSON(res.response.text());
  const json=Array.isArray(raw)?raw:[raw];
  // Fix common safety_level values and missing fields
  if(Array.isArray(json)){
    json.forEach((item) => {
      const variant = item as Record<string, unknown>;
      variant.safety_level = normalizeSafetyLevel(
        typeof variant.safety_level === 'string' ? variant.safety_level : 'normal'
      );
      // Fix other fields
      if(typeof variant.mood !== 'string' || variant.mood.length<2) variant.mood="engaging";
      if(typeof variant.style !== 'string' || variant.style.length<2) variant.style="authentic";
      if(typeof variant.cta !== 'string' || variant.cta.length<2) variant.cta="Check it out";
      if(typeof variant.alt !== 'string' || variant.alt.length<20) variant.alt="Engaging social media content";
      if(!Array.isArray(variant.hashtags) || variant.hashtags.length < 3) {
        if(params.platform === 'instagram') {
          variant.hashtags=["#content", "#creative", "#amazing", "#lifestyle"];
        } else {
          variant.hashtags=["#content", "#creative", "#amazing"];
        }
      }
      if(typeof variant.caption !== 'string' || variant.caption.length<1) variant.caption="Check out this amazing content!";
    });

tests/routes/caption-generation.test.ts
+248-21
import { describe, it, expect, beforeEach, vi } from 'vitest';
import { pipeline } from '../../server/caption/geminiPipeline.js';
import { pipelineRewrite } from '../../server/caption/rewritePipeline.js';
import { pipelineTextOnly } from '../../server/caption/textOnlyPipeline.js';
import { pipeline, generateVariants } from '../../server/caption/geminiPipeline.js';
import { pipelineRewrite, variantsRewrite } from '../../server/caption/rewritePipeline.js';
import { pipelineTextOnly, generateVariantsTextOnly } from '../../server/caption/textOnlyPipeline.js';

const openAICreateMock = vi.fn();

vi.mock('openai', () => ({
  __esModule: true,
  default: vi.fn(() => ({
    chat: {
      completions: {
        create: openAICreateMock,
      },
    },
  })),
}));

// Mock dependencies
vi.mock('../../server/lib/gemini.js', () => ({
  textModel: {
    generateContent: vi.fn(),
  },
  visionModel: {
    generateContent: vi.fn(),
  },
}));

vi.mock('../../server/caption/openaiFallback.js', () => ({
  openAICaptionFallback: vi.fn().mockResolvedValue({
    caption: 'Fallback caption',
    hashtags: ['#fallback1', '#fallback2', '#fallback3'],
    safety_level: 'normal',
    alt: 'Fallback alt text that is sufficiently long',
    mood: 'neutral',
    style: 'informative',
    cta: 'Check this out',
    nsfw: false,
  }),
}));

vi.mock('../../server/storage.ts', () => ({
  storage: {
    getUserById: vi.fn(),
    createContentGeneration: vi.fn(),
    updateContentGeneration: vi.fn(),
  },
}));

describe('Caption Generation', () => {
  beforeEach(() => {
    vi.clearAllMocks();
    openAICreateMock.mockReset();
    openAICreateMock.mockResolvedValue({
      choices: [
        {
          message: {
            content: JSON.stringify({
              caption: 'Fallback caption',
              hashtags: ['#fallback1', '#fallback2', '#fallback3'],
              safety_level: 'normal',
              mood: 'neutral',
              style: 'informative',
              cta: 'Check this out',
              alt: 'Fallback alt text that is sufficiently long',
              nsfw: false,
            }),
          },
        },
      ],
    });
  });

  describe('Gemini Pipeline', () => {
    it('should handle image-based caption generation', async () => {
      const mockImageUrl =
        'data:image/jpeg;base64,' +
        '/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAP///////////////wAALCAABAAEBAREA/8QAFAABAAAAAAAAAAAAAAAAAAAACP/EABQQAQAAAAAAAAAAAAAAAAAAAAD/2gAIAQEAAD8Af//Z';
      const mockPlatform = 'instagram';
      const mockVoice = 'flirty_playful';

      // Mock successful responses
      const mockFactsResponse = {
        response: {
          text: () => JSON.stringify({
            objects: ['woman', 'lingerie'],
            setting: 'bedroom',
            mood: 'seductive',
          }),
        },
      };

      const mockVariantsResponse = {
        response: {
          text: () =>
            JSON.stringify([
@@ -81,139 +100,347 @@ describe('Caption Generation', () => {
          text: () =>
            JSON.stringify({
              winner_index: 0,
              scores: [5, 4, 3, 2, 1],
              reason: 'Selected based on engagement potential',
              final: {
                caption: 'Feeling gorgeous tonight ✨',
                hashtags: ['#lingerie', '#confidence', '#style'],
                safety_level: 'spicy_safe',
                mood: 'confident',
                style: 'authentic',
                cta: 'What do you think?',
                alt: 'A glamorous example alt text to satisfy schema',
                nsfw: false,
              },
            }),
        },
      };

      const { textModel, visionModel } = await import('../../server/lib/gemini.js');
      (visionModel.generateContent as any).mockResolvedValueOnce(mockFactsResponse);
      (textModel.generateContent as any)
        .mockResolvedValueOnce(mockVariantsResponse)
        .mockResolvedValueOnce(mockRankResponse);

      const fallbackModule = await import('../../server/caption/openaiFallback.js');
      const fallbackSpy = vi.spyOn(fallbackModule, 'openAICaptionFallback');

      const result = await pipeline({
        imageUrl: mockImageUrl,
        platform: mockPlatform,
        voice: mockVoice,
      });

      const { openAICaptionFallback } = await import('../../server/caption/openaiFallback.js');

      expect(openAICaptionFallback).not.toHaveBeenCalled();
      expect(fallbackSpy).not.toHaveBeenCalled();
      expect(result.final).toMatchObject({
        caption: expect.any(String),
        safety_level: expect.stringMatching(/safe|low|spicy_safe/),
      });
      fallbackSpy.mockRestore();
    });

    it('should handle safety level normalization', async () => {
      const mockResponse = {
        response: {
          text: () => JSON.stringify([
            {
              caption: 'Test caption',
              hashtags: ['#test'],
              safety_level: 'spicy_safe', // Should be normalized to spicy_safe
              mood: 'confident',
              style: 'authentic',
              cta: 'Check it out',
            },
          ]),
        },
      };

      const { textModel } = await import('../../server/lib/gemini.js');
      (textModel.generateContent as any).mockResolvedValue(mockResponse);

      // This would normally be called as part of the pipeline
      const { generateVariants } = await import('../../server/caption/geminiPipeline.js');
      const result = await generateVariants({
        platform: 'instagram',
        voice: 'flirty_playful',
        facts: { objects: ['test'] },
      });

      expect(result[0].safety_level).toBe('spicy_safe');
    });

    it('sanitizes hints before embedding them into Gemini prompts', async () => {
      const specialHint = 'Focus on "colors"\nand vibe';
      const { textModel } = await import('../../server/lib/gemini.js');
      const textModelMock = vi.mocked(textModel.generateContent);
      let promptBody = '';

      textModelMock.mockImplementationOnce(async (input: unknown[]) => {
        const first = input[0] as { text: string };
        promptBody = first.text;
        return {
          response: {
            text: () =>
              JSON.stringify([
                {
                  caption: 'Variant caption ready for testing',
                  hashtags: ['#content', '#creative', '#amazing'],
                  safety_level: 'normal',
                  mood: 'confident',
                  style: 'authentic',
                  cta: 'Check it out',
                  alt: 'Detailed alternative text example for testing prompts',
                  nsfw: false,
                },
              ]),
          },
        };
      });

      const variants = await generateVariants({
        platform: 'instagram',
        voice: 'flirty_playful',
        facts: { objects: ['camera'] },
        hint: specialHint,
      });

      expect(promptBody).toContain('HINT:Focus on \\"colors\\" and vibe');
      expect(variants[0].caption).toBe('Variant caption ready for testing');
    });
  });

  describe('Text-Only Pipeline', () => {
    it('should generate content without image context', async () => {
      const mockResponse = {
        response: {
          text: () => JSON.stringify([
            {
              caption: 'Motivational content for today!',
              hashtags: ['#motivation', '#mindset'],
              safety_level: 'normal',
              mood: 'inspiring',
              style: 'authentic',
              cta: 'What motivates you?',
            },
          ]),
        },
      };

      const { textModel } = await import('../../server/lib/gemini.js');
      (textModel.generateContent as any).mockResolvedValue(mockResponse);

      const result = await pipelineTextOnly({
        platform: 'instagram',
        voice: 'inspiring',
        theme: 'motivation',
        context: 'morning motivation post',
      });

      expect(result.final).toMatchObject({
        caption: expect.stringContaining('Motivational'),
        safety_level: 'normal',
      });
    });

    it('sanitizes theme, context, and hint values for text-only prompts', async () => {
      const specialTheme = 'Summer "Vibes"\nSale';
      const specialContext = 'Line one\nLine two "Quote"';
      const specialHint = 'Boost "sales"\nfast';
      const { textModel } = await import('../../server/lib/gemini.js');
      const textModelMock = vi.mocked(textModel.generateContent);
      let promptBody = '';

      textModelMock.mockImplementationOnce(async (input: unknown[]) => {
        const first = input[0] as { text: string };
        promptBody = first.text;
        return {
          response: {
            text: () =>
              JSON.stringify([
                {
                  caption: 'Sanitized variant caption',
                  hashtags: ['#content', '#creative', '#amazing'],
                  safety_level: 'normal',
                  mood: 'confident',
                  style: 'authentic',
                  cta: 'Check it out',
                  alt: 'Detailed alternative text example for text-only pipeline prompts',
                  nsfw: false,
                },
              ]),
          },
        };
      });

      const variants = await generateVariantsTextOnly({
        platform: 'instagram',
        voice: 'inspiring',
        theme: specialTheme,
        context: specialContext,
        hint: specialHint,
      });

      expect(promptBody).toContain('THEME: "Summer \\"Vibes\\" Sale"');
      expect(promptBody).toContain('CONTEXT: "Line one Line two \\"Quote\\""');
      expect(promptBody).toContain('HINT:Boost \\"sales\\" fast');
      expect(variants[0].caption).toBe('Sanitized variant caption');
    });
  });

  describe('Rewrite Pipeline', () => {
    it('should improve existing captions', async () => {
      const existingCaption = 'Basic caption here';
      const mockResponse = {
        response: {
          text: () => JSON.stringify([
            {
              caption: 'Enhanced and engaging caption! ✨',
              hashtags: ['#enhanced', '#content'],
              safety_level: 'normal',
              mood: 'engaging',
              style: 'authentic',
              cta: 'What do you think?',
            },
          ]),
        },
      };

      const { textModel } = await import('../../server/lib/gemini.js');
      const genSpy = vi.spyOn(textModel, 'generateContent').mockResolvedValue(mockResponse as any);

      const result = await pipelineRewrite({
        platform: 'instagram',
        voice: 'engaging',
        existingCaption,
      });

      expect(result.final.caption).not.toBe(existingCaption);
      expect(result.final.caption).toContain('Enhanced');

      genSpy.mockRestore();
    });

    it('sanitizes existing captions and hints for rewrite prompts', async () => {
      const messyCaption = 'Original "quote"\nwith newline';
      const messyHint = 'Focus on "engagement"\nplease';
      const { textModel } = await import('../../server/lib/gemini.js');
      const textModelMock = vi.mocked(textModel.generateContent);
      let promptBody = '';

      textModelMock.mockImplementationOnce(async (input: unknown[]) => {
        const first = input[0] as { text: string };
        promptBody = first.text;
        return {
          response: {
            text: () =>
              JSON.stringify([
                {
                  caption: 'Enhanced and engaging caption! ✨',
                  hashtags: ['#enhanced', '#content'],
                  safety_level: 'normal',
                  mood: 'engaging',
                  style: 'authentic',
                  cta: 'What do you think?',
                  alt: 'Detailed rewrite alt text showcasing sanitized handling of prompts',
                  nsfw: false,
                },
              ]),
          },
        };
      });

      const variants = await variantsRewrite({
        platform: 'instagram',
        voice: 'engaging',
        existingCaption: messyCaption,
        hint: messyHint,
      });

      expect(promptBody).toContain('EXISTING_CAPTION: "Original \\"quote\\" with newline"');
      expect(promptBody).toContain('HINT:Focus on \\"engagement\\" please');
      expect(variants[0].caption).toBe('Enhanced and engaging caption! ✨');
    });
  });

  describe('OpenAI Fallback', () => {
    it('sanitizes existing captions for text-only fallback prompts', async () => {
      const messyCaption = 'Original "quote"\nwith newline';
      const capturedRequests: unknown[] = [];
      openAICreateMock.mockImplementationOnce(async request => {
        capturedRequests.push(request);
        return {
          choices: [
            {
              message: {
                content: JSON.stringify({
                  caption: 'Fallback caption',
                  hashtags: ['#fallback1', '#fallback2', '#fallback3'],
                  safety_level: 'normal',
                  mood: 'neutral',
                  style: 'informative',
                  cta: 'Check this out',
                  alt: 'Fallback alt text that is sufficiently long',
                  nsfw: false,
                }),
              },
            },
          ],
        };
      });

      const { openAICaptionFallback } = await import('../../server/caption/openaiFallback.js');

      await openAICaptionFallback({
        platform: 'instagram',
        voice: 'engaging',
        existingCaption: messyCaption,
      });

      const firstRequest = capturedRequests[0] as { messages: Array<{ content: unknown }> };
      const userMessage = firstRequest.messages[1].content as string;
      expect(userMessage).toContain('Rewrite this caption: "Original \\"quote\\" with newline"');
    });

    it('sanitizes existing captions for OpenAI vision prompts', async () => {
      const messyCaption = 'Original "quote"\nwith newline';
      const capturedRequests: unknown[] = [];
      openAICreateMock.mockImplementationOnce(async request => {
        capturedRequests.push(request);
        return {
          choices: [
            {
              message: {
                content: JSON.stringify({
                  caption: 'Fallback caption',
                  hashtags: ['#fallback1', '#fallback2', '#fallback3'],
                  safety_level: 'normal',
                  mood: 'neutral',
                  style: 'informative',
                  cta: 'Check this out',
                  alt: 'Fallback alt text that is sufficiently long',
                  nsfw: false,
                }),
              },
            },
          ],
        };
      });

      const { openAICaptionFallback } = await import('../../server/caption/openaiFallback.js');

      await openAICaptionFallback({
        platform: 'instagram',
        voice: 'engaging',
        imageUrl: 'data:image/jpeg;base64,AAA',
        existingCaption: messyCaption,
      });

      const firstRequest = capturedRequests[0] as {
        messages: Array<{ content: Array<{ type: string; text?: string }> }>;
      };
      const userContent = firstRequest.messages[1].content[0].text as string;
      expect(userContent).toContain(
        'Analyze this image and rewrite this caption to better match what you see: "Original \\"quote\\" with newline"',
      );
    });
  });
});
});
