tests/integration/workflow.test.ts
+48-28
import { describe, it, expect, beforeEach, vi } from 'vitest';

// Mock all external dependencies for integration testing
const mockGeminiTextResponse = JSON.stringify([{
  caption: 'Test caption generated by AI',
  hashtags: ['#test', '#ai'],
  safety_level: 'spicy_safe',
  mood: 'confident',
  style: 'authentic',
  cta: 'Check it out',
  alt: 'Test image description',
  nsfw: false
}]);

const mockGeminiVisionResponse = JSON.stringify({
  objects: ['woman', 'lingerie'],
  setting: 'bedroom',
  mood: 'confident'
});

const createGeminiResponse = (payload: string) => ({
  text: payload,
  response: { text: () => payload },
});

const mockTextModel = {
  generateContent: vi.fn<(input: unknown) => Promise<ReturnType<typeof createGeminiResponse>>>().mockResolvedValue(
    createGeminiResponse(mockGeminiTextResponse)
  ),
};

const mockVisionModel = {
  generateContent: vi.fn<(input: unknown) => Promise<ReturnType<typeof createGeminiResponse>>>().mockResolvedValue(
    createGeminiResponse(mockGeminiVisionResponse)
  ),
};

const mockIsGeminiAvailable = vi.fn(() => true);

vi.mock('../../server/lib/gemini-client', () => ({
  __esModule: true,
  getTextModel: () => mockTextModel,
  getVisionModel: () => mockVisionModel,
  isGeminiAvailable: mockIsGeminiAvailable,
}));

vi.mock('../../server/lib/gemini.ts', () => ({
  __esModule: true,
  textModel: {
    generateContent: vi.fn().mockResolvedValue({
      response: {
        text: () => JSON.stringify([{
          caption: 'Test caption generated by AI',
          hashtags: ['#test', '#ai'],
          safety_level: 'spicy_safe',
          mood: 'confident',
          style: 'authentic',
          cta: 'Check it out',
          alt: 'Test image description',
          nsfw: false
        }])
      }
    })
  },
  visionModel: {
    generateContent: vi.fn().mockResolvedValue({
      response: {
        text: () => JSON.stringify({
          objects: ['woman', 'lingerie'],
          setting: 'bedroom',
          mood: 'confident'
        })
      }
    })
  },
  isGeminiAvailable: () => true
  textModel: mockTextModel,
  visionModel: mockVisionModel,
  isGeminiAvailable: mockIsGeminiAvailable,
  getTextModel: () => mockTextModel,
  getVisionModel: () => mockVisionModel,
}));

vi.mock('../../server/storage', () => ({
  storage: {
    getUserById: vi.fn().mockResolvedValue({
      id: 1,
      username: 'testuser',
      tier: 'pro',
      subscription_status: 'active'
    }),
    createContentGeneration: vi.fn().mockResolvedValue({
      id: 1,
      userId: 1,
      type: 'image_to_content',
      result: {}
    }),
    updateContentGeneration: vi.fn().mockResolvedValue(true)
  }
}));

import { pipeline } from '../../server/caption/geminiPipeline';
import { pipelineTextOnly } from '../../server/caption/textOnlyPipeline';
import { pipelineRewrite } from '../../server/caption/rewritePipeline';

describe('End-to-End Content Generation Workflow', () => {
tests/routes/caption-generation.test.ts
+98-100
import { describe, it, expect, beforeEach, vi, type Mock } from 'vitest';
import { pipeline } from '../../server/caption/geminiPipeline';
import { pipelineRewrite, extractKeyEntities } from '../../server/caption/rewritePipeline';
import { pipelineTextOnly } from '../../server/caption/textOnlyPipeline';

// Mock dependencies
interface GeminiMockResponse {
  text?: string;
  response?: {
    text: () => string;
    functionCall?: Record<string, unknown>;
    functionCalls?: Record<string, unknown>[];
  };
  usageMetadata?: { totalTokenCount?: number };
}

type GeminiGenerateContent = (input: unknown) => Promise<GeminiMockResponse>;

const textModel = {
  generateContent: vi.fn<GeminiGenerateContent>(),
};

const visionModel = {
  generateContent: vi.fn<GeminiGenerateContent>(),
};

const isGeminiAvailable = vi.fn<() => boolean>(() => true);

vi.mock('../../server/lib/gemini-client', () => ({
  __esModule: true,
  getTextModel: () => textModel,
  getVisionModel: () => visionModel,
  isGeminiAvailable,
}));

vi.mock('../../server/lib/gemini.ts', () => ({
  __esModule: true,
  textModel: {
    generateContent: vi.fn(),
  },
  visionModel: {
    generateContent: vi.fn(),
  },
  isGeminiAvailable: vi.fn(() => true),
  textModel,
  visionModel,
  isGeminiAvailable,
  getTextModel: () => textModel,
  getVisionModel: () => visionModel,
}));

import { generationResponseSchema } from '../../shared/types/caption';

vi.mock('../../server/caption/openaiFallback', () => ({
  openAICaptionFallback: vi.fn().mockResolvedValue({
    caption: 'Fallback caption',
    hashtags: ['#fallback1', '#fallback2', '#fallback3'],
    safety_level: 'normal',
    alt: 'Fallback alt text that is sufficiently long',
    mood: 'neutral',
    style: 'informative',
    cta: 'Check this out',
    nsfw: false,
  }),
}));

// Type interfaces for test safety
interface MockResponse {
  response: {
    text: () => string;
    functionCall?: Record<string, unknown>;
    functionCalls?: Record<string, unknown>[];
  };
}

interface CaptionResult {
  caption: string;
  hashtags: string[];
  safety_level: string;
  mood: string;
  style: string;
  cta: string;
  alt: string;
  nsfw: boolean;
}

const asMock = <T>(fn: T) => fn as unknown as Mock;

vi.mock('../../server/storage.ts', () => ({
  storage: {
    getUserById: vi.fn(),
    createContentGeneration: vi.fn(),
    updateContentGeneration: vi.fn(),
  },
}));

const createGeminiResponse = (payload: string, usage?: GeminiMockResponse['usageMetadata']): GeminiMockResponse => ({
  text: payload,
  response: {
    text: () => payload,
  },
  usageMetadata: usage,
});

const asMock = <T>(fn: T) => fn as unknown as Mock;

describe('Caption Generation', () => {
  beforeEach(async () => {
    vi.clearAllMocks();
    const { textModel, visionModel } = await import('../../server/lib/gemini.ts');
    (textModel.generateContent as Mock | undefined)?.mockReset?.();
    (visionModel.generateContent as Mock | undefined)?.mockReset?.();
    const { isGeminiAvailable } = await import('../../server/lib/gemini.ts');
    asMock(isGeminiAvailable).mockReset?.();
    asMock(isGeminiAvailable).mockReturnValue(true);
    textModel.generateContent.mockReset();
    visionModel.generateContent.mockReset();
    isGeminiAvailable.mockReset();
    isGeminiAvailable.mockReturnValue(true);
    const { openAICaptionFallback } = await import('../../server/caption/openaiFallback.ts');
    const mockOpenAI = vi.mocked(openAICaptionFallback);
    mockOpenAI.mockReset();
    mockOpenAI.mockResolvedValue({
      caption: 'Fallback caption',
      hashtags: ['#fallback1', '#fallback2', '#fallback3'],
      safety_level: 'normal',
      alt: 'Fallback alt text that is sufficiently long',
      mood: 'neutral',
      style: 'informative',
      cta: 'Check this out',
      nsfw: false,
    });
  });

  describe('Gemini Pipeline', () => {
    it('should handle image-based caption generation', async () => {
      const mockImageUrl =
        'data:image/jpeg;base64,' +
        '/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAP///////////////wAALCAABAAEBAREA/8QAFAABAAAAAAAAAAAAAAAAAAAACP/EABQQAQAAAAAAAAAAAAAAAAAAAAD/2gAIAQEAAD8Af//Z';
      const mockPlatform = 'instagram';
      const mockVoice = 'flirty_playful';

      // Mock successful responses
      const mockFactsResponse = {
        response: {
          text: () => JSON.stringify({
            objects: ['lingerie'],
            setting: 'bedroom',
            mood: 'confident',
          }),
        },
      };
      const mockFactsResponse = createGeminiResponse(
        JSON.stringify({
          objects: ['lingerie'],
          setting: 'bedroom',
          mood: 'confident',
        })
      );

      const variantPayload = [
        {
          caption: 'Feeling gorgeous tonight âœ¨',
          hashtags: ['#lingerie', '#confidence', '#style'],
          safety_level: 'spicy_safe',
          mood: 'confident',
          style: 'authentic',
          cta: 'What do you think?',
          alt: 'A glamorous example alt text to satisfy schema',
          nsfw: false,
        },
        {
          caption: 'Lace layers with late night sparkle',
          hashtags: ['#lace', '#latenight', '#sparkle'],
          safety_level: 'normal',
          mood: 'playful',
          style: 'bold',
          cta: 'Slide through if you feel the glow',
          alt: 'Detailed alt text describing lace details glowing under soft lighting.',
          nsfw: false,
        },
        {
          caption: 'Moonlit silk and champagne laughs',
          hashtags: ['#moonlit', '#silk', '#champagne'],
@@ -134,137 +156,113 @@ describe('Caption Generation', () => {
          alt: 'Alt text capturing a confident pose beside a city window at night.',
          nsfw: false,
        },
        {
          caption: 'Velvet shadows and bold smiles',
          hashtags: ['#velvet', '#bold', '#smiles'],
          safety_level: 'spicy_safe',
          mood: 'confident',
          style: 'dramatic',
          cta: 'Drop your favorite night-out emoji',
          alt: 'Alt text describing a model in velvet attire with playful lighting.',
          nsfw: false,
        },
        {
          caption: 'Neon-lit nights and satin strides',
          hashtags: ['#neon', '#satin', '#nightout'],
          safety_level: 'normal',
          mood: 'energized',
          style: 'modern',
          cta: 'Tell me your go-to city soundtrack',
          alt: 'Alt text highlighting neon reflections on satin fabrics downtown.',
          nsfw: false,
        },
      ];

      const mockVariantsResponse = {
        response: {
          text: () => JSON.stringify(variantPayload),
        },
      };
      const mockVariantsResponse = createGeminiResponse(JSON.stringify(variantPayload));

      const mockRankResponse = {
        response: {
          text: () =>
            JSON.stringify({
              winner_index: 0,
              scores: [5, 4, 3, 2, 1],
              reason: 'Selected based on engagement potential',
              final: variantPayload[0],
            }),
        },
      };
      const mockRankResponse = createGeminiResponse(
        JSON.stringify({
          winner_index: 0,
          scores: [5, 4, 3, 2, 1],
          reason: 'Selected based on engagement potential',
          final: variantPayload[0],
        })
      );

      const retryVariantPayload = variantPayload.map((variant, index) => ({
        ...variant,
        caption: `${variant.caption} (retry ${index + 1})`,
        alt: `${variant.alt} Retry sequence ${index + 1}.`,
      }));

      const retryVariantsResponse = {
        response: {
          text: () => JSON.stringify(retryVariantPayload),
        },
      };
      const retryVariantsResponse = createGeminiResponse(JSON.stringify(retryVariantPayload));

      const retryRankResponse = {
        response: {
          text: () =>
            JSON.stringify({
              winner_index: 1,
              scores: [4, 5, 3, 2, 1],
              reason: 'Retry selection maintains quality variety',
              final: retryVariantPayload[1],
            }),
        },
      };
      const retryRankResponse = createGeminiResponse(
        JSON.stringify({
          winner_index: 1,
          scores: [4, 5, 3, 2, 1],
          reason: 'Retry selection maintains quality variety',
          final: retryVariantPayload[1],
        })
      );

      const finalVariantPayload = retryVariantPayload.map((variant, index) => ({
        ...variant,
        caption: `${variant.caption} (stabilized ${index + 1})`,
        alt: `${variant.alt} Stabilized coverage pass ${index + 1}.`,
      }));

      const finalVariantsResponse = {
        response: {
          text: () => JSON.stringify(finalVariantPayload),
        },
      };
      const finalVariantsResponse = createGeminiResponse(JSON.stringify(finalVariantPayload));

      const finalRankResponse = {
        response: {
          text: () =>
            JSON.stringify({
              winner_index: 2,
              scores: [3, 4, 5, 2, 1],
              reason: 'Final stabilization ranking',
              final: finalVariantPayload[2],
            }),
        },
      };
      const finalRankResponse = createGeminiResponse(
        JSON.stringify({
          winner_index: 2,
          scores: [3, 4, 5, 2, 1],
          reason: 'Final stabilization ranking',
          final: finalVariantPayload[2],
        })
      );

      const { textModel, visionModel } = await import('../../server/lib/gemini.ts');
      const visionGenerateMock = asMock(visionModel.generateContent);
      visionGenerateMock.mockResolvedValueOnce(mockFactsResponse);
      const textGenerateMock = asMock(textModel.generateContent);
      const responseQueue = [
      visionModel.generateContent.mockResolvedValueOnce(mockFactsResponse);
      const responseQueue: GeminiMockResponse[] = [
        mockVariantsResponse,
        mockRankResponse,
        retryVariantsResponse,
        retryRankResponse,
        finalVariantsResponse,
        finalRankResponse,
      ];
      textGenerateMock.mockImplementation(() => {
      textModel.generateContent.mockImplementation(async () => {
        if (responseQueue.length === 0) {
          responseQueue.push(finalVariantsResponse, finalRankResponse);
        }
        const next = responseQueue.shift();
        if (!next) {
          throw new Error('Gemini variants unavailable');
        }
        return Promise.resolve(next as Awaited<ReturnType<(typeof textModel)['generateContent']>>);
        return next;
      });

      const result = await pipeline({
        imageUrl: mockImageUrl,
        platform: mockPlatform,
        voice: mockVoice,
      });

      const { openAICaptionFallback } = await import('../../server/caption/openaiFallback.ts');

      expect(openAICaptionFallback).not.toHaveBeenCalled();
      expect(result.final).toMatchObject({
        caption: expect.any(String) as string,
        safety_level: expect.stringMatching(/safe|low|spicy_safe|normal/),
      });
      expect(result.titles).toBeDefined();
      expect(Array.isArray(result.titles)).toBe(true);
      expect(result.titles?.length).toBeGreaterThan(0);
      const finalTitles = (result.final as { titles?: string[] }).titles;
      expect(finalTitles).toBeDefined();
      expect(Array.isArray(finalTitles)).toBe(true);
      expect(finalTitles?.length).toBeGreaterThan(0);
      const rankedFinalTitles = ((result.ranked as { final?: { titles?: string[] } })?.final)?.titles;
      expect(rankedFinalTitles).toBeDefined();
      expect(rankedFinalTitles?.length).toBeGreaterThan(0);
@@ -928,57 +926,57 @@ describe('Caption Generation', () => {
          caption: 'Velvet secrets under moonlit alleys',
          hashtags: ['#velvet', '#moonlit', '#alleys'],
          safety_level: 'normal',
          mood: 'mysterious',
          style: 'dramatic',
          cta: 'Reveal your night secret',
          alt: 'Another long-form alt text to maintain schema compliance',
          nsfw: false,
        },
        {
          caption: 'Gilded glow with midnight attitude',
          hashtags: ['#gilded', '#midnight', '#attitude'],
          safety_level: 'normal',
          mood: 'sultry',
          style: 'glamorous',
          cta: 'Who are you texting tonight?',
          alt: 'Final alt entry covering the golden styling for unique variant set',
          nsfw: false,
        },
      ];

      const { textModel } = await import('../../server/lib/gemini.ts');
      const textGenerateMock = asMock(textModel.generateContent);
      textGenerateMock
        .mockResolvedValueOnce({
          response: { text: () => JSON.stringify(duplicateBatch) },
          text: JSON.stringify(duplicateBatch) },
        })
        .mockResolvedValueOnce({
          response: { text: () => JSON.stringify(uniqueBatch) },
          text: JSON.stringify(uniqueBatch) },
        })
        .mockResolvedValue({
          response: { text: () => JSON.stringify(uniqueBatch) },
          text: JSON.stringify(uniqueBatch) },
        });

      const { generateVariants } = await import('../../server/caption/geminiPipeline.ts');
      const result = await generateVariants({
        platform: 'instagram',
        voice: 'flirty_playful',
        facts: { objects: ['test'] },
      });

      const callCount = textGenerateMock.mock.calls.length;
      if (callCount >= 2) {
        const secondPrompt = textGenerateMock.mock.calls[1][0][0].text as string;
        expect(secondPrompt).toContain('You already wrote');
      } else {
        expect(result.some(variant => variant.caption.includes('(retry filler'))).toBe(true);
      }
      expect(new Set(result.map(v => v.caption.toLowerCase().slice(0, 80))).size).toBe(5);
    });

    it('sanitizes base hints with quotes and line breaks for Gemini variants', async () => {
      const variantPayload = [
        {
          caption: 'Fresh take on winter vibes with cozy layers',
          hashtags: ['#winter', '#cozy', '#layers'],
          safety_level: 'normal',
@@ -1104,52 +1102,52 @@ describe('Caption Generation', () => {
        {
          caption: 'Electric neon glow painting the city streets',
          hashtags: ['#neon', '#electric', '#city'],
          safety_level: 'normal',
          mood: 'energetic',
          style: 'modern',
          cta: 'Drop your beat',
          alt: 'Long-form alt text to exercise duplicate retry sanitization fourth.',
          nsfw: false,
        },
        {
          caption: 'Soft pastel dreams meeting golden hour magic',
          hashtags: ['#pastel', '#dreams', '#golden'],
          safety_level: 'normal',
          mood: 'dreamy',
          style: 'ethereal',
          cta: 'Share the magic',
          alt: 'Long-form alt text to exercise duplicate retry sanitization fifth.',
          nsfw: false,
        },
      ];

      const { textModel } = await import('../../server/lib/gemini.ts');
      const textGenerateMock = asMock(textModel.generateContent);
      textGenerateMock
        .mockResolvedValueOnce({ response: { text: () => JSON.stringify(duplicateBatch) } })
        .mockResolvedValueOnce({ response: { text: () => JSON.stringify(uniqueBatch) } });
        .mockResolvedValueOnce({ text: JSON.stringify(duplicateBatch) } })
        .mockResolvedValueOnce({ text: JSON.stringify(uniqueBatch) } });

      const { generateVariants } = await import('../../server/caption/geminiPipeline.ts');
      const baseHint = 'Line1\nLine2 "quoted"';
      await generateVariants({
        platform: 'instagram',
        voice: 'flirty_playful',
        facts: { objects: ['retry'] },
        hint: baseHint,
      });

      expect(textGenerateMock).toHaveBeenCalledTimes(2);
      const firstPrompt = textGenerateMock.mock.calls[0][0][0].text as string;
      const secondPrompt = textGenerateMock.mock.calls[1][0][0].text as string;

      const { serializePromptField } = await import('../../server/caption/promptUtils.ts');
      const sanitizedBaseHint = serializePromptField(baseHint, { block: true });
      expect(firstPrompt).toContain(`\nHINT:${sanitizedBaseHint}`);
      expect(firstPrompt).not.toContain('HINT:Line1\nLine2 "quoted"');

      const retryHintRaw = `${baseHint} Need much more variety across tone, structure, and imagery.`;
      const sanitizedRetryHint = serializePromptField(retryHintRaw, { block: true });
      expect(secondPrompt).toContain(`\nHINT:${sanitizedRetryHint}`);
      expect(secondPrompt).not.toContain(
        'HINT:Line1\nLine2 "quoted" Need much more variety across tone, structure, and imagery.'
      );
@@ -1391,57 +1389,57 @@ describe('Caption Generation', () => {
          caption: 'Refocus, refuel, and repeat your mission',
          hashtags: ['#refocus', '#refuel', '#mission'],
          safety_level: 'normal',
          mood: 'focused',
          style: 'encouraging',
          cta: 'Share your repeatable habit',
          alt: 'Alt copy illustrating a repeatable mission-building routine',
          nsfw: false,
        },
        {
          caption: 'Evening reflection: celebrate the subtle wins',
          hashtags: ['#evening', '#reflection', '#wins'],
          safety_level: 'normal',
          mood: 'grateful',
          style: 'reflective',
          cta: 'Name one small victory today',
          alt: 'Reflective alt text encouraging users to acknowledge daily progress',
          nsfw: false,
        },
      ];

      const { textModel } = await import('../../server/lib/gemini.ts');
      const textGenerateMock = asMock(textModel.generateContent);
      textGenerateMock
        .mockResolvedValueOnce({
          response: { text: () => JSON.stringify(duplicateBatch) },
          text: JSON.stringify(duplicateBatch) },
        })
        .mockResolvedValueOnce({
          response: { text: () => JSON.stringify(uniqueBatch) },
          text: JSON.stringify(uniqueBatch) },
        })
        .mockResolvedValue({
          response: { text: () => JSON.stringify(uniqueBatch) },
          text: JSON.stringify(uniqueBatch) },
        });

      const { generateVariantsTextOnly } = await import('../../server/caption/textOnlyPipeline.ts');
      const originalEnv = process.env.NODE_ENV;
      process.env.NODE_ENV = 'development';
      let result;
      try {
        result = await generateVariantsTextOnly({
          platform: 'instagram',
          voice: 'inspiring',
          theme: 'motivation',
          context: 'morning motivation post',
        });
      } finally {
        process.env.NODE_ENV = originalEnv;
      }

      const callCount = textGenerateMock.mock.calls.length;
      if (callCount >= 2) {
        const secondPrompt = textGenerateMock.mock.calls[1][0][0].text as string;
        expect(secondPrompt).toContain('You already wrote');
      } else {
        expect(result.some(variant => variant.caption.includes('(retry filler'))).toBe(true);
      }
      expect(new Set(result.map(v => v.caption.toLowerCase().slice(0, 80))).size).toBe(5);
@@ -1622,102 +1620,102 @@ describe('Caption Generation', () => {

      generateSpy.mockRestore();
    });

    it('retries rewrite with hints when the first pass is too short', async () => {
      const existingCaption = 'Basic caption here';
      const longAltText =
        'A descriptive alt text that clearly explains the scene and exceeds the schema requirements for length.';

      const makeVariants = (caption: string) =>
        Array.from({ length: 5 }, () => ({
          caption,
          hashtags: ['#vibes', '#style', '#moments'],
          safety_level: 'normal',
          mood: 'engaging',
          style: 'authentic',
          cta: 'Tell me what you think',
          alt: longAltText,
          nsfw: false,
        }));

      const shortVariantsResponse = {
        response: {
          text: () => JSON.stringify(makeVariants(existingCaption)),
        },
      } satisfies { response: { text: () => string } };
      } satisfies { text: string };

      const shortRankResponse = {
        response: {
          text: () =>
            JSON.stringify({
              winner_index: 0,
              scores: [5, 4, 3, 2, 1],
              reason: 'Short baseline rewrite',
              final: {
                caption: existingCaption,
                hashtags: ['#vibes', '#style', '#moments'],
                safety_level: 'normal',
                mood: 'engaging',
                style: 'authentic',
                cta: 'Tell me what you think',
                alt: longAltText,
                nsfw: false,
              },
            }),
        },
      } satisfies { response: { text: () => string } };
      } satisfies { text: string };

      const longerCaption =
        'Basic caption here, now expanded with vivid detail that teases the story and invites you to join the conversation.';

      const longVariantsResponse = {
        response: {
          text: () => JSON.stringify(makeVariants(longerCaption)),
        },
      } satisfies { response: { text: () => string } };
      } satisfies { text: string };

      const longRankResponse = {
        response: {
          text: () =>
            JSON.stringify({
              winner_index: 0,
              scores: [5, 4, 3, 2, 1],
              reason: 'Longer rewrite with CTA',
              final: {
                caption: longerCaption,
                hashtags: ['#vibes', '#style', '#moments'],
                safety_level: 'normal',
                mood: 'engaging',
                style: 'authentic',
                cta: 'Tell me what you think',
                alt: longAltText,
                nsfw: false,
              },
            }),
        },
      } satisfies { response: { text: () => string } };
      } satisfies { text: string };

      const { textModel } = await import('../../server/lib/gemini.ts');
      const generateContentMock = vi.spyOn(textModel, 'generateContent');

      const shortVariantsCast = shortVariantsResponse as unknown as Awaited<
        ReturnType<(typeof textModel)['generateContent']>
      >;
      const shortRankCast = shortRankResponse as unknown as Awaited<
        ReturnType<(typeof textModel)['generateContent']>
      >;
      const longVariantsCast = longVariantsResponse as unknown as Awaited<
        ReturnType<(typeof textModel)['generateContent']>
      >;
      const longRankCast = longRankResponse as unknown as Awaited<
        ReturnType<(typeof textModel)['generateContent']>
      >;

      generateContentMock
        .mockResolvedValueOnce(shortVariantsCast)
        .mockResolvedValueOnce(shortRankCast)
        .mockResolvedValueOnce(longVariantsCast)
        .mockResolvedValueOnce(longRankCast);

      const result = await pipelineRewrite({
        platform: 'instagram',
