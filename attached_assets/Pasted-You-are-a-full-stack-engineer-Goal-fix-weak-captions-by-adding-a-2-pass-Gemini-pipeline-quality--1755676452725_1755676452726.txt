You are a full-stack engineer. Goal: fix weak captions by adding a 2-pass Gemini pipeline + quality gates, and improve the UI readability. Do everything below end-to-end.

### 0) Dependencies & env
- Add deps:
  npm i @google/generative-ai zod
- Ensure Node 18+ (built-in fetch).
- Add env var: GEMINI_API_KEY
- Create src/lib/gemini.ts:
  --------------------------------------------------
  import { GoogleGenerativeAI } from "@google/generative-ai";
  export const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);
  export const visionModel = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
  export const textModel   = genAI.getGenerativeModel({ model: "gemini-1.5-flash" }); // keep consistent
  --------------------------------------------------

### 1) Prompts (create folder ./prompts)
Create these files with exact contents:

- ./prompts/system.txt
  --------------------------------------------------
  You are a senior social copywriter. Write on-brand, image-relevant captions that convert.
  Hard rules:
  - Use IMAGE_FACTS as ground truth.
  - Match VOICE and PLATFORM constraints.
  - Never output placeholders or meta text.
  - Return valid JSON only per schema when asked; no prose.
  --------------------------------------------------

- ./prompts/guard.txt
  --------------------------------------------------
  Never output: "generated content", "placeholder", "N/A", or meta-text.
  If info is missing, infer from IMAGE_FACTS cues conservatively.
  --------------------------------------------------

- ./prompts/extract.txt
  --------------------------------------------------
  Task: Extract concrete facts from the image. Return JSON only:
  {"objects":[],"colors":[],"vibe":"","setting":"","wardrobe":"","angles":[]}
  Rules: Use concise, literal nouns/colors; no extra text.
  --------------------------------------------------

- ./prompts/variants.txt
  --------------------------------------------------
  Given:
  PLATFORM: <instagram|x|reddit|tiktok>
  VOICE: <flirty_playful|gamer_nerdy|luxury_minimal|arts_muse|gym_energy|cozy_girl>
  IMAGE_FACTS: <json>

  Write 5 caption options. Return JSON array of 5 objects ONLY with this schema:
  {
    "caption":"", "alt":"", "hashtags":[], "cta":"", "mood":"", "style":"", "safety_level":""
  }

  Requirements:
  - 5 different angles; 1 short & punchy, 1 CTA-forward, 1 aesthetic/poetic.
  - Use nouns/colors/setting from IMAGE_FACTS so it obviously matches the picture.
  - Platform limits:
    * Instagram: hook <=125 chars, total <=2200; 3–8 targeted hashtags.
    * X: <=250 chars; 1–3 hashtags.
    * Reddit: conversational, no hashtag spam.
    * TikTok: 150–220 chars; 2–5 hashtags.
  --------------------------------------------------

- ./prompts/rank.txt
  --------------------------------------------------
  Rank the 5 candidates for: Relevance(40), Voice(25), Originality(20), CTA(10), Safety(5).
  Return JSON only:
  {
    "winner_index": 0-4,
    "scores": [5 ints],
    "reason": "<240 chars",
    "final": { "caption":"", "alt":"", "hashtags":[], "cta":"", "mood":"", "style":"", "safety_level":"" }
  }
  Trim hashtags to platform limits.
  --------------------------------------------------

### 2) Schemas & utils
- Create src/caption/schema.ts
  --------------------------------------------------
  import { z } from "zod";
  export const CaptionItem = z.object({
    caption: z.string().min(1),
    alt: z.string().min(20).max(200),
    hashtags: z.array(z.string()).min(2).max(10),
    cta: z.string().min(2),
    mood: z.string().min(2),
    style: z.string().min(2),
    safety_level: z.enum(["normal","spicy_safe","needs_review"])
  });
  export const CaptionArray = z.array(CaptionItem).length(5);
  export const RankResult = z.object({
    winner_index: z.number().min(0).max(4),
    scores: z.array(z.number()).length(5),
    reason: z.string().min(1).max(240),
    final: CaptionItem
  });

  export function platformChecks(p: "instagram"|"x"|"reddit"|"tiktok", item: z.infer<typeof CaptionItem>) {
    const len = item.caption.length;
    if (p === "x" && len > 250) return "X caption too long";
    if (p === "tiktok" && (len < 150 || len > 220)) return "TikTok length out of range (150–220)";
    if (p === "instagram" && len > 2200) return "Instagram caption too long";
    if (p === "reddit" && item.hashtags.some(h=>h.startsWith("#"))) return "Reddit: no hashtag spam";
    // basic hashtag ranges
    const count = item.hashtags.length;
    if (p === "instagram" && (count < 3 || count > 8)) return "Instagram hashtags 3–8";
    if (p === "x" && (count < 0 || count > 3)) return "X hashtags 0–3";
    if (p === "tiktok" && (count < 2 || count > 5)) return "TikTok hashtags 2–5";
    // ban basic generic tags
    const banned = new Set(["#love","#follow","#like","#instagood","#photooftheday"]);
    if (item.hashtags.some(h=>banned.has(h.toLowerCase()))) return "Generic hashtags detected";
    return null;
  }
  --------------------------------------------------

- Create src/caption/stylePack.ts
  --------------------------------------------------
  export const STYLE_TOKENS = ["flirty_playful","gamer_nerdy","luxury_minimal","arts_muse","gym_energy","cozy_girl"] as const;
  export type StyleToken = typeof STYLE_TOKENS[number];
  --------------------------------------------------

- Create src/caption/geminiPipeline.ts
  --------------------------------------------------
  import fs from "node:fs/promises";
  import path from "node:path";
  import { z } from "zod";
  import { visionModel, textModel } from "../lib/gemini";
  import { CaptionArray, RankResult, platformChecks } from "./schema";

  async function loadPrompt(p: string) {
    return fs.readFile(path.join(process.cwd(), "prompts", p), "utf8");
  }
  async function fetchAsBase64(url: string) {
    const res = await fetch(url);
    if (!res.ok) throw new Error(`Fetch image failed: ${res.status}`);
    const buf = Buffer.from(await res.arrayBuffer());
    return buf.toString("base64");
  }
  async function safeJSON<T>(txt: string): Promise<T> {
    const start = txt.indexOf("{"); const arr = txt.indexOf("[");
    const i = (arr !== -1 && (arr < start || start === -1)) ? arr : start;
    const j = Math.max(txt.lastIndexOf("}"), txt.lastIndexOf("]"));
    const core = (i !== -1 && j !== -1) ? txt.slice(i, j+1) : txt;
    return JSON.parse(core);
  }

  export async function extractFacts(imageUrl: string) {
    const sys = await loadPrompt("system.txt");
    const guard = await loadPrompt("guard.txt");
    const prompt = await loadPrompt("extract.txt");
    const base64 = await fetchAsBase64(imageUrl);
    const res = await visionModel.generateContent([
      { text: sys + "\n" + guard + "\n" + prompt },
      { inlineData: { data: base64, mimeType: "image/jpeg" } }
    ]);
    return safeJSON<any>(res.response.text());
  }

  export async function generateVariants(params: {platform: "instagram"|"x"|"reddit"|"tiktok", voice: string, facts: any, hint?: string}) {
    const sys = await loadPrompt("system.txt");
    const guard = await loadPrompt("guard.txt");
    const prompt = await loadPrompt("variants.txt");
    const user = `
      PLATFORM: ${params.platform}
      VOICE: ${params.voice}
      IMAGE_FACTS: ${JSON.stringify(params.facts)}
      ${params.hint ? "HINT:"+params.hint : ""}
    `;
    const res = await textModel.generateContent([{ text: sys + "\n" + guard + "\n" + prompt + "\n" + user }]);
    const json = await safeJSON(res.response.text());
    return CaptionArray.parse(json);
  }

  export async function rankAndSelect(variants: any) {
    const sys = await loadPrompt("system.txt");
    const guard = await loadPrompt("guard.txt");
    const prompt = await loadPrompt("rank.txt");
    const user = JSON.stringify(variants);
    const res = await textModel.generateContent([{ text: sys + "\n" + guard + "\n" + prompt + "\n" + user }]);
    const json = await safeJSON(res.response.text());
    return RankResult.parse(json);
  }

  export async function pipeline({ imageUrl, platform, voice }: { imageUrl: string, platform: "instagram"|"x"|"reddit"|"tiktok", voice?: string }) {
    const v = voice || "flirty_playful";
    const facts = await extractFacts(imageUrl);
    let variants = await generateVariants({ platform, voice: v, facts });
    let ranked = await rankAndSelect(variants);
    let out = ranked.final;

    // quality gates
    const err = platformChecks(platform, out);
    if (err || out.caption.toLowerCase().includes("generated content")) {
      variants = await generateVariants({ platform, voice: v, facts, hint: `Fix: ${err || "No placeholders"}; ground in objects/colors/setting from IMAGE_FACTS` });
      ranked = await rankAndSelect(variants);
      out = ranked.final;
    }

    return { facts, variants, ranked, final: out };
  }
  --------------------------------------------------

### 3) API route
Create POST /api/caption/generate (adjust to your framework: Next.js API route, Express, etc.)
- For Next.js: src/pages/api/caption/generate.ts
  --------------------------------------------------
  import type { NextApiRequest, NextApiResponse } from "next";
  import { pipeline } from "../../../caption/geminiPipeline";

  export default async function handler(req: NextApiRequest, res: NextApiResponse) {
    try {
      if (req.method !== "POST") return res.status(405).json({ error: "Method not allowed" });
      const { imageUrl, platform, voice } = req.body || {};
      if (!imageUrl || !platform) return res.status(400).json({ error: "imageUrl and platform are required" });
      const result = await pipeline({ imageUrl, platform, voice });
      return res.status(200).json(result);
    } catch (e:any) {
      console.error(e);
      return res.status(500).json({ error: e.message || "generation failed" });
    }
  }
  --------------------------------------------------

(If using Express instead, create routes/caption.ts and wire it in app.ts; same logic.)

### 4) UI: make it easier to read
- Create src/components/CaptionPreview.tsx
  --------------------------------------------------
  import React from "react";

  export function CaptionPreview({ data }: { data: any }) {
    if (!data) return null;
    const { final, ranked } = data;
    const charCount = final.caption.length;
    return (
      <div className="rounded-2xl border p-4 space-y-3 bg-white/60">
        <div className="flex items-center justify-between">
          <div className="text-lg font-semibold">Caption Preview</div>
          <div className="text-sm opacity-75">Chars: {charCount}</div>
        </div>
        <div className="text-sm text-gray-700 whitespace-pre-wrap">{final.caption}</div>
        <div className="text-xs text-gray-500">ALT: {final.alt}</div>

        <div className="flex flex-wrap gap-2">
          {final.hashtags.map((h: string) => (
            <span key={h} className="px-2 py-1 rounded-full bg-gray-100 text-xs">{h}</span>
          ))}
        </div>

        <div className="grid grid-cols-2 gap-2 text-xs">
          <div><b>Mood</b>: {final.mood}</div>
          <div><b>Style</b>: {final.style}</div>
          <div><b>CTA</b>: {final.cta}</div>
          <div><b>Safety</b>: {final.safety_level}</div>
        </div>

        <div className="text-xs text-gray-500">
          <b>Why this won:</b> {ranked.reason}
        </div>

        <div className="flex gap-2">
          <button onClick={() => navigator.clipboard.writeText(final.caption)} className="px-3 py-1 border rounded">Copy Caption</button>
          <button onClick={() => navigator.clipboard.writeText(JSON.stringify(final, null, 2))} className="px-3 py-1 border rounded">Copy JSON</button>
        </div>
      </div>
    );
  }
  --------------------------------------------------

- On your generation page (e.g., src/pages/caption.tsx):
  - Add platform select (instagram/x/reddit/tiktok), voice select, image URL input, “Generate” button.
  - After POST, render <CaptionPreview data={responseJson} />.
  - Error handling: if API returns error or final.caption empty, show a red banner and a “Regenerate” button.

### 5) Tests (optional but quick)
- Add a simple parse test to ensure the model returns valid JSON parsable by zod.
  Create tests/caption-schema.test.ts using your test runner (or skip if none).

### 6) Deliverables / Verify
- Start dev server, hit POST /api/caption/generate with:
  {
    "imageUrl": "<public_jpeg_url>",
    "platform": "instagram",
    "voice": "luxury_minimal"
  }
- Expect JSON with {facts, variants[5], ranked, final}.
- In UI, verify:
  - Readable card, pills for hashtags, char count, copy buttons.
  - No “generated content” placeholders.
  - If the caption is out-of-range for platform, pipeline auto-regenerates once.

### 7) Notes / Future
- Optional similarity check: add a second pass using embeddings when ready; if similarity < threshold, call generateVariants again with a grounding hint.
- If you later add OpenAI/Claude, keep this exact contract (facts → 5 variants → rank → gates).
